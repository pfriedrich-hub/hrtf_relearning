Index: .idea/shelf/Uncommitted_changes_before_Update_at_12_28_2025_1_38_PM__Changes_.xml
===================================================================
diff --git a/.idea/shelf/Uncommitted_changes_before_Update_at_12_28_2025_1_38_PM__Changes_.xml b/.idea/shelf/Uncommitted_changes_before_Update_at_12_28_2025_1_38_PM__Changes_.xml
deleted file mode 100644
--- a/.idea/shelf/Uncommitted_changes_before_Update_at_12_28_2025_1_38_PM__Changes_.xml	(revision cf777cdf3656397ca133decb83b62881be9b0c4f)
+++ /dev/null	(revision cf777cdf3656397ca133decb83b62881be9b0c4f)
@@ -1,8 +0,0 @@
-<changelist name="Uncommitted_changes_before_Update_at_12_28_2025_1_38_PM_[Changes]" date="1766925565723" recycled="true" deleted="true">
-  <option name="PATH" value="$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Update_at_12_28_2025_1_38_PM_[Changes]/shelved.patch" />
-  <option name="DESCRIPTION" value="Uncommitted changes before Update at 12/28/2025 1:38 PM [Changes]" />
-  <binary>
-    <option name="AFTER_PATH" value="hrtf_relearning/hrtf/record/calibration/data/calibration_dome.pkl" />
-    <option name="SHELVED_PATH" value="$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Update_at_12_28_2025_1_38_PM_[Changes]/calibration_dome.pkl" />
-  </binary>
-</changelist>
\ No newline at end of file
Index: .idea/shelf/Uncommitted_changes_before_Update_at_12_28_2025_1_38_PM_[Changes]/shelved.patch
===================================================================
diff --git a/.idea/shelf/Uncommitted_changes_before_Update_at_12_28_2025_1_38_PM_[Changes]/shelved.patch b/.idea/shelf/Uncommitted_changes_before_Update_at_12_28_2025_1_38_PM_[Changes]/shelved.patch
deleted file mode 100644
--- a/.idea/shelf/Uncommitted_changes_before_Update_at_12_28_2025_1_38_PM_[Changes]/shelved.patch	(revision cf777cdf3656397ca133decb83b62881be9b0c4f)
+++ /dev/null	(revision cf777cdf3656397ca133decb83b62881be9b0c4f)
@@ -1,167 +0,0 @@
-Index: .idea/shelf/Uncommitted_changes_before_Update_at_12_17_2025_5_21_PM_[Changes]/shelved.patch
-===================================================================
-diff --git a/.idea/shelf/Uncommitted_changes_before_Update_at_12_17_2025_5_21_PM_[Changes]/shelved.patch b/.idea/shelf/Uncommitted_changes_before_Update_at_12_17_2025_5_21_PM_[Changes]/shelved.patch
-deleted file mode 100644
---- a/.idea/shelf/Uncommitted_changes_before_Update_at_12_17_2025_5_21_PM_[Changes]/shelved.patch	(revision c1855ffaa0401de426b3c09cd9f09facec5d3dc8)
-+++ /dev/null	(revision c1855ffaa0401de426b3c09cd9f09facec5d3dc8)
-@@ -1,22 +0,0 @@
--Index: hrtf_relearning/data/env config.txt
--===================================================================
--diff --git a/hrtf_relearning/data/env config.txt b/hrtf_relearning/data/env config.txt
--deleted file mode 100644
----- a/hrtf_relearning/data/env config.txt	(revision a5f0f2be9bbb483146dbd9fe5f5e7afe0aad62c2)
--+++ /dev/null	(revision a5f0f2be9bbb483146dbd9fe5f5e7afe0aad62c2)
--@@ -1,14 +0,0 @@
---pycharm 2025.2
---python 3.11.9 virtual environment (-add git/bin to PATH variables)
---
---
---pip install git+https://github.com/pfriedrich-hub/slab.git
--- git+https://github.com/pfriedrich-hub/pybinsim_tuil.git
--- h5py h5netcdf metawear pyqt5 pynput pyfar
---
---
--- optional:
---    -for cuda support (>=RTX 30xx):
---        pip install torch torchvision --index-url https://download.pytorch.org/whl/cu128
---        check with: torch.cuda.is_available()
--- pip install git+https://github.com/pfriedrich-hub/freefield.git
--\ No newline at end of file
-Index: .idea/shelf/Uncommitted_changes_before_Update_at_12_17_2025_5_21_PM__Changes_.xml
-===================================================================
-diff --git a/.idea/shelf/Uncommitted_changes_before_Update_at_12_17_2025_5_21_PM__Changes_.xml b/.idea/shelf/Uncommitted_changes_before_Update_at_12_17_2025_5_21_PM__Changes_.xml
-deleted file mode 100644
---- a/.idea/shelf/Uncommitted_changes_before_Update_at_12_17_2025_5_21_PM__Changes_.xml	(revision c1855ffaa0401de426b3c09cd9f09facec5d3dc8)
-+++ /dev/null	(revision c1855ffaa0401de426b3c09cd9f09facec5d3dc8)
-@@ -1,4 +0,0 @@
--<changelist name="Uncommitted_changes_before_Update_at_12_17_2025_5_21_PM_[Changes]" date="1765988508893" recycled="true" deleted="true">
--  <option name="PATH" value="$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Update_at_12_17_2025_5_21_PM_[Changes]/shelved.patch" />
--  <option name="DESCRIPTION" value="Uncommitted changes before Update at 12/17/2025 5:21 PM [Changes]" />
--</changelist>
-\ No newline at end of file
-Index: hrtf_relearning/hrtf/record/record_hrir.py
-IDEA additional info:
-Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
-<+>import matplotlib\r\nmatplotlib.use('tkagg')\r\nimport logging\r\nfrom pathlib import Path\r\nimport copy\r\nfrom datetime import datetime\r\nfrom pynput import keyboard\r\nimport numpy\r\nimport freefield\r\nimport pyfar\r\nimport warnings\r\nimport slab\r\nfrom matplotlib import pyplot as plt\r\nwarnings.filterwarnings(\"ignore\", category=pyfar._utils.PyfarDeprecationWarning)\r\n\r\n\r\n# -------------------------------------------------------------------------\r\n# Global settings\r\n# -------------------------------------------------------------------------\r\nsubject_id = 'kemar_test'\r\noverwrite = False\r\nreference = 'kemar_reference'\r\nn_directions = 1\r\nn_recordings = 20\r\nfs = 48828  # 97656\r\nshow = True\r\nn_samples_out = 256\r\n\r\nslab.set_default_samplerate(fs)\r\nfreefield.set_logger(\"info\")\r\n\r\n\r\n\r\n# -------------------------------------------------------------------------\r\n# High-level: record HRIR for one subject\r\n# -------------------------------------------------------------------------\r\ndef record_hrir(\r\n    subject_id: str, reference: str, n_directions: int = 5, n_recordings: int = 5,\r\n    fs: int = fs, overwrite: bool = False, n_samples_out: int = 256, show: bool = True):\r\n\r\n    hrtf_dir = Path.cwd() / \"data\" / \"hrtf\"\r\n    subject_dir = hrtf_dir / \"rec\" / subject_id\r\n    ref_dir = hrtf_dir / \"rec\" / \"reference\" / reference\r\n\r\n    # 1) in ear recordings\r\n    if (not subject_dir.exists()) or overwrite:\r\n        subject_dir.mkdir(exist_ok=True, parents=True)\r\n        # todo make sure we record 2 channels\r\n        ear_pressure = Recordings.record_dome(n_directions, n_recordings, hp_freq=120, fs=fs)\r\n        ear_pressure.params[\"subject_id\"] = subject_id\r\n        ear_pressure.to_wav(subject_dir, overwrite=overwrite)\r\n    else:\r\n        logging.info(\"Loading subject recordings from wav directory\")\r\n        ear_pressure = Recordings.from_wav(subject_dir)\r\n\r\n    # 2) reference recordings\r\n    if (not ref_dir.exists()) or overwrite:\r\n        logging.info(\"Recording new reference\")\r\n        ref_dir.mkdir(exist_ok=True, parents=True)\r\n        reference_pressure = Recordings.record_dome(n_directions=1, n_recordings=n_recordings, hp_freq=120, fs=fs)\r\n        reference_pressure.params[\"subject_id\"] = reference\r\n        reference_pressure.to_wav(ref_dir, overwrite=overwrite)\r\n    else:\r\n        logging.info(\"Loading reference recordings\")\r\n        reference_pressure = Recordings.from_wav(ref_dir)\r\n\r\n    # plot spectra\r\n    # ear_pressure.plot_spectra()\r\n    # reference_pressure.plot_spectra()\r\n\r\n    # 3) Compute TF (deconvolve recordings with inverted excitation signal)\r\n    # tf_recorded = ear_pressure.compute_tf(n_samp_out=n_samples_out, show=show)\r\n    # tf_reference = reference_pressure.compute_tf(n_samp_out=n_samples_out, show=show)\r\n\r\n    # 4) Equalize HRIR by reference IR\r\n    hrir = equalize(ear_pressure, reference_pressure, n_samples_out=n_samples_out, show=show)\r\n    # hrir = equalize(hrir_recorded, hrir_reference, n_samp_out=n_samp_out, show=show)\r\n    # hrir = equalize_old(ear_pressure, reference_pressure, n_samp_out, show=show)\r\n\r\n    # 5) Low frequency extrapolation\r\n    hrir = lowfreq_extrapolate(hrir, f_extrap=400.0, f_target=150.0, head_radius=0.0875, show=False)\r\n\r\n    # 6) Extend azimuths + add binaural cues (ILD full-band off-midline + ITD align)\r\n    hrir = expand_azimuths_with_binaural_cues(hrir, az_range=(-50, 50), head_radius=0.0875, show=False)\r\n\r\n    # 5) Export to slab.HRTF\r\n    hrir = hrir.to_slab_hrtf(datatype=\"FIR\")\r\n    if show:\r\n        fig, ax = plt.subplots()\r\n        hrir.plot_tf(hrir.cone_sources(0), axis=ax)\r\n    return hrir\r\n\r\n\r\n# -------------------------------------------------------------------------\r\n# Base grid container\r\n# -------------------------------------------------------------------------\r\nclass SpeakerGridBase:\r\n    \"\"\"\r\n    Base container for data defined on the loudspeaker grid.\r\n    Keys are strings like '19_0.0_40.0' → (idx, az, el).\r\n    Values are typically slab.Binaural or slab.Filter.\r\n    \"\"\"\r\n\r\n    def __init__(self, data=None, params=None):\r\n        self.data: dict[str, object] = data or {}\r\n        self.params: dict[str, object] = params or {}\r\n\r\n    # --- dict-like ---------------------------------------------------------\r\n    def __getitem__(self, key):\r\n        \"\"\"\r\n        Access entries in the grid.\r\n\r\n        - grid['19_0.0_40.0'] -> value for that key (dict-style)\r\n        - grid[0]             -> first value in insertion order\r\n        - grid[-1]            -> last value\r\n        - grid[0:3]           -> list of first three values (values only)\r\n        \"\"\"\r\n        # int index -> single value\r\n        if isinstance(key, int):\r\n            values = list(self.data.values())\r\n            try:\r\n                return values[key]  # supports negative indices as usual\r\n            except IndexError as exc:\r\n                raise IndexError(\r\n                    f\"Index {key} out of range for SpeakerGridBase with \"\r\n                    f\"{len(values)} elements.\"\r\n                ) from exc\r\n\r\n        # slice -> list of values\r\n        if isinstance(key, slice):\r\n            values = list(self.data.values())\r\n            return values[key]\r\n\r\n        # everything else -> behave like a normal dict\r\n        return self.data[key]\r\n\r\n    def __setitem__(self, key: str, value: object) -> None:\r\n        self.data[key] = value\r\n\r\n    def __iter__(self):\r\n        return iter(self.data)\r\n\r\n    def items(self):\r\n        return self.data.items()\r\n\r\n    def keys(self):\r\n        return self.data.keys()\r\n\r\n    def values(self):\r\n        return self.data.values()\r\n\r\n    def __len__(self):\r\n        return len(self.data)\r\n\r\n    # --- key helpers -------------------------------------------------------\r\n    @staticmethod\r\n    def parse_key(key: str) -> tuple[int, float, float]:\r\n        parts = key.split(\"_\")\r\n        if len(parts) != 3:\r\n            raise ValueError(f\"Cannot parse key '{key}', expected 'idx_az_el'\")\r\n        idx = int(parts[0])\r\n        az = float(parts[1])\r\n        el = float(parts[2])\r\n        return idx, az, el\r\n\r\n    # --- spatial helpers ---------------------------------------------------\r\n    def get_sources(self, distance: float = 1.4) -> numpy.ndarray:\r\n        coords = []\r\n        for key in self.data.keys():\r\n            _, az, el = self.parse_key(key)\r\n            coords.append([az, el, distance])\r\n        return numpy.array(coords, dtype=\"float16\")\r\n\r\n    def to_wav(self, path: Path | str, overwrite: bool = False) -> None:\r\n        \"\"\"\r\n        Write all entries in self.data to WAV files.\r\n\r\n        Parameters\r\n        ----------\r\n        path : base directory for saving the wav files\r\n        overwrite : if False, existing wav files are kept and skipped.\r\n                    if True, existing wav files are overwritten.\r\n        \"\"\"\r\n        path = Path(path)\r\n        path.mkdir(parents=True, exist_ok=True)\r\n        self.write_params_file(path)  # write recording parameters\r\n        for key, obj in self.data.items():\r\n            if not hasattr(obj, \"write\"):\r\n                raise TypeError(f\"Object for key {key} has no `.write` method: {type(obj)}\")\r\n            fname = path / f\"{key}.wav\"\r\n            if fname.exists() and not overwrite:\r\n                logging.info(f\"Skipping existing file (overwrite=False): {fname}\")\r\n                continue\r\n            obj.write(fname)\r\n\r\n    # --- parameter logging -------------------------------------------------\r\n    def write_params_file(self, path: Path, filename: str = \"params.txt\") -> None:\r\n        \"\"\"\r\n        Write all entries from self.params to a human-readable text file.\r\n        \"\"\"\r\n        path.mkdir(parents=True, exist_ok=True)\r\n        file = path / filename\r\n\r\n        lines = []\r\n        for key, val in self.params.items():\r\n            if isinstance(val, dict):\r\n                lines.append(f\"{key}:\")\r\n                for sk, sv in val.items():\r\n                    lines.append(f\"  {sk}: {sv}\")\r\n            else:\r\n                lines.append(f\"{key}: {val}\")\r\n\r\n        lines += [\r\n            \"\",\r\n            \"Software versions:\",\r\n            f\"  slab:      {getattr(slab, '__version__', 'unknown')}\",\r\n            f\"  pyfar:     {getattr(pyfar, '__version__', 'unknown')}\",\r\n            f\"  freefield: {getattr(freefield, '__version__', 'unknown')}\",\r\n        ]\r\n\r\n        with file.open(\"w\", encoding=\"utf-8\") as f:\r\n            f.write(\"\\n\".join(lines))\r\n\r\n    # --- selection ---------------------------------------------------------\r\n    def select(\r\n        self,\r\n        azimuth: float | tuple[float, float] | None = None,\r\n        elevation: float | tuple[float, float] | None = None,\r\n    ) -> \"SpeakerGridBase\":\r\n        if azimuth is None:\r\n            az_low, az_high = -float(\"inf\"), float(\"inf\")\r\n        elif isinstance(azimuth, (int, float)):\r\n            az_low = az_high = float(azimuth)\r\n        else:\r\n            az_low, az_high = float(min(azimuth)), float(max(azimuth))\r\n\r\n        if elevation is None:\r\n            el_low, el_high = -float(\"inf\"), float(\"inf\")\r\n        elif isinstance(elevation, (int, float)):\r\n            el_low = el_high = float(elevation)\r\n        else:\r\n            el_low, el_high = float(min(elevation)), float(max(elevation))\r\n\r\n        sub = {}\r\n        for key, obj in self.data.items():\r\n            _, az, el = self.parse_key(key)\r\n            if az_low <= az <= az_high and el_low <= el <= el_high:\r\n                sub[key] = obj\r\n\r\n        # copy params reference\r\n        return type(self)(data=sub, params=self.params.copy())\r\n\r\n\r\n# -------------------------------------------------------------------------\r\n# Recordings (binaural in-ear)\r\n# -------------------------------------------------------------------------\r\nclass Recordings(SpeakerGridBase):\r\n    \"\"\"\r\n    Binaural in-ear recordings over the speaker dome.\r\n    Values are `slab.Binaural`.\r\n    \"\"\"\r\n\r\n    def __init__(self, data=None, params=None, signal: slab.Sound | None = None):\r\n        super().__init__(data=data, params=params)\r\n        self.signal = signal\r\n\r\n    @classmethod\r\n    def record_dome(cls, n_directions=5, n_recordings=5, hp_freq=120, fs=48828):\r\n        \"\"\"Record across the dome and return a Recordings object with all parameters stored.\"\"\"\r\n        if freefield.PROCESSORS.mode != \"play_birec\":\r\n            freefield.initialize(\"dome\", \"play_birec\")\r\n\r\n        # excitation signal  # todo 1 - adjust sweep parameters (freq range and ramp) to measure across 120-18 khz\r\n        params = {\"type\": \"slab.Sound.chirp\", \"duration\": 0.2, \"level\": 85,\r\n                  \"from_frequency\": 120, \"to_frequency\": fs/2, \"samplerate\": fs}\r\n        # Orb Audio Mod1 frequency response: 120 Hz - 18 KHz, 5 ms ramp cuts off some frequencies\r\n        signal = slab.Sound.chirp(duration=params[\"duration\"], level=params[\"level\"], samplerate=fs, kind='logarithmic',\r\n                                  from_frequency=params[\"from_frequency\"], to_frequency=params[\"to_frequency\"])\r\n        signal = signal.ramp(when=\"both\", duration=0.001)  # matches the ramp in bi_play_buf.rcx\r\n        signal.params = params\r\n\r\n        speakers_all = freefield.read_speaker_table()\r\n        speakers = cls.get_speakers(speakers_all, azimuth=0, elevation=(50, -37.5))  # omit speaker at -50°\r\n        if len(speakers) < 2:\r\n            raise RuntimeError(\"Need at least two speakers to infer vertical resolution.\")\r\n\r\n        res = abs(speakers[0].elevation - speakers[1].elevation) / n_directions\r\n        min_el = min(spk.elevation for spk in speakers)\r\n\r\n        recordings_dict = {}\r\n        filt = slab.Filter.band(kind=\"hp\", frequency=hp_freq, samplerate=fs)\r\n        [led_speaker] = freefield.pick_speakers(23)  # get object for center speaker LED\r\n\r\n        for n in range(n_directions):\r\n            elevation_step = n * res\r\n            if n_directions > 1: # skip for reference recordings\r\n                freefield.write(tag='bitmask', value=led_speaker.digital_channel,\r\n                                processors=led_speaker.digital_proc)  # illuminate LED\r\n                input(f\"Press Enter when head is at {0 + elevation_step}° elevation ...\")\r\n            for base_spk in speakers:\r\n                spk = copy.deepcopy(base_spk)\r\n                spk.elevation -= elevation_step\r\n                if spk.elevation >= min_el:\r\n                    logging.info(f\"Recording from Speaker {spk.index} at {spk.elevation:.1f}° elevation\")\r\n                    key = f\"{spk.index}_{spk.azimuth}_{spk.elevation}\"\r\n                    rec = cls.record_speaker(spk, signal, n_recordings, fs*2)\r\n                    rec.data -= numpy.mean(rec.data, axis=0)  # remove DC\r\n                    rec = filt.apply(rec)  # highpass filter\r\n                    recordings_dict[key] = rec\r\n            freefield.write(tag='bitmask', value=0, processors=led_speaker.digital_proc)  # turn off LED\r\n        params = {\r\n            \"fs\": fs,\r\n            \"n_recordings\": n_recordings,\r\n            \"n_directions\": n_directions,\r\n            \"signal\": getattr(signal, \"params\", {}),\r\n            \"highpass frequency\": hp_freq,\r\n            \"datetime\": datetime.now().isoformat(),\r\n        }\r\n        return cls(data=recordings_dict, params=params, signal=signal)\r\n\r\n    # --- conversion to IRs --------------------------------------------------\r\n    def compute_tf(self, n_samp_out: int = 256, show: bool = False) -> \"ImpulseResponses\":\r\n        \"\"\"\r\n        Convert this set of recordings to impulse responses.\r\n\r\n        Steps:\r\n        1. Stack all binaural in-ear recordings into a multi channel pyfar.Signal\r\n        2. Compute regularized inverse of the excitation signal\r\n        3. Deconvolve (Y * X^{-1}) to obtain HRIRs\r\n        4. Align group delay relative to a center loudspeaker\r\n        5. Window and crop to a fixed length\r\n        6. Convert to slab.Filter and return an ImpulseResponses object\r\n\r\n        If show is True, a summary figure of all processing steps is plotted.\r\n        \"\"\"\r\n\r\n        # ------------------------------------------------------------------\r\n        # 0) Basic parameters\r\n        # ------------------------------------------------------------------\r\n        if \"fs\" in self.params:\r\n            fs = int(self.params[\"fs\"])\r\n        else:\r\n            from record_hrir import fs as fs_global\r\n            fs = int(fs_global)\r\n\r\n        if not self.data:\r\n            raise ValueError(\"Recordings.compute_tf(): self.data is empty.\")\r\n\r\n        # ------------------------------------------------------------------\r\n        # 1) Convert recordings -> pyfar.Signal\r\n        # ------------------------------------------------------------------\r\n        rec_array = [rec.data.T for rec in self.data.values()]  # (2, n_samples) per rec\r\n        recording = pyfar.Signal(rec_array, fs)\r\n\r\n        # ------------------------------------------------------------------\r\n        # 2) Invert the excitation chirp\r\n        # ------------------------------------------------------------------\r\n        if self.signal is None:\r\n            raise ValueError(\"Recordings.compute_tf(): self.signal is None, \"\r\n                             \"cannot perform deconvolution.\")\r\n        sig = self.signal\r\n        sig_params = self.params.get(\"signal\", {})\r\n        from_f = sig_params.get(\"from_frequency\")\r\n        to_f = sig_params.get(\"to_frequency\")\r\n\r\n        # filter excitation signal, if recordings where filtered\r\n        if \"highpass_frequency\" in self.params:\r\n            hp_freq = self.params.get('highpass_frequency')\r\n            filt = slab.Filter.band(kind=\"hp\", frequency=hp_freq, samplerate=fs)\r\n            sig = filt.apply(sig)\r\n\r\n        excitation = pyfar.Signal(sig.data.T, fs)  # (2, n_samples)\r\n        ref_inv = pyfar.dsp.regularized_spectrum_inversion(\r\n            excitation,\r\n            (from_f, to_f),)\r\n\r\n        # ------------------------------------------------------------------\r\n        # 3) Deconvolve: HRIR = Y * X^{-1}\r\n        # ------------------------------------------------------------------\r\n        hrir_deconvolved = recording * ref_inv\r\n\r\n        # ------------------------------------------------------------------\r\n        # 4) Align group delay\r\n        # ------------------------------------------------------------------\r\n        hrir_shifted = pyfar.dsp.time_shift(hrir_deconvolved, 2000, unit=\"samples\")\r\n\r\n        center_key = \"23_0.0_0.0\"  # adjust to your actual center key\r\n        keys_list = list(self.data.keys())\r\n        if center_key in self.data:\r\n            center_idx = keys_list.index(center_key)\r\n        else:\r\n            logging.warning(\r\n                \"Center key %s not found in recordings, using first entry (%s) instead.\",\r\n                center_key, keys_list[0]\r\n            )\r\n            center_idx = 0\r\n\r\n        center_onset = pyfar.dsp.find_impulse_response_start(\r\n            hrir_shifted[center_idx], threshold=15\r\n        )\r\n        center_onset = float(numpy.min(center_onset))\r\n        center_onset_s = center_onset / hrir_shifted.sampling_rate\r\n\r\n        desired_onset_s = 0.001\r\n        shift_s = desired_onset_s - center_onset_s\r\n        hrir_aligned = pyfar.dsp.time_shift(hrir_shifted, shift_s, unit=\"s\")\r\n\r\n        # ------------------------------------------------------------------\r\n        # 5) Window around the earliest onset in the whole dataset\r\n        # ------------------------------------------------------------------\r\n        onsets = pyfar.dsp.find_impulse_response_start(hrir_aligned, threshold=10)\r\n        onsets_min = numpy.min(onsets) / hrir_aligned.sampling_rate  # seconds\r\n\r\n        times = (onsets_min - .00025,  # start of fade-in\r\n                 onsets_min,  # end if fade-in\r\n                 onsets_min + .0048,  # start of fade_out\r\n                 onsets_min + .0058)  # end of_fade_out\r\n\r\n        hrir_windowed, window = pyfar.dsp.time_window(\r\n            hrir_aligned,\r\n            times,\r\n            \"hann\",\r\n            unit=\"s\",\r\n            crop=\"end\",\r\n            return_window=True,\r\n        )\r\n\r\n        # cut to final length\r\n        times_samples = [0, 10, 246, n_samp_out-1]\r\n        hrir_final = pyfar.dsp.time_window(\r\n            hrir_windowed,\r\n            times_samples,\r\n            \"hann\",\r\n            crop=\"end\",\r\n        )\r\n        # hrir_final = hrir_windowed\r\n\r\n        # ------------------------------------------------------------------\r\n        # 6) Optionally: plot processing steps\r\n        # ------------------------------------------------------------------\r\n        if show:\r\n            _plot_processing_pyfar(\r\n                excitation=excitation,\r\n                ref_inv=ref_inv,\r\n                recording=recording,\r\n                hrir_deconvolved=hrir_deconvolved,\r\n                hrir_shifted=hrir_shifted,\r\n                hrir_aligned=hrir_aligned,\r\n                hrir_windowed=hrir_windowed,\r\n                hrir_final=hrir_final,\r\n                window=window,\r\n                center_idx=center_idx,\r\n            )\r\n\r\n        # ------------------------------------------------------------------\r\n        # 7) Convert to slab.Filter and wrap in ImpulseResponses\r\n        # ------------------------------------------------------------------\r\n        params = {\r\n            \"fs\": fs,\r\n            \"signal\": self.params.get(\"signal\", {}),\r\n            \"n_samp\": n_samp_out,\r\n            \"date\": datetime.now().isoformat(),\r\n        }\r\n\r\n        out = copy.deepcopy(self)\r\n        for key, h in zip(out.data.keys(), hrir_final):\r\n            out.data[key] = slab.Filter(\r\n                data=h.time.T,\r\n                samplerate=fs,\r\n                fir=\"IR\",\r\n            )\r\n\r\n        return ImpulseResponses(data=out.data, params=params)\r\n\r\n    @staticmethod\r\n    def record_speaker(speaker, signal: slab.Sound, n_recordings: int, fs: int) -> slab.Binaural:\r\n        recordings = []\r\n        for _ in range(n_recordings):\r\n            recordings.append(\r\n                freefield.play_and_record(\r\n                    speaker=speaker,\r\n                    sound=signal,\r\n                    compensate_delay=True,\r\n                    equalize=False,\r\n                    recording_samplerate=fs,\r\n                )\r\n            )  # todo test this to make sure both channels are recorded!\r\n        return slab.Binaural(numpy.mean(recordings, axis=0))\r\n\r\n    @staticmethod\r\n    def get_speakers(speakers, azimuth=None, elevation=None):\r\n        out = []\r\n        if azimuth is None:\r\n            az_low, az_high = -float(\"inf\"), float(\"inf\")\r\n        elif isinstance(azimuth, (int, float)):\r\n            az_low = az_high = float(azimuth)\r\n        else:\r\n            az_low, az_high = float(min(azimuth)), float(max(azimuth))\r\n\r\n        if elevation is None:\r\n            el_low, el_high = -float(\"inf\"), float(\"inf\")\r\n        elif isinstance(elevation, (int, float)):\r\n            el_low = el_high = float(elevation)\r\n        else:\r\n            el_low, el_high = float(min(elevation)), float(max(elevation))\r\n\r\n        for spk in speakers:\r\n            if az_low <= spk.azimuth <= az_high and el_low <= spk.elevation <= el_high:\r\n                out.append(spk)\r\n        return out\r\n\r\n        # --- I/O: always Binaural --------------------------------------\r\n\r\n    @classmethod\r\n    def from_wav(cls, path: Path | str):\r\n        \"\"\"\r\n        Load binaural recordings from wav and params.txt into a Recordings object.\r\n        Also reconstructs the excitation signal if params contain it.\r\n        \"\"\"\r\n        path = Path(path)\r\n        data: dict[str, slab.Binaural] = {}\r\n        for wav in path.glob(\"*.wav\"):\r\n            data[wav.stem] = slab.Binaural(wav)\r\n        if not data:\r\n            raise FileNotFoundError(f\"No .wav files found in {path}\")\r\n        data = dict(sorted(data.items(), key=lambda kv: (float(kv[0].rsplit(\"_\", 2)[-1]))))  # sort by elevation\r\n\r\n        params = parse_params_file(path)\r\n        signal = None\r\n        sig_params = params.get(\"signal\", {})\r\n        if isinstance(sig_params, dict) and sig_params.get(\"type\") == \"slab.Sound.chirp\":\r\n            dur = sig_params.get(\"duration\", 0.2)\r\n            level = sig_params.get(\"level\", 90)\r\n            fs_sig = sig_params.get(\"samplerate\", fs)  # fall back to global fs\r\n            f_start = sig_params.get(\"from_frequency\", 50)\r\n            f_end = sig_params.get(\"to_frequency\", fs_sig / 2)\r\n\r\n            signal = slab.Sound.chirp(\r\n                duration=dur,\r\n                level=level,\r\n                samplerate=fs_sig,\r\n                from_frequency=f_start,\r\n                to_frequency=f_end,\r\n            )\r\n            # if you always ramped originally, you can ramp again here:\r\n            signal = signal.ramp(when=\"both\", duration=0.01)\r\n            signal.params = sig_params\r\n\r\n        return cls(data=data, params=params, signal=signal)\r\n\r\n    # --- plotting of spectra -----------------------------------------------\r\n    def spectrum(\r\n            self,\r\n            azimuth=0,\r\n            linesep=20,\r\n            xscale=\"linear\",\r\n            axis=None,\r\n    ):\r\n        \"\"\"\r\n        Waterfall plot of left + right ear spectra from in-ear recordings.\r\n        Elevations determine vertical offset (one curve per elevation).\r\n        Left ear = dark gray, right = lighter gray.\r\n\r\n        Parameters\r\n        ----------\r\n        xlim : tuple\r\n            Frequency axis limits.\r\n        n_bins : int or None\r\n            FFT resolution for spectrum().\r\n        linesep : float\r\n            Vertical separation in dB between stacked spectra.\r\n        xscale : 'linear' or 'log'\r\n            Frequency axis scaling.\r\n        show : bool\r\n            Show the plot immediately.\r\n        axis : matplotlib axis or None\r\n            Insert plot into an existing axis.\r\n        \"\"\"\r\n        xlim = (self.params['signal']['from_frequency'], self.params['signal']['to_frequency'])\r\n        # Create axis\r\n        if axis is None:\r\n            fig, axis = plt.subplots(figsize=(7, 6))\r\n        else:\r\n            fig = axis.figure\r\n\r\n        keys = list(self.data.keys())\r\n\r\n        elevations = []\r\n        specs_L = []  # left ear spectra\r\n        specs_R = []  # right ear spectra\r\n        freqs_saved = None\r\n\r\n        # ------------------------------------------------------------------\r\n        # Extract spectra from all recordings\r\n        # ------------------------------------------------------------------\r\n        for key in keys:\r\n            _, _, el = self.parse_key(key)\r\n            rec = self.data[key]  # slab.Binaural\r\n\r\n            # left ear\r\n            Hl, freqs = rec.channel(0).spectrum(show=False)\r\n            # right ear\r\n            Hr, _ = rec.channel(1).spectrum(show=False)\r\n\r\n            if freqs_saved is None:\r\n                freqs_saved = freqs\r\n\r\n            elevations.append(el)\r\n            specs_L.append(Hl)\r\n            specs_R.append(Hr)\r\n\r\n        elevations = numpy.asarray(elevations)\r\n        specs_L = numpy.asarray(specs_L)\r\n        specs_R = numpy.asarray(specs_R)\r\n\r\n        # baseline correction (compute common baseline from original data)\r\n        baseline = numpy.mean((specs_L + specs_R) / 2)\r\n\r\n        specs_L = specs_L - baseline\r\n        specs_R = specs_R - baseline\r\n\r\n        # ------------------------------------------------------------------\r\n        # Sort by elevation\r\n        # ------------------------------------------------------------------\r\n        idx = numpy.argsort(elevations)\r\n        elevations = elevations[idx]\r\n        specs_L = specs_L[idx]\r\n        specs_R = specs_R[idx]\r\n\r\n        # Compute vertical offsets\r\n        vlines = numpy.arange(len(elevations)) * (linesep + 20)\r\n\r\n        # ------------------------------------------------------------------\r\n        # Plot waterfall curves\r\n        # ------------------------------------------------------------------\r\n        for i, (Hl, Hr) in enumerate(zip(specs_L, specs_R)):\r\n            axis.plot(\r\n                freqs_saved, Hl + vlines[i],\r\n                color=\"0.25\", linewidth=0.8, alpha=0.9, label=\"Left\" if i == 0 else None,\r\n            )\r\n            axis.plot(\r\n                freqs_saved, Hr + vlines[i],\r\n                color=\"0.65\", linewidth=0.8, alpha=0.9, label=\"Right\" if i == 0 else None,\r\n            )\r\n\r\n        # ------------------------------------------------------------------\r\n        # Elevation labels\r\n        # ------------------------------------------------------------------\r\n        ticks = vlines[::2]\r\n        labels = elevations[::2].astype(int)\r\n\r\n        axis.set_yticks(ticks)\r\n        axis.set_yticklabels(labels)\r\n        axis.set_ylabel(\"Elevation (°)\")\r\n\r\n        # ------------------------------------------------------------------\r\n        # dB scale bar (height = linesep)\r\n        # ------------------------------------------------------------------\r\n        scale_x = xlim[0] + 300\r\n        scale_y0 = vlines[-1] + 40\r\n        scale_y1 = scale_y0 + linesep\r\n\r\n        axis.plot([scale_x, scale_x], [scale_y0, scale_y1],\r\n                  color=\"0.1\", linewidth=1.2)\r\n        axis.text(\r\n            scale_x + 90,\r\n            scale_y0 + linesep / 2,\r\n            f\"{linesep} dB\",\r\n            va=\"center\", fontsize=7, color=\"0.1\"\r\n        )\r\n\r\n        # ------------------------------------------------------------------\r\n        # Formatting utilities\r\n        # ------------------------------------------------------------------\r\n        axis.set_xlim(xlim)\r\n        axis.set_xscale(xscale)\r\n\r\n        # Format frequency labels as kHz\r\n        axis.xaxis.set_major_formatter(\r\n            matplotlib.ticker.FuncFormatter(lambda x, pos: f\"{int(x / 1000)}\")\r\n        )\r\n        axis.set_xlabel(\"Frequency [kHz]\")\r\n\r\n        axis.grid(axis=\"y\", linestyle=\":\", linewidth=0.3, alpha=0.5)\r\n        axis.legend(loc=\"upper right\", fontsize=7)\r\n        plt.show()\r\n        return fig\r\n\r\n\r\n# -------------------------------------------------------------------------\r\n# Impulse Responses (slab.Filter grid)\r\n# -------------------------------------------------------------------------\r\nclass ImpulseResponses(SpeakerGridBase):\r\n    \"\"\"\r\n    Directional impulse responses over the speaker dome.\r\n    Values are `slab.Filter` (FIR).\r\n    \"\"\"\r\n    def __init__(self, data=None, params=None):\r\n        super().__init__(data=data, params=params)\r\n\r\n    def apply_spherical_head_lowfreq(\r\n            self,\r\n            f_extrap: float = 400.0,\r\n            f_target: float = 150.0,\r\n            head_radius: float | None = None,\r\n            onset_threshold_db: float = 20.0,\r\n            center_az: float = 0.0,\r\n            az_tol: float = 1e-6,\r\n    ) -> \"ImpulseResponses\":\r\n        \"\"\"\r\n        Use a spherical head model as\r\n\r\n        - low-frequency magnitude anchor (LF extrapolation, externalisation),\r\n        - full-band ILD template for off-midline azimuths,\r\n        - ITD target (via time shift of the whole IR).\r\n\r\n        Pipeline inside this method:\r\n\r\n        1) Convert current IRs (slab.Filter) -> pyfar.Signal (hrir_meas).\r\n        2) Build pyfar.Coordinates from the source grid and compute spherical-\r\n           head HRTFs (shtf) for the same positions.\r\n        3) LOW-FREQ MAGNITUDE EXTRAPOLATION (notebook-style):\r\n           - anchor magnitudes at 0 Hz and f_target from spherical head,\r\n           - use measured magnitudes for f >= f_extrap,\r\n           - interpolate smoothly over the full frequency axis,\r\n           - keep measured phase.\r\n        4) FULL-BAND ILD SHAPING (off-midline only):\r\n           - for each non-midline azimuth, impose spherical-head ILD per\r\n             frequency bin, preserving the measured average level.\r\n        5) ITD ALIGNMENT:\r\n           - compute ITD from spherical head and from the modified HRIRs,\r\n           - time-shift the entire right-ear IR per position so ITD matches\r\n             the spherical head across the band.\r\n        6) Convert back to slab.Filter and store in self.data.\r\n\r\n        Parameters\r\n        ----------\r\n        f_extrap\r\n            Frequency (Hz) above which measured magnitude is trusted. Below\r\n            this, magnitude is extrapolated between spherical head and\r\n            measured data.\r\n        f_target\r\n            Frequency (Hz) at which the spherical-head magnitude is used as a\r\n            second anchor for the low-frequency extrapolation.\r\n        head_radius\r\n            Optional head radius (meters) for spherical_head(). If None,\r\n            the default head from spherical_head.py is used.\r\n        onset_threshold_db\r\n            Threshold in dB for onset detection when estimating ITD.\r\n        center_az\r\n            Azimuth (deg) considered the vertical midline (e.g. 0°).\r\n        az_tol\r\n            Tolerance (deg) when deciding if a source is on the midline.\r\n\r\n        Returns\r\n        -------\r\n        self : ImpulseResponses\r\n            Modified in-place and returned for chaining.\r\n        \"\"\"\r\n\r\n        fs = int(self.params[\"fs\"])\r\n\r\n        # --- 1) Convert ImpulseResponses -> pyfar.Signal -------------------\r\n        keys = list(self.data.keys())\r\n        if not keys:\r\n            raise ValueError(\"apply_spherical_head_lowfreq: no IRs in self.data\")\r\n\r\n        filters = [self.data[k] for k in keys]  # slab.Filter\r\n        # slab.Filter.data: (n_samples, n_channels)\r\n        # -> (n_pos, n_ears, n_samples)\r\n        data = numpy.stack([filt.data.T for filt in filters], axis=0)\r\n        hrir_meas = pyfar.Signal(data, fs)\r\n\r\n        # --- 2) Build pyfar.Coordinates from your grid ---------------------\r\n        # get_sources() should return [az, el, r] in degrees / meters\r\n        sources = self.get_sources()  # shape (n_pos, 3)\r\n        coords = pyfar.Coordinates(\r\n            sources[:, 0],  # azimuth in deg\r\n            sources[:, 1],  # elevation in deg\r\n            sources[:, 2],  # radius in m\r\n            domain=\"sph\",\r\n            convention = 'top_elev',\r\n            unit=\"deg\",\r\n        )\r\n\r\n        # --- 3) Spherical-head HRTFs for same positions --------------------\r\n        shtf = _spherical_head_for(coords, hrir_meas.n_samples, fs, head_radius)\r\n\r\n        # --- 4) Low-frequency magnitude extrapolation (notebook-style) -----\r\n        freqs = hrir_meas.frequencies  # (n_freqs,)\r\n        mag_meas = numpy.abs(hrir_meas.freq)\r\n        phase_meas = numpy.angle(hrir_meas.freq)\r\n        mag_sph = numpy.abs(shtf.freq)\r\n\r\n        # frequencies we trust from the measurement\r\n        mask_extrap = freqs >= f_extrap\r\n\r\n        # frequency below which magnitude is assumed constant (second anchor)\r\n        f_target_idx = hrir_meas.find_nearest_frequency(f_target)\r\n        f_target = freqs[f_target_idx]  # snap to exact grid\r\n\r\n        # valid (trusted) measurement magnitudes and freqs\r\n        freqs_valid = freqs[mask_extrap]  # (n_valid,)\r\n        mag_valid = mag_meas[..., mask_extrap]  # (n_pos, n_ears, n_valid)\r\n\r\n        # spherical head magnitudes at anchors\r\n        mag0 = mag_sph[..., 0:1]  # 0 Hz\r\n        mag_ft = mag_sph[..., f_target_idx:f_target_idx + 1]  # f_target\r\n\r\n        # concatenate along frequency axis: 0 Hz, f_target, f >= f_extrap\r\n        mag_anchor = numpy.concatenate((mag0, mag_ft, mag_valid), axis=-1)\r\n        freqs_anchor = numpy.concatenate((\r\n            numpy.array([0.0]),\r\n            numpy.array([f_target]),\r\n            freqs_valid,\r\n        ))\r\n\r\n        # interpolate magnitude over full freq grid\r\n        mag_interp = numpy.empty_like(hrir_meas.freq)\r\n        for src in range(mag_anchor.shape[0]):\r\n            for ear in range(mag_anchor.shape[1]):\r\n                mag_interp[src, ear] = numpy.interp(\r\n                    freqs,\r\n                    freqs_anchor,\r\n                    mag_anchor[src, ear],\r\n                )\r\n\r\n        # apply new magnitude, keep measured phase for now\r\n        hrir_meas.freq = mag_interp * numpy.exp(1j * phase_meas)\r\n\r\n        # --- 5) Full-band ILD shaping for off-midline azimuths ------------\r\n        H_meas = hrir_meas.freq  # updated complex HRTFs\r\n        mag_meas = numpy.abs(H_meas)  # updated magnitudes\r\n        phase_meas = numpy.angle(H_meas)  # updated phases\r\n        mag_head = mag_sph  # spherical-head magnitudes\r\n\r\n        n_pos, n_ears, n_freqs = mag_meas.shape\r\n        if n_ears != 2:\r\n            raise ValueError(\"apply_spherical_head_lowfreq expects binaural data (2 ears).\")\r\n\r\n        az = sources[:, 0]\r\n        is_midline = numpy.abs(az - center_az) <= az_tol\r\n\r\n        mag_new = mag_meas.copy()\r\n\r\n        for i in range(n_pos):\r\n            if is_midline[i]:\r\n                # keep original ILD on the vertical midline\r\n                continue\r\n\r\n            # spherical head ILD ratio R/L\r\n            mag_head_L = mag_head[i, 0, :]\r\n            mag_head_R = mag_head[i, 1, :]\r\n            r = mag_head_R / numpy.maximum(mag_head_L, 1e-12)  # R/L\r\n\r\n            # average magnitude from measured HRTF (power average)\r\n            mag_L_meas = mag_meas[i, 0, :]\r\n            mag_R_meas = mag_meas[i, 1, :]\r\n            A = numpy.sqrt((mag_L_meas ** 2 + mag_R_meas ** 2) / 2.0)\r\n\r\n            # new magnitudes: preserve A, enforce ILD ratio r\r\n            mL = A * numpy.sqrt(2.0 / (1.0 + r ** 2))\r\n            mR = r * mL\r\n\r\n            mag_new[i, 0, :] = mL\r\n            mag_new[i, 1, :] = mR\r\n\r\n        # rebuild complex spectrum with new magnitudes and original phase\r\n        H_new = mag_new * numpy.exp(1j * phase_meas)\r\n        hrir_meas.freq = H_new\r\n\r\n        # --- 6) ITD alignment: impose spherical-head ITD via time shift ----\r\n        # force both into time domain (no iteration over Signal)\r\n        _ = shtf.time\r\n        _ = hrir_meas.time\r\n\r\n        # onsets in samples: (n_pos, n_ears)\r\n        onsets_model = pyfar.dsp.find_impulse_response_start(\r\n            shtf, threshold=onset_threshold_db\r\n        )\r\n        onsets_meas = pyfar.dsp.find_impulse_response_start(\r\n            hrir_meas, threshold=onset_threshold_db\r\n        )\r\n\r\n        # use numpy arrays for signal data to avoid domain-iteration issues\r\n        time_data = hrir_meas.time  # (n_pos, n_ears, n_samples)\r\n        time_data_shifted = numpy.empty_like(time_data)\r\n\r\n        for i in range(time_data.shape[0]):  # over positions\r\n            onset_m_L = onsets_model[i, 0]\r\n            onset_m_R = onsets_model[i, 1]\r\n            onset_h_L = onsets_meas[i, 0]\r\n            onset_h_R = onsets_meas[i, 1]\r\n\r\n            itd_model = (onset_m_R - onset_m_L) / fs\r\n            itd_meas = (onset_h_R - onset_h_L) / fs\r\n            delta_itd = itd_model - itd_meas\r\n\r\n            # keep left ear fixed, shift right ear by delta_itd\r\n            time_data_shifted[i, 0, :] = time_data[i, 0, :]\r\n\r\n            sig_r = pyfar.Signal(time_data[i, 1:2, :], fs)  # (1, n_samples)\r\n            sig_r_shifted = pyfar.dsp.time_shift(sig_r, delta_itd, unit=\"s\")\r\n            time_data_shifted[i, 1, :] = sig_r_shifted.time[0]\r\n\r\n        # --- 7) Write back to self.data as slab.Filter --------------------\r\n        for key, sig_time in zip(keys, time_data_shifted):\r\n            # sig_time: (n_ears, n_samples) -> slab.Filter expects (n_samples, n_ears)\r\n            self.data[key] = slab.Filter(\r\n                data=sig_time.T,\r\n                samplerate=fs,\r\n                fir=\"IR\",\r\n            )\r\n\r\n        # bookkeeping\r\n        self.params.setdefault(\"spherical_head\", {})\r\n        self.params[\"spherical_head\"].update(\r\n            {\r\n                \"f_extrap\": float(f_extrap),\r\n                \"f_target\": float(f_target),\r\n                \"head_radius\": float(head_radius) if head_radius is not None else None,\r\n                \"onset_threshold_db\": float(onset_threshold_db),\r\n                \"center_az\": float(center_az),\r\n                \"az_tol\": float(az_tol),\r\n                \"date\": datetime.now().isoformat(),\r\n            }\r\n        )\r\n\r\n        return self\r\n\r\n    # --- export to slab.HRTF ----------------------------------------------\r\n    def to_slab_hrtf(\r\n        self,\r\n        fs: int | None = None,\r\n        datatype: str = \"FIR\",\r\n    ) -> slab.HRTF:\r\n        \"\"\"\r\n        Convert this ImpulseResponses object into a slab.HRTF.\r\n\r\n        Assumes that self.data is a dict mapping keys like\r\n        '23_0.0_40.0' → slab.Filter with shape (n_samples, n_channels).\r\n\r\n        The resulting HRTF has shape (n_positions, n_samples, n_channels)\r\n        and sources from self.get_sources().\r\n\r\n        Parameters\r\n        ----------\r\n        fs\r\n            Samplerate for the HRTF. If None, tries self.params[\"fs\"],\r\n            then the samplerate of the first Filter.\r\n        datatype\r\n            Passed to slab.HRTF (e.g. 'FIR').\r\n\r\n        Returns\r\n        -------\r\n        hrtf : slab.HRTF\r\n        \"\"\"\r\n        if not self.data:\r\n            raise ValueError(\"to_slab_hrtf: no filters in self.data\")\r\n\r\n        # samplerate\r\n        if fs is None:\r\n            if \"fs\" in self.params:\r\n                fs = int(self.params[\"fs\"])\r\n            else:\r\n                # fall back to first filter's samplerate\r\n                first_key = next(iter(self.data.keys()))\r\n                fs = int(self.data[first_key].samplerate)\r\n\r\n        # ensure a stable order: use keys list once for data and coordinates\r\n        keys = list(self.data.keys())\r\n\r\n        # stack filters: (n_positions, n_samples, n_channels)\r\n        data = numpy.stack([self.data[k].data for k in keys], axis=0)\r\n\r\n        # sources: (n_positions, 3) -> [az, el, r]\r\n        # uses the same internal order as self.data, so things stay aligned\r\n        sources = self.get_sources()\r\n\r\n        hrir = slab.HRTF(\r\n            data=data,\r\n            sources=sources,\r\n            samplerate=fs,\r\n            datatype=datatype,\r\n        )\r\n\r\n        return hrir\r\n\r\n    @classmethod\r\n    def from_wav(cls, path: Path | str, fs: int | None = None, meta: dict | None = None):\r\n        \"\"\"\r\n        Load IRs from WAV into slab.Filter objects.\r\n        \"\"\"\r\n        path = Path(path)\r\n        data: dict[str, slab.Filter] = {}\r\n        for wav in path.glob(\"*.wav\"):\r\n            snd = slab.Binaural(wav)  # or slab.Sound\r\n            data[wav.stem] = slab.Filter(data=snd.data, samplerate=snd.samplerate, fir=\"IR\")\r\n        if not data:\r\n            raise FileNotFoundError(f\"No .wav files found in {path}\")\r\n        if fs is None:\r\n            first = next(iter(data.values()))\r\n            fs = first.samplerate\r\n        return cls(data=data, fs=fs, meta=meta or {})\r\n\r\n    # --- plotting -----------------------------------------------------------\r\n    def plot(self, kind: str = \"tf\"):\r\n        \"\"\"\r\n        Plot TF or IRs offset by elevation.\r\n        \"\"\"\r\n        from matplotlib import pyplot as plt\r\n\r\n        fig, ax = plt.subplots()\r\n\r\n        for key, ir in self.data.items():\r\n            _, _, el = self.parse_key(key)\r\n            if kind.upper() == \"TF\":\r\n                _ = ir.tf(show=True, axis=ax)\r\n            else:\r\n                ax.plot(ir.data)\r\n            line = ax.lines[-1]\r\n            x, y = line.get_xdata(), line.get_ydata()\r\n            line.set_ydata(y + el)\r\n            line.set_label(f\"el={el:.1f}°\")\r\n\r\n        if kind.upper() == \"TF\":\r\n            ax.set_xlim([2e3, 18e3])\r\n            ax.set_xscale(\"linear\")\r\n            ax.set_xlabel(\"Frequency [Hz]\")\r\n            ax.set_ylim(80, -80)\r\n        else:\r\n            ax.set_xlabel(\"Samples\")\r\n\r\n        ax.set_ylabel(\"Amplitude (offset by elevation)\")\r\n        ax.set_title(f\"Impulse responses ({kind.upper()})\")\r\n        ax.legend(title=\"Elevation (°)\")\r\n        plt.show()\r\n\r\n    # --- plotting of transfer functions -----------------------------------------------\r\n    def tf(\r\n            self,\r\n            azimuth=0,\r\n            linesep=20,\r\n            xscale=\"log\",\r\n            axis=None,\r\n    ):\r\n        \"\"\"\r\n        Waterfall plot of left + right ear spectra from in-ear recordings.\r\n        Elevations determine vertical offset (one curve per elevation).\r\n        Left ear = dark gray, right = lighter gray.\r\n\r\n        Parameters\r\n        ----------\r\n        xlim : tuple\r\n            Frequency axis limits.\r\n        n_bins : int or None\r\n            FFT resolution for spectrum().\r\n        linesep : float\r\n            Vertical separation in dB between stacked spectra.\r\n        xscale : 'linear' or 'log'\r\n            Frequency axis scaling.\r\n        show : bool\r\n            Show the plot immediately.\r\n        axis : matplotlib axis or None\r\n            Insert plot into an existing axis.\r\n        \"\"\"\r\n        xlim = (self.params['signal']['from_frequency'], self.params['signal']['to_frequency'])\r\n        # Create axis\r\n        if axis is None:\r\n            fig, axis = plt.subplots(figsize=(7, 6))\r\n        else:\r\n            fig = axis.figure\r\n\r\n        keys = list(self.data.keys())\r\n\r\n        elevations = []\r\n        specs_L = []  # left ear spectra\r\n        specs_R = []  # right ear spectra\r\n        freqs_saved = None\r\n\r\n        # ------------------------------------------------------------------\r\n        # Extract spectra from all recordings\r\n        # ------------------------------------------------------------------\r\n        for key in keys:\r\n            _, _, el = self.parse_key(key)\r\n            filt = self.data[key]  # slab.Binaural\r\n\r\n            # left ear\r\n            freqs, Hl = filt.channel(0).tf(show=False)\r\n            # right ear\r\n            _, Hr = filt.channel(1).tf(show=False)\r\n\r\n            if freqs_saved is None:\r\n                freqs_saved = freqs\r\n\r\n            elevations.append(el)\r\n            specs_L.append(Hl)\r\n            specs_R.append(Hr)\r\n\r\n        elevations = numpy.asarray(elevations)\r\n        specs_L = numpy.asarray(specs_L)\r\n        specs_R = numpy.asarray(specs_R)\r\n\r\n        # baseline correction (compute common baseline from original data)\r\n        baseline = numpy.mean((specs_L + specs_R) / 2)\r\n\r\n        specs_L = specs_L - baseline\r\n        specs_R = specs_R - baseline\r\n\r\n        # ------------------------------------------------------------------\r\n        # Sort by elevation\r\n        # ------------------------------------------------------------------\r\n        idx = numpy.argsort(elevations)\r\n        elevations = elevations[idx]\r\n        specs_L = specs_L[idx]\r\n        specs_R = specs_R[idx]\r\n\r\n        # Compute vertical offsets\r\n        vlines = numpy.arange(len(elevations)) * (linesep + 20)\r\n\r\n        # ------------------------------------------------------------------\r\n        # Plot waterfall curves\r\n        # ------------------------------------------------------------------\r\n        for i, (Hl, Hr) in enumerate(zip(specs_L, specs_R)):\r\n            axis.plot(\r\n                freqs_saved, Hl + vlines[i],\r\n                color=\"0.25\", linewidth=0.8, alpha=0.9, label=\"Left\" if i == 0 else None,\r\n            )\r\n            axis.plot(\r\n                freqs_saved, Hr + vlines[i],\r\n                color=\"0.65\", linewidth=0.8, alpha=0.9, label=\"Right\" if i == 0 else None,\r\n            )\r\n\r\n        # ------------------------------------------------------------------\r\n        # Elevation labels\r\n        # ------------------------------------------------------------------\r\n        ticks = vlines[::2]\r\n        labels = elevations[::2].astype(int)\r\n\r\n        axis.set_yticks(ticks)\r\n        axis.set_yticklabels(labels)\r\n        axis.set_ylabel(\"Elevation (°)\")\r\n\r\n        # ------------------------------------------------------------------\r\n        # dB scale bar (height = linesep)\r\n        # ------------------------------------------------------------------\r\n        scale_x = xlim[0] + 300\r\n        scale_y0 = vlines[-1] + 40\r\n        scale_y1 = scale_y0 + linesep\r\n\r\n        axis.plot([scale_x, scale_x], [scale_y0, scale_y1],\r\n                  color=\"0.1\", linewidth=1.2)\r\n        axis.text(\r\n            scale_x + 90,\r\n            scale_y0 + linesep / 2,\r\n            f\"{linesep} dB\",\r\n            va=\"center\", fontsize=7, color=\"0.1\"\r\n        )\r\n\r\n        # ------------------------------------------------------------------\r\n        # Formatting utilities\r\n        # ------------------------------------------------------------------\r\n        axis.set_xlim(xlim)\r\n        axis.set_xscale(xscale)\r\n        if xscale == \"log\":\r\n            axis.set_xscale(\"log\")\r\n            # optionally: let matplotlib choose ticks/formatter\r\n            axis.xaxis.set_minor_locator(matplotlib.ticker.LogLocator(base=10.0, subs=\"all\"))\r\n            axis.xaxis.set_minor_formatter(matplotlib.ticker.LogFormatter(base=10.0,\r\n                                                                          labelOnlyBase=False))\r\n            axis.grid(axis='x', which='both', linestyle=':', linewidth=0.3, alpha=1)\r\n            axis.set_xticks([20, 40, 60, 100, 200, 400, 600, 1000, 2e3, 4e3, 6e3, 10e3, 20e3])\r\n            axis.set_xticklabels([20,40,60,100,200,400,600,'1k','2k','4k','6k','10k','20k'])\r\n            axis.set_xlim(1e3, 18e3)  # works better\r\n\r\n        # axis.set_xscale(xscale)\r\n        # # Format frequency labels as kHz\r\n        # axis.xaxis.set_major_formatter(\r\n        #     matplotlib.ticker.FuncFormatter(lambda x, pos: f\"{int(x / 1000)}\")\r\n        # )\r\n        # axis.set_xlabel(\"Frequency [kHz]\")\r\n\r\n        axis.grid(axis=\"y\", linestyle=\":\", linewidth=0.3, alpha=1)\r\n        axis.legend(loc=\"upper right\", fontsize=7)\r\n        plt.show()\r\n        return fig\r\n\r\n\r\n# -------------------------------------------------------------------------\r\n# HRTF processing\r\n# -------------------------------------------------------------------------\r\ndef equalize(\r\n    recorded: ImpulseResponses | Recordings,\r\n    reference: ImpulseResponses | Recordings,\r\n    n_samples_out: int = 256,\r\n    show: bool = False,\r\n) -> ImpulseResponses:\r\n    \"\"\"\r\n    Equalize IRs (per loudspeaker) using reference measurements.\r\n\r\n    Steps:\r\n    1. Convert recorded IRs (slab.Filter) to pyfar.Signal objects\r\n    2. For each loudspeaker ID:\r\n       - pick matching reference IR\r\n       - remove DC\r\n       - compute regularized inverse of the reference spectrum\r\n       - convolve all IRs from this loudspeaker with the inverse\r\n    3. Pack all equalized IRs into a single pyfar.Signal\r\n    4. Time-align using the central loudspeaker (23_0.0_0.0) to 1 ms\r\n    5. Window all HRIRs\r\n    6. Convert back to ImpulseResponses (slab.Filter grid)\r\n    7. Optionally plot intermediate steps (show=True)\r\n    \"\"\"\r\n    logging.info(\"Applying equalization\")\r\n\r\n    signal_params = recorded.params[\"signal\"]\r\n    fs = int(recorded.params[\"fs\"])\r\n    from_f = signal_params[\"from_frequency\"]\r\n    to_f = signal_params[\"to_frequency\"]\r\n    center_key = \"23_0.0_0.0\"\r\n    # save the center loudspeaker’s reference + inverse for plotting\r\n    center_ref = None\r\n    center_ref_inv = None\r\n\r\n    # ------------------------------------------------------------------\r\n    # 1) Convert recorded HRIRs to pyfar.Signal\r\n    # ------------------------------------------------------------------\r\n    equalized = ImpulseResponses()\r\n    for key, filt in recorded.items():\r\n        # slab.Filter data: (n_samples, n_channels)\r\n        equalized[key] = pyfar.Signal(filt.data.T, filt.samplerate)\r\n\r\n    # ------------------------------------------------------------------\r\n    # 2) Loudspeaker-wise equalization using reference recordings\r\n    # ------------------------------------------------------------------\r\n    # speaker ID = first two chars of key (e.g. \"19\", \"23\", ...)\r\n    speaker_ids = list(set(key[:2] for key in equalized.keys()))\r\n    for spk_id in speaker_ids:\r\n\r\n        # find the reference entry for this loudspeaker\r\n        ref_candidates = [k for k in reference.keys() if k.startswith(spk_id + \"_\")]\r\n        if not ref_candidates:\r\n            raise KeyError(f\"No matching reference for loudspeaker ID '{spk_id}'\")\r\n        ref_key = ref_candidates[0]\r\n        ref = pyfar.Signal(reference[ref_key].data.T, fs)\r\n        # remove DC\r\n        # ref.time -= numpy.mean(reference.time, axis=-1, keepdims=True)\r\n        # regularized inverse of reference\r\n        ref_inv = pyfar.dsp.regularized_spectrum_inversion(ref, frequency_range=(200, 18000))\r\n        # save center recordings for plotting\r\n        if ref_key == center_key:\r\n            center_ref = ref\r\n            center_ref_inv = ref_inv\r\n\r\n        # equalize all recordings from this loudspeaker\r\n        rec_keys = [k for k in equalized.keys() if k.startswith(spk_id + \"_\")]\r\n        for key in rec_keys:\r\n            ir = equalized[key]\r\n            # ir.time -= numpy.mean(ir.time, axis=-1, keepdims=True)  # remove DC\r\n            ir_equalized = ir * ref_inv\r\n            equalized[key] = ir_equalized\r\n\r\n    # ------------------------------------------------------------------\r\n    # 3) Pack equalized HRIRs into one pyfar.Signal\r\n    # ------------------------------------------------------------------\r\n    keys_list = list(equalized.keys())\r\n    sig_list = [equalized[k] for k in keys_list]\r\n    # shape: (n_positions, n_channels, n_samples)\r\n    hrir_equalized = pyfar.Signal(numpy.stack([s.time for s in sig_list], axis=0), fs)\r\n\r\n    # ------------------------------------------------------------------\r\n    # 4) Temporal alignment using central loudspeaker\r\n    # ------------------------------------------------------------------\r\n    hrir_shifted = pyfar.dsp.time_shift(hrir_equalized, 2000)\r\n\r\n    # find index of central loudspeaker in keys_list\r\n    center_idx = keys_list.index(center_key)\r\n    center_onset = pyfar.dsp.find_impulse_response_start(\r\n        hrir_shifted[center_idx], threshold=15\r\n    )\r\n    center_onset = float(numpy.min(center_onset))\r\n    center_onset_s = center_onset / fs\r\n\r\n    # shift so that center onset is at 1 ms\r\n    desired_onset_s = 0.001\r\n    shift_s = desired_onset_s - center_onset_s\r\n    hrir_aligned = pyfar.dsp.time_shift(hrir_shifted, shift_s, unit=\"s\")\r\n\r\n    # ------------------------------------------------------------------\r\n    # 5) Window the HRIRs (short asymmetric Hanning window) and cut to final length\r\n    # ------------------------------------------------------------------\r\n    onsets = pyfar.dsp.find_impulse_response_start(hrir_aligned, threshold=15)\r\n    onsets_min = numpy.min(onsets) / fs  # earliest onset in seconds\r\n    times = (onsets_min - .00025,  # start of fade-in\r\n             onsets_min,  # end if fade-in\r\n             onsets_min + .0048,  # start of fade_out\r\n             onsets_min + .0058)  # end of_fade_out\r\n    hrir_windowed, window = pyfar.dsp.time_window(\r\n        hrir_aligned, times, \"hann\", unit=\"s\", crop=\"none\", return_window=True)\r\n\r\n    # cut to n_samp out if raw recordings where provided\r\n    if isinstance(recorded, Recordings):\r\n        times_samples = [0, 10, 246, n_samples_out - 1]\r\n        hrir_cropped = pyfar.dsp.time_window(\r\n            hrir_windowed,\r\n            times_samples,\r\n            \"hann\",\r\n            crop=\"end\",\r\n        )\r\n        equalized.params[\"n_samples\"] = n_samples_out\r\n        hrir_final = hrir_cropped\r\n    else:\r\n        hrir_final = hrir_windowed\r\n\r\n    # ------------------------------------------------------------------\r\n    # 6) Convert to slab filters and return ImpulseResponses\r\n    # ------------------------------------------------------------------\r\n    for key, filt in zip(equalized.keys(), hrir_final):\r\n        # pyfar.Signal: (n_channels, n_samples) -> slab.Filter expects (n_samples, n_channels)\r\n        equalized[key] = slab.Filter(data=filt.time.T, samplerate=fs, fir=\"IR\")\r\n    equalized.params = {\r\n        \"fs\": fs,\r\n        \"signal\": signal_params,\r\n        \"n_samp_out\": n_samples_out,\r\n        \"date\": datetime.now().isoformat(),\r\n    }\r\n\r\n    # ------------------------------------------------------------------\r\n    # Plot equalization stages (optional)\r\n    # ------------------------------------------------------------------\r\n    if show:\r\n        # raw recorded center IR as pyfar.Signal\r\n        raw_center = pyfar.Signal(recorded[center_key].data.T, fs)\r\n        # equalized but not windowed center signal\r\n        _plot_equalization_pyfar(\r\n            raw_center=raw_center,\r\n            center_ref=center_ref,\r\n            center_ref_inv=center_ref_inv,\r\n            hrir_equalized=hrir_equalized,\r\n            hrir_shifted=hrir_shifted,\r\n            hrir_aligned=hrir_aligned,\r\n            hrir_windowed=hrir_windowed,\r\n            hrir_final=hrir_final,\r\n            window=window,\r\n            center_idx=center_idx,\r\n        )\r\n\r\n    return equalized\r\n\r\n\r\ndef equalize_old(\r\n    hrir_recorded: ImpulseResponses | Recordings,\r\n    hrir_reference: ImpulseResponses | Recordings,\r\n    n_samp_out: int = 256,\r\n    show: bool = False):\r\n\r\n    logging.info(\"Applying equalization\")\r\n\r\n    signal_params = hrir_recorded.params[\"signal\"]\r\n    fs = int(hrir_recorded.params[\"fs\"])\r\n    n_samp = int(hrir_recorded.params[\"n_samp\"])\r\n\r\n    from_f = signal_params[\"from_frequency\"]\r\n    to_f = signal_params[\"to_frequency\"]\r\n\r\n    # ------------------------------------------------------------------\r\n    # 1) Convert recorded HRIRs to pyfar.Signal\r\n    # ------------------------------------------------------------------\r\n    equalized = ImpulseResponses()\r\n    for key, filt in hrir_recorded.items():\r\n        # slab.Filter data: (n_samples, n_channels)\r\n        equalized[key] = pyfar.Signal(filt.data.T, filt.samplerate)\r\n\r\n    # ------------------------------------------------------------------\r\n    # 2) Loudspeaker-wise equalization using reference recordings\r\n    # ------------------------------------------------------------------\r\n    # speaker ID = first two chars of key (e.g. \"19\", \"23\", ...)\r\n    speaker_ids = list(set(key[:2] for key in equalized.keys()))\r\n\r\n    # we’ll remember the center loudspeaker’s reference + inverse for plotting\r\n    center_key_full = \"23_0.0_0.0\"\r\n    center_ref_signal = None\r\n    center_ref_inv = None\r\n\r\n    for spk_id in speaker_ids:\r\n        # find the reference entry for this loudspeaker\r\n        ref_candidates = [k for k in hrir_reference.keys() if k.startswith(spk_id + \"_\")]\r\n        if not ref_candidates:\r\n            raise KeyError(f\"No matching reference for loudspeaker ID '{spk_id}'\")\r\n        ref_key = ref_candidates[0]\r\n\r\n        reference = pyfar.Signal(hrir_reference[ref_key].data.T, fs)\r\n        # remove DC\r\n        reference.time -= numpy.mean(reference.time, axis=-1, keepdims=True)\r\n\r\n        # regularized inverse of reference\r\n        reference_inv = pyfar.dsp.regularized_spectrum_inversion(\r\n            reference,\r\n            frequency_range=(from_f, to_f),\r\n        )  # todo different range (20, 18750)\r\n\r\n        # store for plotting if this loudspeaker contains the center key\r\n        rec_keys = [k for k in equalized.keys() if k.startswith(spk_id + \"_\")]\r\n        if center_key_full in rec_keys:\r\n            center_ref_signal = reference\r\n            center_ref_inv = reference_inv\r\n\r\n        # equalize all recordings from this loudspeaker\r\n        for key in rec_keys:\r\n            ir = equalized[key]\r\n            ir.time -= numpy.mean(ir.time, axis=-1, keepdims=True)  # remove DC\r\n            ir_equalized = ir * reference_inv\r\n\r\n            # windowing\r\n            n0 = min(int(numpy.argmax(numpy.abs(ir_equalized.time[0]))),\r\n                     int(numpy.argmax(numpy.abs(ir_equalized.time[1]))))\r\n            ir_windowed = pyfar.dsp.time_window(ir_equalized,\r\n                                                  (max(0, n0 - 50), min(n0 + 100, len(ir_equalized.time[0]) - 1)),\r\n                                                  'boxcar', unit=\"samples\",\r\n                                                  crop=\"window\")  # (170,335)\r\n            ir_windowed = pyfar.dsp.pad_zeros(ir_windowed, ir_equalized.n_samples - ir_windowed.n_samples)\r\n\r\n            # low freq extrapolation\r\n            ir_low = pyfar.dsp.filter.crossover(\r\n                pyfar.signals.impulse(ir_windowed.n_samples), 4, 400)[0]  # *(10**(-1))\r\n            ir_low.sampling_rate = 48828\r\n            ir_high = pyfar.dsp.filter.crossover(ir_windowed, 4, 400)[1]\r\n            ir_low_delayed = pyfar.dsp.fractional_time_shift(\r\n                ir_low, pyfar.dsp.find_impulse_response_delay(\r\n                    ir_windowed))  # error if too noisy, overwrite function and use exactly the peakpoint?\r\n            ir_extrapolated = ir_low_delayed + ir_high\r\n\r\n            # no time shift\r\n\r\n            # down sampling\r\n            ir_final = pyfar.dsp.time_window(\r\n                ir_extrapolated, (0, n_samp_out-1), 'boxcar',\r\n                crop='window')\r\n\r\n            equalized[key] = ir_final\r\n\r\n            if key == center_key_full:\r\n                raw_center = ir\r\n                reference_center = reference\r\n                reference_inv_center = reference_inv\r\n                equalized_center = ir_equalized\r\n                ir_windowed_center = ir_windowed\r\n\r\n    #     # ------------------------------------------------------------------\r\n    # 4) Temporal alignment using central loudspeaker\r\n    # ------------------------------------------------------------------\r\n    # hrir_shifted = pyfar.dsp.time_shift(hrir, int(n_samp / 2))\r\n    #\r\n    # # find index of central loudspeaker in keys_list\r\n    # center_key = center_key_full if center_key_full in keys_list else keys_list[0]\r\n    # center_idx = keys_list.index(center_key)\r\n    #\r\n    # center_onset = pyfar.dsp.find_impulse_response_start(\r\n    #     hrir_shifted[center_idx], threshold=15\r\n    # )\r\n    # center_onset = float(numpy.min(center_onset))\r\n    # center_onset_s = center_onset / fs\r\n    #\r\n    # # shift so that center onset is at 1 ms\r\n    # desired_onset_s = 0.001\r\n    # shift_s = desired_onset_s - center_onset_s\r\n    # hrir_aligned = pyfar.dsp.time_shift(hrir_shifted, shift_s, unit=\"s\")\r\n\r\n    # ------------------------------------------------------------------\r\n    # 6) Plot equalization stages (optional)\r\n    # ------------------------------------------------------------------\r\n    if show:\r\n        _plot_equalization_pyfar(\r\n            raw_center=raw_center,\r\n            reference=reference_center,\r\n            reference_inv=reference_inv_center,\r\n            equalized_center=equalized_center,\r\n            hrir_windowed=ir_windowed_center,\r\n            )\r\n    # ------------------------------------------------------------------\r\n    # 7) Convert to slab filters and return ImpulseResponses\r\n    # ------------------------------------------------------------------\r\n    equalized.params = {\r\n        \"fs\": fs,\r\n        \"signal\": signal_params,\r\n        \"n_samp_out\": n_samp_out,\r\n        \"date\": datetime.now().isoformat(),\r\n    }\r\n    for key, filt in equalized.items():\r\n        # pyfar.Signal: (n_channels, n_samples) -> slab.Filter expects (n_samples, n_channels)\r\n        equalized[key] = slab.Filter(data=filt.time.T, samplerate=fs, fir=\"IR\")\r\n    return equalized\r\n\r\ndef lowfreq_extrapolate(\r\n    irs,\r\n    f_extrap: float = 400.0,\r\n    f_target: float = 150.0,\r\n    head_radius: float | None = None,\r\n    show: bool = False,\r\n    probe_index: int | None = None,\r\n):\r\n    \"\"\"\r\n    Smoothly replace low frequencies with spherical-head magnitude.\r\n\r\n    Anchors the magnitude at 0 Hz and `f_target` from a spherical-head model,\r\n    keeps measured magnitudes above `f_extrap`, and linearly interpolates\r\n    across the full band. Phase (and thus ITD) is preserved.\r\n\r\n    Parameters\r\n    ----------\r\n    irs : ImpulseResponses\r\n        Binaural IRs in pyfar spherical coords (`domain=\"sph\"`, `top_elev`).\r\n    f_extrap : float\r\n        Frequency (Hz) above which measured magnitudes are trusted.\r\n    f_target : float\r\n        Low-frequency anchor (Hz) taken from the spherical-head model.\r\n    head_radius : float or None\r\n        Spherical-head radius in meters (None → model default).\r\n    show : bool\r\n        If True, plot before/after magnitude for one position.\r\n\r\n    Returns\r\n    -------\r\n    ImpulseResponses\r\n        New object with LF-magnitude extrapolated, phase unchanged.\r\n\r\n    Notes\r\n    -----\r\n    Interpolates magnitudes per ear per source; uses `domain='freq'`\r\n    when constructing pyfar signals for plotting.\r\n    \"\"\"\r\n    # ----------------------------------------------------------------------\r\n    # (1) Convert measured IRs -> pyfar.Signal + spherical coordinates\r\n    # ----------------------------------------------------------------------\r\n    hrir_meas, coords, keys, fs = _irs_to_pyfar(irs)\r\n\r\n    # Get spherical-head HRTFs for the same coordinates\r\n    shtf = _spherical_head_for(coords, hrir_meas.n_samples, fs, head_radius)\r\n\r\n    # ----------------------------------------------------------------------\r\n    # (2) Prepare variables and masks for frequency-domain interpolation\r\n    # ----------------------------------------------------------------------\r\n    freqs = hrir_meas.frequencies           # frequency axis [Hz]\r\n    mask_extrap = freqs >= f_extrap         # region where measurement is trusted\r\n\r\n    # Find index closest to f_target (used as second model anchor)\r\n    f_target_idx = hrir_meas.find_nearest_frequency(f_target)\r\n    f_target = freqs[f_target_idx]          # ensure grid alignment\r\n\r\n    # Separate magnitude and phase for convenience\r\n    mag_meas = numpy.abs(hrir_meas.freq)\r\n    phase_meas = numpy.angle(hrir_meas.freq)\r\n    mag_sph = numpy.abs(shtf.freq)          # spherical-head magnitude\r\n\r\n    # ----------------------------------------------------------------------\r\n    # (3) Build the \"anchor\" magnitude vectors\r\n    # ----------------------------------------------------------------------\r\n    # - 0 Hz and f_target: take from spherical-head model\r\n    # - f >= f_extrap: take from measurement\r\n    # Everything between will be interpolated later.\r\n\r\n    freqs_valid = freqs[mask_extrap]                    # f >= f_extrap\r\n    mag_valid = mag_meas[..., mask_extrap]              # measured magnitudes above f_extrap\r\n\r\n    mag0 = mag_sph[..., 0:1]                            # model @ 0 Hz\r\n    mag_ft = mag_sph[..., f_target_idx:f_target_idx+1]  # model @ f_target\r\n\r\n    # Concatenate anchor magnitudes for each ear/source:\r\n    # shape: (n_pos, n_ears, 2 + n_valid)\r\n    mag_anchor = numpy.concatenate((mag0, mag_ft, mag_valid), axis=-1)\r\n\r\n    # Corresponding anchor frequencies\r\n    freqs_anchor = numpy.concatenate((\r\n        numpy.array([0.0]),\r\n        numpy.array([f_target]),\r\n        freqs_valid,\r\n    ))\r\n\r\n    # ----------------------------------------------------------------------\r\n    # (4) Interpolate magnitude across the entire frequency axis\r\n    # ----------------------------------------------------------------------\r\n    mag_interp = numpy.empty_like(hrir_meas.freq)\r\n    for src in range(mag_anchor.shape[0]):       # iterate over all source positions\r\n        for ear in range(mag_anchor.shape[1]):   # iterate over ears (L/R)\r\n            # Linear interpolation in magnitude domain\r\n            mag_interp[src, ear] = numpy.interp(\r\n                freqs,             # full frequency grid\r\n                freqs_anchor,      # anchor frequencies\r\n                mag_anchor[src, ear],  # anchor magnitudes\r\n            )\r\n\r\n    # ----------------------------------------------------------------------\r\n    # (5) Combine new magnitudes with original phases\r\n    # ----------------------------------------------------------------------\r\n    # Phase is preserved (no ITD or phase shift change here)\r\n    hrir_meas.freq = mag_interp * numpy.exp(1j * phase_meas)\r\n\r\n    # ----------------------------------------------------------------------\r\n    # (6) Optional quick visualization: before vs after (one position)\r\n    # ----------------------------------------------------------------------\r\n    if show:\r\n        idx = 0 if probe_index is None else int(probe_index)\r\n\r\n        # Plot frequency responses for left/right ear before and after\r\n        plt.figure()\r\n        ax = pyfar.plot.freq(\r\n            pyfar.Signal(mag_meas[idx] * numpy.exp(1j * phase_meas[idx]), fs, domain='freq'),\r\n            color=[.6, .6, .6],\r\n            label=['before L', 'before R'],\r\n        )\r\n        pyfar.plot.freq(\r\n            pyfar.Signal(hrir_meas.freq[idx], fs, domain='freq'),\r\n            label=['after L', 'after R'],\r\n            ax=ax,\r\n        )\r\n        ax.set_title(f'LF extrapolation (pos {idx})')\r\n        ax.set_xlim(50, fs / 2)\r\n        ax.legend()\r\n        plt.show()\r\n\r\n    # ----------------------------------------------------------------------\r\n    # (7) Convert back into ImpulseResponses object for next pipeline step\r\n    # ----------------------------------------------------------------------\r\n    time_data = hrir_meas.time  # (n_pos, n_ears, n_samples)\r\n    out = _pyfar_to_irs(irs, keys, time_data, fs)\r\n\r\n    # Bookkeeping / metadata\r\n    out.params.setdefault(\"processing\", {})\r\n    out.params[\"processing\"][\"lowfreq_extrapolate\"] = {\r\n        \"f_extrap\": float(f_extrap),\r\n        \"f_target\": float(f_target),\r\n        \"head_radius\": float(head_radius) if head_radius is not None else None,\r\n        \"date\": datetime.now().isoformat(),\r\n    }\r\n\r\n    return out\r\n\r\ndef expand_azimuths_with_binaural_cues(\r\n    hrir,\r\n    az_range: tuple[float, float] = (-50, 50),\r\n    head_radius: float | None = None,\r\n    onset_threshold_db: float = 15.0,\r\n    show: bool = False,\r\n    probe_az: float = 45.0,\r\n):\r\n    \"\"\"\r\n     Extend vertical-arc HRIRs across azimuths and impose binaural cues.\r\n\r\n     This combines three processing steps:\r\n       1) **Azimuth expansion** – Duplicates all IRs near `center_az` across\r\n          a grid within `az_range`, spaced by the mean elevation step.\r\n       2) **Full-band ILD shaping** – Applies spherical-head ILDs to all\r\n          off-midline sources while preserving per-frequency power and phase.\r\n       3) **ITD alignment** – Shifts the right-ear IR so measured ITDs match\r\n          those predicted by the spherical-head model.\r\n\r\n     If `show=True`, plots one example (closest to `probe_az`) using\r\n     `pyfar.plot.time_freq` to visualize ITD and ILD.\r\n\r\n     Parameters\r\n     ----------\r\n     irs : ImpulseResponses\r\n         Binaural input (2 ch) in pyfar spherical coordinates\r\n         (`domain=\"sph\"`, `convention=\"top_elev\"`).\r\n     az_range : (float, float)\r\n         Azimuth range (deg) for duplication, e.g. (-35, 35).\r\n     head_radius : float or None\r\n         Sphere radius in meters; default uses model internal value.\r\n     center_az : float\r\n         Midline azimuth (deg), typically 0.\r\n     show : bool\r\n         Plot diagnostic time/freq view at `probe_az`.\r\n\r\n     Returns\r\n     -------\r\n     ImpulseResponses\r\n         New object with expanded azimuths, spherical-head ILDs,\r\n         and ITD-aligned IRs.\r\n\r\n     Notes\r\n     -----\r\n     ILDs are applied per frequency bin via R/L magnitude ratios from the\r\n     spherical-head model; ITDs are adjusted by time-shifting the right ear.\r\n     \"\"\"\r\n\r\n    # ---------------------------------------------------------------------\r\n    # STEP 2: AZIMUTH EXPANSION\r\n    # ---------------------------------------------------------------------\r\n    # We start from a vertical arc at center_az (e.g., 0°). We’ll duplicate\r\n    # those IRs across an azimuth grid covering az_range. The azimuth grid\r\n    # step equals the mean *elevation* step in your existing arc, so the\r\n    # az grid density matches your vertical sampling density.\r\n    # New entries are deep-copied so later edits won’t affect originals.\r\n    # ---------------------------------------------------------------------\r\n    sources0 = hrir.get_sources()  # shape (n_pos, 3): [az, el, r]\r\n    elevations = numpy.unique(sources0[:, 1])\r\n    if len(elevations) > 1:\r\n        vertical_res = float(numpy.mean(numpy.diff(numpy.sort(elevations))))\r\n    else:\r\n        # Fallback (single elevation present): create a single az step\r\n        vertical_res = az_range[1] - az_range[0]\r\n\r\n    # --- build azimuth grid based on vertical spacing ---\r\n    azimuths = numpy.arange(az_range[0], az_range[1] + vertical_res / 2, vertical_res)\r\n    # wrap to [0, 360) for pyfar convention (0°=front, 90°=left)\r\n    azimuths_wrapped = _wrap_az_deg_ccw(azimuths)\r\n\r\n    # --- find midline IRs at az = 0 (wrapped 0°) ---\r\n    def _key_az_wrapped(k: str) -> float:\r\n        # keys look like \"spk_az_el\"\r\n        return float(_wrap_az_deg_ccw(float(k.split(\"_\")[1])))\r\n\r\n    # --- duplicate midline IRs across azimuth grid, inserting wrapped az into keys ---\r\n    out = copy.deepcopy(hrir)\r\n    new_entries = {}\r\n\r\n    for key in hrir.data.keys():\r\n        spk, _az_str, el_str = key.split(\"_\")  # reuse elevation\r\n        for az_w in azimuths_wrapped:\r\n            az_s = f\"{float(az_w):.1f}\"\r\n            new_key = f\"{spk}_{az_s}_{el_str}\"\r\n            if new_key not in out.data and new_key not in new_entries:\r\n                new_entries[new_key] = copy.deepcopy(out.data[key])  # independent copy\r\n\r\n    # --- update and sort dictionary for stable downstream behavior ---\r\n    out.data.update(new_entries)\r\n\r\n    try:\r\n        from collections import OrderedDict\r\n        def _parse_key_triple(k):\r\n            spk, az_s, el_s = k.split(\"_\")\r\n            return (float(az_s), float(el_s), spk)\r\n\r\n        out.data = OrderedDict(sorted(out.data.items(), key=lambda kv: _parse_key_triple(kv[0])))\r\n    except Exception:\r\n        pass  # sorting is optional\r\n\r\n    # --- convert to pyfar + compute spherical-head reference ---\r\n    hrir, coords, keys, fs = _irs_to_pyfar(out)\r\n    shtf = _spherical_head_for(coords, hrir.n_samples, fs, head_radius)\r\n\r\n    # ---------------------------------------------------------------------\r\n    # STEP 3: FULL-BAND ILD SHAPING (OFF-MIDLINE ONLY)\r\n    # ---------------------------------------------------------------------\r\n    # For each synthesized direction, we impose the spherical-head ILD per\r\n    # frequency bin. We preserve the measured *power average* per bin:\r\n    #   r(f)  = H_R_head / H_L_head    (magnitude ratio)\r\n    #   A(f)  = sqrt((|H_L|^2 + |H_R|^2) / 2)\r\n    #   mL'   = A * sqrt(2/(1+r^2))\r\n    #   mR'   = r * mL'\r\n    # Phases are preserved (ILD affects magnitudes only).\r\n    # Midline (≈ center_az) directions are left untouched.\r\n    # ---------------------------------------------------------------------\r\n    H_meas = hrir.freq  # complex spectrum, shape (n_pos, 2, n_bins)\r\n    mag_meas = numpy.abs(H_meas)\r\n    phase_meas = numpy.angle(H_meas)\r\n    mag_head = numpy.abs(shtf.freq)\r\n\r\n    n_pos, n_ears, _ = mag_meas.shape\r\n    if n_ears != 2:\r\n        raise ValueError(\"Binaural data expected (2 ears).\")\r\n\r\n    sources = out.get_sources()\r\n    az_all = sources[:, 0]\r\n    is_midline = sources[:, 0] == 0\r\n\r\n    # Copy magnitudes; we will overwrite off-midline entries\r\n    mag_new = mag_meas.copy()\r\n\r\n    for i in range(n_pos):\r\n        if is_midline[i]:\r\n            # Keep measured magnitudes on the midline as-is\r\n            continue\r\n\r\n        # Head-model ILD ratio r(f) = R/L\r\n        mL_h = mag_head[i, 0, :]\r\n        mR_h = mag_head[i, 1, :]\r\n        r = mR_h / numpy.maximum(mL_h, 1e-12)  # protect division\r\n\r\n        # Measured magnitudes and power average\r\n        mL = mag_meas[i, 0, :]\r\n        mR = mag_meas[i, 1, :]\r\n        A = numpy.sqrt((mL**2 + mR**2) / 2.0)\r\n\r\n        # Apply ILD while preserving A and phases\r\n        mL_new = A * numpy.sqrt(2.0 / (1.0 + r**2))\r\n        mR_new = r * mL_new\r\n\r\n        mag_new[i, 0, :] = mL_new\r\n        mag_new[i, 1, :] = mR_new\r\n\r\n    # Recombine with original phases\r\n    H_new = mag_new * numpy.exp(1j * phase_meas)\r\n    hrir.freq = H_new  # pyfar will update time on demand\r\n\r\n    # ---------------------------------------------------------------------\r\n    # STEP 4: ITD ALIGNMENT (GLOBAL TIME SHIFT OF RIGHT EAR)\r\n    # ---------------------------------------------------------------------\r\n    # We want the *onset difference* (right minus left) to match the model\r\n    # in the *time domain*. Compute onsets for both (model & processed),\r\n    # then time-shift the *entire* right ear by ΔITD per direction.\r\n    # ---------------------------------------------------------------------\r\n    _ = hrir.time  # ensure time cache\r\n    _ = shtf.time\r\n\r\n    on_mod = pyfar.dsp.find_impulse_response_start(shtf, threshold=onset_threshold_db)\r\n    on_mea = pyfar.dsp.find_impulse_response_start(hrir, threshold=onset_threshold_db)\r\n\r\n    time_data = hrir.time  # shape (n_pos, 2, n_samples)\r\n    out_time = numpy.empty_like(time_data)\r\n\r\n    for i in range(time_data.shape[0]):\r\n        # Convert sample offsets to seconds\r\n        itd_model = (on_mod[i, 1] - on_mod[i, 0]) / fs\r\n        itd_meas  = (on_mea[i, 1] - on_mea[i, 0]) / fs\r\n        delta_itd = itd_model - itd_meas  # desired additional shift for right ear\r\n\r\n        # Left ear unchanged\r\n        out_time[i, 0, :] = time_data[i, 0, :]\r\n\r\n        # Shift right ear in time using pyfar; preserves spectrum consistency\r\n        sig_r = pyfar.Signal(time_data[i, 1:2, :], fs)\r\n        sig_rs = pyfar.dsp.time_shift(sig_r, delta_itd, unit=\"s\")\r\n        out_time[i, 1, :] = sig_rs.time[0]\r\n\r\n    # ---------------------------------------------------------------------\r\n    # OPTIONAL: Quick diagnostic plot at ~probe_az\r\n    # ---------------------------------------------------------------------\r\n    if show:\r\n        idx = int(numpy.argmin(numpy.abs(az_all - float(probe_az))))\r\n        import matplotlib.pyplot as plt\r\n        plt.figure(figsize=(7,10))\r\n        ax_t, ax_f = pyfar.plot.time_freq(pyfar.Signal(out_time[idx], fs))\r\n        ax_t.get_lines()[0].set_label('left')\r\n        ax_t.get_lines()[1].set_label('right')\r\n        ax_t.legend()\r\n        ax_f.get_lines()[0].set_label('left')\r\n        ax_f.get_lines()[1].set_label('right')\r\n        ax_f.legend()\r\n        ax_t.set_title('time')\r\n        ax_f.set_title(\"magnitude\")\r\n        plt.suptitle(f\"Result @ az≈{az_all[idx]:.1f}°\")\r\n        plt.show()\r\n\r\n    # ---------------------------------------------------------------------\r\n    # Return as a fresh ImpulseResponses object with provenance\r\n    # ---------------------------------------------------------------------\r\n    out_final = _pyfar_to_irs(out, keys, out_time, fs)\r\n    out_final.params.setdefault(\"processing\", {})\r\n    out_final.params[\"processing\"][\"expand_azimuths_with_binaural_cues\"] = {\r\n        \"az_range\": [float(az_range[0]), float(az_range[1])],\r\n        \"head_radius\": float(head_radius) if head_radius is not None else None,\r\n        \"onset_threshold_db\": float(onset_threshold_db),\r\n        \"date\": datetime.now().isoformat(),\r\n    }\r\n    return out_final\r\n\r\n\r\n\r\n# -------------------------------------------------------------------------\r\n# Helpers / Plotting\r\n# -------------------------------------------------------------------------\r\ndef _irs_to_pyfar(irs):\r\n    \"\"\"ImpulseResponses -> (pyfar.Signal, pyfar.Coordinates, keys, fs)\"\"\"\r\n    fs = int(irs.params[\"fs\"])\r\n    keys = list(irs.data.keys())\r\n    if not keys:\r\n        raise ValueError(\"No filters in ImpulseResponses.data\")\r\n    filters = [irs.data[k] for k in keys]  # slab.Filter\r\n    data = numpy.stack([f.data.T for f in filters], axis=0)  # (n_pos, n_ears, n_samp)\r\n\r\n    sources = irs.get_sources()  # (n_pos, 3): [az, el, r] in deg/m\r\n    coords = pyfar.Coordinates(\r\n        sources[:, 0],  # azimuth in deg\r\n        sources[:, 1],  # elevation in deg\r\n        sources[:, 2],  # radius in m\r\n        domain=\"sph\",\r\n        convention=\"top_elev\",\r\n        unit=\"deg\",\r\n    )\r\n    sig = pyfar.Signal(data, fs)\r\n    return sig, coords, keys, fs\r\n\r\ndef _pyfar_to_irs(template_irs, keys, time_data, fs):\r\n    \"\"\"(keys aligned with dimension 0) -> new ImpulseResponses with slab.Filters.\"\"\"\r\n    out = copy.deepcopy(template_irs)\r\n    for key, sig_time in zip(keys, time_data):  # sig_time: (n_ears, n_samp)\r\n        out.data[key] = slab.Filter(data=sig_time.T, samplerate=fs, fir=\"IR\")\r\n    return out\r\n\r\ndef _spherical_head_for(coords, n_samples, fs, head_radius=None):\r\n    \"\"\"\r\n    Wrap spherical_head() and, if head_radius is given, construct the expected\r\n    spharpy/SOFAR SamplingSphere with two ear nodes (±90° az, 0° el).\r\n    \"\"\"\r\n    from hrtf_relearning.hrtf.processing.spherical_head import spherical_head as _spherical_head\r\n    if head_radius is None:  # use default head radius: .0875 m\r\n        return _spherical_head(coords, n_samples=n_samples, sampling_rate=fs)\r\n    head = pyfar.Coordinates(0, [head_radius, -head_radius], 0)\r\n    return _spherical_head(coords,head=head,n_samples=n_samples,sampling_rate=fs)\r\n\r\ndef _plot_processing_pyfar(excitation, ref_inv, recording, hrir_deconvolved, hrir_shifted,\r\n    hrir_aligned, hrir_windowed, hrir_final, window, center_idx: int = 0) -> None:\r\n    \"\"\"\r\n    Comprehensive overview of the processing pipeline, using pyfar's\r\n    plotting shortcuts (same style as Fabian's notebook).\r\n\r\n    Shows, in one figure with subplots:\r\n    - Recorded sweep at center position\r\n    - Excitation + inverse (frequency domain)\r\n    - Deconvolved, shifted, aligned, windowed HRIRs\r\n    - Window overlay\r\n    - Frequency response before vs after final truncation\r\n    \"\"\"\r\n    import pyfar.plot as pfplot\r\n\r\n    # which source index we show in detail\r\n    idx = center_idx\r\n\r\n    fig, axes = plt.subplots(3, 3, figsize=(15, 10))\r\n    axes = axes.ravel()\r\n\r\n    # 1) Recorded sweep at the ears (time, both channels)\r\n    ax = axes[0]\r\n    pfplot.time(recording[idx], unit=\"ms\", ax=ax, label=[\"left\", \"right\"])\r\n    ax.set_title(f\"Recorded sine sweep (center pos)\")\r\n    ax.legend()\r\n\r\n    # 2) Excitation in time domain\r\n    ax = axes[1]\r\n    pfplot.time(excitation[0], unit=\"ms\", ax=ax)\r\n    ax.set_title(\"Excitation sweep (time)\")\r\n\r\n    # 3) Excitation and inverse in frequency domain\r\n    ax = axes[2]\r\n    pfplot.freq(excitation[0], freq_scale=\"log\", ax=ax, color=[0.6, 0.6, 0.6])\r\n    pfplot.freq(ref_inv[0], freq_scale=\"log\", ax=ax, label=[\"inverse L\", \"inverse R\"])\r\n    ax.set_title(\"Excitation & inverse (magnitude)\")\r\n    ax.set_xlim(50, excitation.sampling_rate / 2)\r\n    ax.legend(loc=\"best\")\r\n\r\n    # 4) Deconvolved HRIR at center position (time, dB)\r\n    ax = axes[3]\r\n    pfplot.time(hrir_deconvolved[idx], dB=True, unit=\"ms\", ax=ax)\r\n    ax.set_title(\"Deconvolved HRIR (center pos)\")\r\n\r\n    # 5) Time-shifted HRIRs (all positions)\r\n    ax = axes[4]\r\n    pfplot.time(hrir_shifted, dB=True, unit=\"ms\", ax=ax)\r\n    ax.set_title(\"Time-shifted HRIRs (all positions)\")\r\n\r\n    # 6) Aligned HRIR at center (onset at 1 ms)\r\n    ax = axes[5]\r\n    pfplot.time(hrir_aligned[idx], unit=\"ms\", ax=ax)\r\n    ax.axvline(1.0, color=\"k\", linestyle=\"--\",\r\n               label=\"1 ms: desired onset (center)\")\r\n    ax.set_xlim(0, 5)\r\n    ax.legend()\r\n    ax.set_title(\"Aligned center HRIR\")\r\n\r\n    # 7) Aligned HRIRs (all positions)\r\n    ax = axes[6]\r\n    pfplot.time(hrir_aligned, unit=\"ms\", ax=ax)\r\n    ax.axvline(1.0, color=\"k\", linestyle=\"--\",\r\n               label=\"1 ms: desired onset (center)\")\r\n    ax.set_xlim(0, 25)\r\n    ax.legend()\r\n    ax.set_title(\"Aligned HRIRs (all positions)\")\r\n\r\n    # 8) Windowed HRIRs + window\r\n    ax = axes[7]\r\n    pfplot.time(hrir_windowed, unit=\"ms\", dB=True, ax=ax)\r\n    pfplot.time(window, unit=\"ms\", dB=True,\r\n                color=\"k\", linestyle=\"--\", ax=ax, label=\"window\")\r\n    ax.set_xlim(0, 10)\r\n    ax.set_title(\"Windowed HRIRs + window\")\r\n    ax.legend()\r\n\r\n    # 9) Frequency response before vs after final truncation (one position)\r\n    ax = axes[8]\r\n    pfplot.freq(\r\n        hrir_windowed[idx],\r\n        freq_scale=\"log\",\r\n        ax=ax,\r\n        color=[0.6, 0.6, 0.6],\r\n    )\r\n    pfplot.freq(\r\n        hrir_final[idx],\r\n        freq_scale=\"log\",\r\n        ax=ax,\r\n        label=[\"final L\", \"final R\"],\r\n    )\r\n    ax.set_title(f\"HRIRs before/after final truncation (center pos)\")\r\n    ax.set_xlim(50, hrir_final.sampling_rate / 2)\r\n    ax.legend(loc=\"lower left\")\r\n    fig.tight_layout()\r\n    plt.show()\r\n\r\ndef _plot_equalization_pyfar(\r\n    raw_center = None, center_ref = None,\r\n    center_ref_inv = None, hrir_equalized= None, hrir_shifted= None,\r\n    hrir_aligned= None, hrir_windowed= None, hrir_final= None, window= None, center_idx: int = 0) -> None:\r\n    \"\"\"\r\n    Overview plot for the equalization pipeline, using pyfar's plotting shortcuts.\r\n    Inspired by the example notebook.\r\n\r\n    Shows:\r\n    - Raw HRIR (center position)\r\n    - Reference IR and inverse (time + magnitude)\r\n    - Center HRIR before vs after equalization\r\n    - Shifted / aligned / windowed HRIRs\r\n    - Window overlay\r\n    - Frequency response before vs after windowing (center)\r\n    \"\"\"\r\n    import pyfar.plot as pfplot\r\n\r\n    fig, axes = plt.subplots(3, 3, figsize=(15, 10))\r\n    axes = axes.ravel()\r\n\r\n    # 1) Raw HRIR at center position (time)\r\n    ax = axes[0]\r\n    pfplot.time(raw_center, unit=\"ms\", ax=ax, label=[\"left\", \"right\"])\r\n    ax.set_title(\"Ear pressure (center)\")\r\n    ax.legend()\r\n\r\n    # ax = axes[1]\r\n    # pfplot.freq(raw_center, ax=ax, label=[\"left\", \"right\"])\r\n    # ax.set_title(\"Ear pressure (center)\")\r\n    # ax.legend()\r\n\r\n    # 2) Reference IR (time)\r\n    ax = axes[1]\r\n    if center_ref is not None:\r\n        pfplot.time(center_ref, unit=\"ms\", ax=ax)\r\n        ax.set_title(\"Reference pressure (center)\")\r\n    else:\r\n\r\n        \r\n        ax.set_title(\"Reference IR (missing)\")\r\n\r\n    # 3) Reference inverse (magnitude)\r\n    ax = axes[2]\r\n    if center_ref_inv is not None:\r\n        pfplot.freq(center_ref_inv, freq_scale=\"log\", ax=ax, label=[\"inv L\", \"inv R\"])\r\n        ax.set_title(\"Inverted reference\")\r\n        ax.set_xlim(50, center_ref_inv.sampling_rate / 2)\r\n        ax.legend()\r\n    else:\r\n        ax.set_title(\"Inverse reference (missing)\")\r\n\r\n    # 4) Center HRIR before vs after equalization (freq)\r\n    ax = axes[3]\r\n    pfplot.freq(raw_center, ax=ax, color=[0.6, 0.6, 0.6])\r\n    pfplot.freq(hrir_equalized[center_idx], ax=ax, label=[\"equalized L\", \"equalized R\"])\r\n    ax.set_title(\"Center HRIR: raw vs equalized\")\r\n    ax.legend()\r\n\r\n    # 5) Time-shifted HRIRs (center)\r\n    if hrir_shifted is not None:\r\n        ax = axes[4]\r\n        pfplot.time(hrir_shifted[center_idx], dB=False, unit=\"ms\", ax=ax)\r\n        ax.set_title(\"Equalized center HRIR (time-shifted)\")\r\n        ax.set_xlim(0, 75)\r\n\r\n    # 6) Aligned center HRIR (1 ms onset)\r\n    if hrir_aligned is not None:\r\n        ax = axes[5]\r\n        pfplot.time(hrir_aligned, unit=\"ms\", ax=ax, linewidth=0.5)\r\n        ax.axvline(1.0, color=\"k\", linestyle=\"--\", label=\"1 ms onset target\")\r\n        ax.set_xlim(0, 25)\r\n        ax.legend()\r\n        ax.set_title(\"Aligned HRIRs (all positions)\")\r\n\r\n    # 7) Windowed HRIRs + window\r\n    if hrir_windowed is not None:\r\n        ax = axes[6]\r\n        pfplot.time(hrir_windowed, unit=\"ms\", dB=True, ax=ax)\r\n        if window is not None:\r\n            pfplot.time(window, unit=\"ms\", dB=True, color=\"k\", linestyle=\"--\", ax=ax, label=\"window\")\r\n        ax.set_xlim(0, 10)\r\n        ax.set_title(\"Windowed HRIRs\")\r\n        ax.legend()\r\n\r\n    # 8) Frequency response (center) before vs after windowing\r\n    if hrir_aligned is not None:\r\n        ax = axes[7]\r\n        pfplot.freq(\r\n            hrir_aligned[center_idx], freq_scale=\"log\", ax=ax, color=[0.6, 0.6, 0.6]\r\n        )\r\n    if hrir_windowed is not None:\r\n        pfplot.freq(\r\n            hrir_windowed[center_idx],\r\n            freq_scale=\"log\",\r\n            ax=ax,\r\n            label=[\"windowed L\", \"windowed R\"],\r\n        )\r\n        ax.set_title(\"Windowed HRIR (center)\")\r\n        ax.set_xlim(50, hrir_windowed.sampling_rate / 2)\r\n        ax.legend(loc=\"lower left\")\r\n\r\n    # 9) Final cropped IR (center)\r\n    if hrir_final is not None:\r\n        ax = axes[8]\r\n        pfplot.time(hrir_final[center_idx], unit=\"ms\", ax=ax)\r\n        ax.axvline(1.0, color=\"k\", linestyle=\"--\", label=\"1 ms onset target\")\r\n        ax.legend()\r\n        ax.set_title(\"Final center IR\")\r\n\r\n    fig.tight_layout()\r\n    plt.show()\r\n\r\ndef wait_for_button(msg=None):\r\n    if msg:\r\n        logging.info(msg)\r\n\r\n    def on_press(key):\r\n        if key == keyboard.Key.enter:\r\n            listener.stop()\r\n\r\n    with keyboard.Listener(on_press=on_press) as listener:\r\n        listener.join()\r\n\r\ndef parse_params_file(path: Path | str, filename: str = \"params.txt\") -> dict:\r\n    \"\"\"\r\n    Read a params.txt written by `write_params_file` and rebuild a params dict.\r\n\r\n    Supports:\r\n    key: value\r\n    nested_dict:\r\n      subkey: subval\r\n    \"\"\"\r\n    path = Path(path)\r\n    file = path / filename\r\n    params: dict[str, object] = {}\r\n\r\n    if not file.exists():\r\n        return params  # no params file → leave dict empty\r\n\r\n    def parse_value(s: str):\r\n        s = s.strip()\r\n        # try int, then float, then bool, else leave as string\r\n        if s.lower() in (\"true\", \"false\"):\r\n            return s.lower() == \"true\"\r\n        try:\r\n            return int(s)\r\n        except ValueError:\r\n            pass\r\n        try:\r\n            return float(s)\r\n        except ValueError:\r\n            pass\r\n        return s\r\n\r\n    with file.open(\"r\", encoding=\"utf-8\") as f:\r\n        lines = [line.rstrip(\"\\n\") for line in f]\r\n    current_dict = None\r\n    for line in lines:\r\n        if not line.strip():\r\n            continue\r\n        # top-level line (no leading spaces)\r\n        if not line.startswith(\" \"):\r\n            if line.endswith(\":\") and not \":\" in line[:-1]:\r\n                # e.g. \"signal:\" or \"Software versions:\"\r\n                key = line[:-1].strip()\r\n                current_key = key\r\n                current_dict = {}\r\n                params[key] = current_dict\r\n            else:\r\n                # e.g. \"fs: 48828\"\r\n                if \":\" in line:\r\n                    key, val = line.split(\":\", 1)\r\n                    key = key.strip()\r\n                    val = val.strip()\r\n                    params[key] = parse_value(val)\r\n                current_dict = None\r\n                current_key = None\r\n        else:\r\n            # indented line: part of current_dict\r\n            if current_dict is not None:\r\n                sub = line.strip()\r\n                if \":\" in sub:\r\n                    sk, sv = sub.split(\":\", 1)\r\n                    current_dict[sk.strip()] = parse_value(sv.strip())\r\n    return params\r\n\r\ndef _wrap_az_deg_ccw(az):\r\n    \"\"\"Wrap azimuth(s) to [0, 360) with CCW-positive (pyfar 'sph/top_elev').\"\"\"\r\n    az = numpy.asarray(az, dtype=float)\r\n    az = numpy.mod(az, 360.0)\r\n    az[az < 0] += 360.0\r\n    return az\r\n\r\n# if __name__ == \"__main__\":\r\n#     # tiny example call – adjust IDs and reference name\r\n#     logging.basicConfig(level=logging.INFO)\r\n#     hrir = record_hrir(subject_id, reference, samp_rec, n_rec, fs, overwrite, n_samp_out, show)\r\n#     pass\r\n#\r\n\r\n\r\n\"\"\"\r\nhrir.write_sofa(hrtf_dir / 'rec' / subject_id / str(subject_id + '.sofa'))  # write to subject rec folder\r\nhrir.write_sofa(hrtf_dir / 'sofa' / str(subject_id + '.sofa'))  # write to sofa folder\r\n\"\"\"
-Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
-<+>UTF-8
-===================================================================
-diff --git a/hrtf_relearning/hrtf/record/record_hrir.py b/hrtf_relearning/hrtf/record/record_hrir.py
---- a/hrtf_relearning/hrtf/record/record_hrir.py	(revision c1855ffaa0401de426b3c09cd9f09facec5d3dc8)
-+++ b/hrtf_relearning/hrtf/record/record_hrir.py	(date 1766344958683)
-@@ -11,17 +11,18 @@
- import warnings
- import slab
- from matplotlib import pyplot as plt
-+import hrtf_relearning
- warnings.filterwarnings("ignore", category=pyfar._utils.PyfarDeprecationWarning)
--
-+ROOT = Path(hrtf_relearning.__file__).resolve().parent
- 
- # -------------------------------------------------------------------------
- # Global settings
- # -------------------------------------------------------------------------
- subject_id = 'kemar_test'
--overwrite = False
-+overwrite = True
- reference = 'kemar_reference'
- n_directions = 1
--n_recordings = 20
-+n_recordings = 10 #todo fix head
- fs = 48828  # 97656
- show = True
- n_samples_out = 256
-@@ -38,7 +39,7 @@
-     subject_id: str, reference: str, n_directions: int = 5, n_recordings: int = 5,
-     fs: int = fs, overwrite: bool = False, n_samples_out: int = 256, show: bool = True):
- 
--    hrtf_dir = Path.cwd() / "data" / "hrtf"
-+    hrtf_dir = ROOT / "data" / "hrtf"
-     subject_dir = hrtf_dir / "rec" / subject_id
-     ref_dir = hrtf_dir / "rec" / "reference" / reference
- 
-@@ -57,7 +58,7 @@
-     if (not ref_dir.exists()) or overwrite:
-         logging.info("Recording new reference")
-         ref_dir.mkdir(exist_ok=True, parents=True)
--        reference_pressure = Recordings.record_dome(n_directions=1, n_recordings=n_recordings, hp_freq=120, fs=fs)
-+        reference_pressure = Recordings.record_dome(n_directions=1, n_recordings=n_recordings, hp_freq=120, fs=fs) 
-         reference_pressure.params["subject_id"] = reference
-         reference_pressure.to_wav(ref_dir, overwrite=overwrite)
-     else:
-@@ -269,7 +270,7 @@
-         """Record across the dome and return a Recordings object with all parameters stored."""
-         if freefield.PROCESSORS.mode != "play_birec":
-             freefield.initialize("dome", "play_birec")
--
-+        # freefield.load_equalization(ROOT / 'hrtf' / 'record' / 'calibration' / 'data' / 'calibration_dome.pkl')
-         # excitation signal  # todo 1 - adjust sweep parameters (freq range and ramp) to measure across 120-18 khz
-         params = {"type": "slab.Sound.chirp", "duration": 0.2, "level": 85,
-                   "from_frequency": 120, "to_frequency": fs/2, "samplerate": fs}
-@@ -279,8 +280,7 @@
-         signal = signal.ramp(when="both", duration=0.001)  # matches the ramp in bi_play_buf.rcx
-         signal.params = params
- 
--        speakers_all = freefield.read_speaker_table()
--        speakers = cls.get_speakers(speakers_all, azimuth=0, elevation=(50, -37.5))  # omit speaker at -50°
-+        speakers = cls.get_speakers(azimuth=0, elevation=(50, -37.5))  # omit speaker at -50°
-         if len(speakers) < 2:
-             raise RuntimeError("Need at least two speakers to infer vertical resolution.")
- 
-@@ -303,9 +303,7 @@
-                 if spk.elevation >= min_el:
-                     logging.info(f"Recording from Speaker {spk.index} at {spk.elevation:.1f}° elevation")
-                     key = f"{spk.index}_{spk.azimuth}_{spk.elevation}"
--                    rec = cls.record_speaker(spk, signal, n_recordings, fs*2)
--                    rec.data -= numpy.mean(rec.data, axis=0)  # remove DC
--                    rec = filt.apply(rec)  # highpass filter
-+                    rec = cls.record_speaker(spk, signal, n_recordings, fs)
-                     recordings_dict[key] = rec
-             freefield.write(tag='bitmask', value=0, processors=led_speaker.digital_proc)  # turn off LED
-         params = {
-@@ -473,22 +471,23 @@
-         return ImpulseResponses(data=out.data, params=params)
- 
-     @staticmethod
--    def record_speaker(speaker, signal: slab.Sound, n_recordings: int, fs: int) -> slab.Binaural:
-+    def record_speaker(speaker, signal: slab.Sound, n_recordings: int, fs: int, filter) -> slab.Binaural:
-         recordings = []
-         for _ in range(n_recordings):
--            recordings.append(
--                freefield.play_and_record(
-+            rec = freefield.play_and_record(
-                     speaker=speaker,
-                     sound=signal,
-                     compensate_delay=True,
--                    equalize=False,
--                    recording_samplerate=fs,
--                )
--            )  # todo test this to make sure both channels are recorded!
--        return slab.Binaural(numpy.mean(recordings, axis=0))
-+                    equalize=True,
-+                    recording_samplerate=fs)
-+            rec.data -= numpy.mean(rec.data, axis=0)  # remove DC
-+            rec = filter.apply(rec)  # highpass filter
-+            recordings.append(rec)
-+        return recordings
- 
-     @staticmethod
--    def get_speakers(speakers, azimuth=None, elevation=None):
-+    def get_speakers(azimuth=None, elevation=None):
-+        speakers = freefield.read_speaker_table()
-         out = []
-         if azimuth is None:
-             az_low, az_high = -float("inf"), float("inf")
-@@ -506,11 +505,9 @@
- 
-         for spk in speakers:
-             if az_low <= spk.azimuth <= az_high and el_low <= spk.elevation <= el_high:
--                out.append(spk)
-+                out.append(freefield.pick_speakers(spk.index)[0])
-         return out
- 
--        # --- I/O: always Binaural --------------------------------------
--
-     @classmethod
-     def from_wav(cls, path: Path | str):
-         """
