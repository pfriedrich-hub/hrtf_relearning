Index: hrtf_relearning/experiment/Training.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import matplotlib\r\nfrom matplotlib import pyplot as plt\r\nimport numpy\r\nimport time\r\nimport multiprocessing as mp\r\nfrom queue import Empty\r\nfrom pythonosc import udp_client\r\nimport datetime\r\ndate = datetime.datetime.now()\r\nimport hrtf_relearning\r\nROOT = hrtf_relearning.PATH\r\n\r\nfrom hrtf_relearning.experiment.misc.training_helpers import meta_motion, game_ui\r\nfrom hrtf_relearning.experiment.Subject import Subject\r\nfrom hrtf_relearning.experiment.misc.training_helpers.training_targets import set_target_probabilistic\r\nfrom hrtf_relearning.hrtf.binsim.hrtf2binsim import *\r\nmatplotlib.rcParams['figure.raise_window'] = False\r\nlogging.getLogger().setLevel('INFO')\r\n\r\n\r\n# -------------------- Config --------------------\r\nSUBJECT_ID = \"JZ\"\r\nHRIR_NAME = \"JZ\"  # 'KU100', 'kemar', etc.\r\nEAR = 'left'              # or None for binaural\r\nHP = 'MYSPHERE'\r\n\r\n# Sound\r\nSOUND_FILE = None         # None -> pink noise pulses; or 'uso_225ms_9_.wav', etc.\r\n# Graphics\r\nshow_ui = True  # todo\r\nSHOW_TF = False  # set to TF or IR to spawn live filter plot\r\n\r\n# Game settings\r\nsettings = dict(\r\n    target_size=3,\r\n    target_time=0.5,\r\n    min_dist=30,\r\n    game_time=90,\r\n    trial_time=10,\r\n    score_time=6,\r\n    gain=.15)\r\n\r\n# -------------------- Global HRIR/Sequence --------------------\r\n\r\n# --- load and process HRIR\r\nhrir = hrtf2binsim(HRIR_NAME, EAR,\r\n    reverb=True, drr=20,\r\n    hp_filter=True, hp=HP,\r\n    convolution=\"cuda\", storage=\"cuda\")\r\n\r\nslab.set_default_samplerate(hrir.samplerate)\r\nHRIR_DIR = ROOT / \"data\" / \"hrtf\" / \"binsim\" / hrir.name\r\n\r\n\r\n\r\n# -------------------- Helpers --------------------\r\ndef make_osc_client(port, ip=\"127.0.0.1\"):\r\n    return udp_client.SimpleUDPClient(ip, port)\r\n\r\n\r\ndef _drain_pose_queue(q):\r\n    items = []\r\n    while True:\r\n        try:\r\n            items.append(q.get_nowait())\r\n        except Empty:\r\n            break\r\n    return items\r\n\r\ndef begin_session(subject):\r\n    \"\"\"\r\n    Call this once at the beginning of a session to get:\r\n      - session_id (timestamp-based)\r\n      - base_index = current length of subject.trials\r\n    \"\"\"\r\n    now = f'{date.strftime(\"%d\")}.{date.strftime(\"%m\")}_{date.strftime(\"%H\")}.{date.strftime(\"%M\")}'\r\n    session_id = datetime.datetime.now().strftime(now)\r\n    base_index = len(subject.trials)\r\n    return {\"session_id\": session_id, \"base_index\": base_index}\r\n\r\ndef play_sound(osc_client, soundfile=None, duration=None, sleep=False):\r\n    \"\"\"Wrapper: set /pyBinSimFile to play a file (or synthesize pink noise pulses).\"\"\"\r\n    if duration:\r\n        if soundfile:\r\n            sound = slab.Sound.read(HRIR_DIR / \"sounds\" / soundfile)\r\n            soundfile = \"cropped_\" + soundfile\r\n            (slab.Sound(sound.data[: int(hrir.samplerate * duration)])\r\n             .ramp(duration=0.03)\r\n             .write(HRIR_DIR / \"sounds\" / soundfile))\r\n        else:\r\n            soundfile = \"noise_pulse.wav\"\r\n            slab.Sound.pinknoise(duration, level=77).ramp(duration=0.03).write(HRIR_DIR / \"sounds\" / soundfile)\r\n    else:\r\n        duration = slab.Sound(HRIR_DIR / \"sounds\" / soundfile).duration\r\n    logging.debug(f\"Setting soundfile: {soundfile}\")\r\n    osc_client.send_message(\"/pyBinSimFile\", str(HRIR_DIR / \"sounds\" / soundfile))\r\n    if sleep:\r\n        time.sleep(duration)\r\n\r\ndef distance_to_interval(distance):\r\n    max_interval = 350\r\n    min_interval = 75\r\n    steepness = 5\r\n    max_distance = numpy.linalg.norm(numpy.subtract([0, 0], [settings[\"az_range\"][0], settings[\"ele_range\"][0]]))\r\n    if distance <= settings[\"target_size\"]:\r\n        return 0\r\n    norm_dist = (distance - settings[\"target_size\"]) / (max_distance - settings[\"target_size\"])\r\n    norm_dist = numpy.clip(norm_dist, 0, 1)\r\n    scale = numpy.log1p(steepness * norm_dist) / numpy.log1p(steepness)\r\n    interval = (min_interval + (max_interval - min_interval) * scale).astype(int)\r\n    return int(interval) / 1000\r\n\r\ndef plot_current_tf(filter_idx_shared, redraw_interval_s=0.05, kind=SHOW_TF):\r\n    \"\"\"\r\n    Lives in its own process. Opens a Qt figure and plots the TF of the\r\n    current HRTF (hrir[filter_idx]) whenever the filter index changes.\r\n    \"\"\"\r\n    # Reuse global `hrir` and its sources\r\n    global hrir\r\n    sources = hrir.sources.vertical_polar  # (N,3), az in [0..360), el linear\r\n    plt.ion()\r\n    fig, ax = plt.subplots(figsize=(7, 4))\r\n    if kind == 'TF':\r\n        ax.set_title(\"Current Transfer Function\")\r\n    if kind == 'IR':\r\n        ax.set_title(\"Current Impulse Response\")\r\n    fig.canvas.manager.set_window_title(f\"Live HR{kind}\")\r\n    last_idx = -1\r\n    while True:\r\n        idx = filter_idx_shared.value\r\n        if idx >= 0 and idx != last_idx:\r\n            last_idx = idx\r\n            try:\r\n                # Clear and replot using slab's built-in viz\r\n                ax.cla()\r\n                # slab.HRTF slice → .tf(show=True, axis=ax) will draw on provided axis\r\n                if kind == 'TF':\r\n                    hrir[idx].channel(0).tf(show=True, axis=ax)\r\n                    hrir[idx].channel(1).tf(show=True, axis=ax)\r\n                    ax.lines[0].set_label('left')\r\n                    ax.lines[1].set_label('right')\r\n                    ax.legend()\r\n                elif kind == 'IR':\r\n                    times = numpy.linspace(0, hrir[idx].n_samples / hrir.samplerate, hrir[idx].n_samples)\r\n                    ax.plot(times, hrir[idx].data[:, 0], label='left')\r\n                    ax.plot(times, hrir[idx].data[:, 1], label='right')\r\n                    ax.legend(loc='upper right')\r\n                # Add some context (az, el)\r\n                az0, el0 = sources[idx, 0], sources[idx, 1]\r\n                az180 = (az0 + 180) % 360 - 180  # to (-180,180]\r\n                ax.set_title(f\"{kind} idx {idx}  |  az={az180:.1f}°, el={el0:.1f}°\")\r\n                ax.grid(True, which='both', linestyle=':', linewidth=0.6)\r\n                fig.canvas.draw_idle()\r\n                plt.pause(0.001)\r\n            except Exception as e:\r\n                # Keep the loop alive even if one plot fails\r\n                ax.cla()\r\n                ax.text(0.5, 0.5, f\"Plot error for idx {idx}:\\n{e}\", ha='center', va='center')\r\n                fig.canvas.draw_idle()\r\n                plt.pause(0.001)\r\n\r\n        # Throttle the loop to avoid pegging a CPU core\r\n        plt.pause(redraw_interval_s)\r\n\r\n# -------------------- Subprocess workers --------------------\r\ndef binsim_stream():\r\n    import pybinsim\r\n    pybinsim.logger.setLevel(logging.WARNING)\r\n    logging.info(f\"Loading {hrir.name}\")\r\n    binsim = pybinsim.BinSim(HRIR_DIR / f\"{hrir.name}_training_settings.txt\")\r\n    binsim.stream_start()\r\n\r\ndef pulse_maker(pulse_interval, pulse_state):\r\n    \"\"\"state: 0 mute, 1 idle, 2 play pulses; interval in seconds (0 => continuous target sound)\"\"\"\r\n    osc = make_osc_client(port=10003)\r\n    target_sound = False\r\n    while True:\r\n        if pulse_state.value == 0:\r\n            osc.send_message(\"/pyBinSimLoudness\", 0)\r\n            target_sound = False\r\n        elif pulse_state.value == 1:\r\n            target_sound = False\r\n        elif pulse_state.value == 2:\r\n            osc.send_message(\"/pyBinSimLoudness\", settings[\"gain\"])\r\n            interval = pulse_interval.value\r\n            if interval == 0 and not target_sound:\r\n                play_sound(osc, soundfile=SOUND_FILE, duration=float(settings[\"target_time\"]), sleep=False)\r\n                target_sound = True\r\n            elif interval != 0:\r\n                play_sound(osc, soundfile=SOUND_FILE, duration=float(interval), sleep=True)\r\n                time.sleep(interval)\r\n                target_sound = False\r\n        time.sleep(0.02)\r\n\r\ndef head_tracker(distance, target, sensor_state, pose_queue, current_trial, plot_filter_idx):\r\n    import logging\r\n    logging.getLogger().setLevel('INFO')\r\n    osc = make_osc_client(port=10000)\r\n    hrtf_sources = hrir.sources.vertical_polar\r\n    #init motion sensor\r\n    device = meta_motion.get_device()\r\n    state = meta_motion.State(device)\r\n    motion_sensor = meta_motion.Sensor(state)\r\n    logging.debug('motion sensor running')\r\n    sensor_state.value = 1  # init flag\r\n    while True:\r\n        if sensor_state.value == 2:  # to be calibrated flag\r\n            logging.debug('Calibrating sensor..')\r\n            motion_sensor.calibrate()\r\n            while not motion_sensor.is_calibrated:\r\n                time.sleep(0.1)\r\n            sensor_state.value = 1\r\n            last_idx = -1\r\n        elif sensor_state.value == 3:\r\n            pose = motion_sensor.get_pose()\r\n            pose_raw = numpy.array((motion_sensor.state.pose.yaw, motion_sensor.state.pose.roll))\r\n            logging.debug(f'raw sensor headpose read out: {pose_raw}')\r\n            # set distance for play_session\r\n            try:\r\n                # store: (t_monotonic, current_trial_id, yaw, pitch, roll)\r\n                pose_queue.put((\r\n                    time.time(),\r\n                    int(current_trial.value),\r\n                    float(pose[0]), float(pose[1])\r\n                ))\r\n            except Exception:\r\n                pass\r\n            rel = target[:] - pose\r\n            distance.value = numpy.linalg.norm(rel)\r\n            # find closest HRTF index and send to BinSim\r\n            rel[0] = (-rel[0] + 360) % 360\r\n            rel_target = numpy.array((rel[0], rel[1], hrtf_sources[0, 2]))\r\n            filter_idx = numpy.argmin(numpy.linalg.norm(rel_target - hrtf_sources, axis=1))\r\n            rel_hrtf_coords = hrtf_sources[filter_idx]\r\n            if filter_idx != last_idx:\r\n                osc.send_message('/pyBinSim_ds_Filter', [0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n                                                         float(rel_hrtf_coords[0]), float(rel_hrtf_coords[1]), 0,\r\n                                                         0, 0, 0])\r\n                last_idx = filter_idx\r\n                if plot_filter_idx is not None:\r\n                    plot_filter_idx.value = int(filter_idx)\r\n        time.sleep(0.02)\r\n\r\ndef play_trial(subject, trial_idx, current_trial, target, distance, pulse_interval, pulse_state, sensor_state,\r\n               game_time_left, game_timer, session_total, last_goal_points, pose_queue):\r\n    \"\"\"\r\n    Returns: (game_timer, score)\r\n    \"\"\"\r\n    # Wait-for-Enter phase handled outside this function.\r\n    current_trial.value = int(trial_idx)\r\n\r\n    # optional: clear old samples so we only keep this trial's data\r\n    _ = _drain_pose_queue(pose_queue)\r\n\r\n    # Start tracking\r\n    score = 0\r\n    trial_timer = 0.0\r\n    time_on_target = 0.0\r\n    count_down = False\r\n\r\n    sensor_state.value = 2  # calibrate\r\n    time.sleep(0.1)\r\n    while not sensor_state.value == 3:\r\n        sensor_state.value = 3\r\n        time.sleep(0.05)\r\n\r\n    # Start pulser\r\n    pulse_interval.value = distance_to_interval(distance.value)\r\n    time.sleep(0.2)\r\n    pulse_state.value = 2\r\n\r\n    logging.debug(\"Starting trial\")\r\n    t0 = time.time()\r\n    while trial_timer < settings['trial_time']:\r\n        trial_timer = time.time() - t0\r\n        if game_timer + trial_timer > settings['game_time']:\r\n            break\r\n\r\n        # update UI timer\r\n        game_time_left.value = max(0.0, settings['game_time'] - (game_timer + trial_timer))\r\n\r\n        # pulse interval based on distance\r\n        pulse_interval.value = distance_to_interval(distance.value)\r\n\r\n        # target window / scoring\r\n        if distance.value < settings['target_size']:\r\n            if not count_down:\r\n                time_on_target, count_down = time.time(), True\r\n        else:\r\n            time_on_target, count_down = time.time(), False\r\n\r\n        if count_down and time.time() > time_on_target + settings['target_time']:  # goal condition\r\n            pulse_state.value = 1  # stop pulse loop (idle but don't mute)\r\n\r\n            # Decide score & file\r\n            if trial_timer <= settings['score_time']:\r\n                score = 2\r\n                sfile = 'coins.wav'\r\n                min_audible = 0.35   # let the double-coin poke through\r\n            else:\r\n                score = 1\r\n                sfile = 'coin.wav'\r\n                min_audible = 0.25   # brief head start for single coin\r\n\r\n            # 1) UI immediately (coin pop + score bump)\r\n            last_goal_points.value = score\r\n            session_total.value = int(session_total.value + score)\r\n\r\n            # 2) Make sure loudness is up for SFX and trigger sound non-blocking\r\n            osc_client.send_message('/pyBinSimLoudness', settings['gain'])\r\n\r\n            # Non-blocking SFX trigger\r\n            play_sound(osc_client, soundfile=sfile, duration=None, sleep=False)\r\n\r\n            # 3) Give the SFX a short head-start before we exit/mute\r\n            # read actual duration (safe if file is present)\r\n            actual_dur = slab.Sound(HRIR_DIR / 'sounds' / sfile).duration\r\n            time.sleep( actual_dur)\r\n\r\n            break\r\n\r\n        time.sleep(0.02)\r\n\r\n    t1 = time.time()\r\n    logging.info(f\"Score: {score}\")\r\n    game_timer += trial_timer\r\n    pulse_state.value = 0\r\n    sensor_state.value = 1\r\n\r\n    # Collect pose samples; keep those for our trial id & time window\r\n    raw = _drain_pose_queue(pose_queue)\r\n    # raw items are (t_monotonic, trial_id, yaw, pitch, roll)\r\n    trace = [(t, yaw, pitch,) for (t, tid, yaw, pitch) in raw\r\n             if (tid == trial_idx) and (t0 <= t <= t1)]\r\n\r\n    # Store on subject\r\n    trial_dict = {\r\n        \"trial_idx\": int(trial_idx),\r\n        \"target\": tuple(target.tolist() if hasattr(target, \"tolist\") else target),\r\n        \"pose_trace\": trace,  # [(t, yaw, pitch, roll), ...]\r\n        \"duration\": float(game_timer),\r\n        # add session id if you used begin_session():\r\n        \"session_id\": globals().get(\"_current_session_id\", None)\r\n    }\r\n    if trial_idx == len(subject.trials):\r\n        subject.trials.append(trial_dict)\r\n    elif 0 <= trial_idx < len(subject.trials):\r\n        subject.trials[trial_idx].update(trial_dict)\r\n    else:\r\n        while len(subject.trials) < (trial_idx + 1):\r\n            subject.trials.append({})\r\n        subject.trials[trial_idx] = trial_dict\r\n    subject.write()\r\n    return game_timer, score\r\n\r\n\r\ndef play_session():\r\n    \"\"\"\r\n    Main loop: start workers, then run until game_time.\r\n    \"\"\"\r\n    global osc_client\r\n    osc_client = make_osc_client(port=10003)\r\n    subject = Subject(SUBJECT_ID)\r\n    sequence = subject.last_sequence\r\n\r\n    if sequence:\r\n        az_range = tuple(sequence.settings[\"azimuth_range\"])\r\n        ele_range = tuple(sequence.settings[\"elevation_range\"])\r\n        logging.info(\"Using sequence-based target ranges: az=%s el=%s\", az_range, ele_range)\r\n    else:\r\n        az_range = (-35, 35)\r\n        ele_range = (-35, 35)\r\n        logging.info(\"Using default target ranges: az=%s el=%s\", az_range, ele_range)\r\n\r\n    global settings\r\n    settings = dict(settings, az_range=az_range, ele_range=ele_range)\r\n\r\n    # Shared state for workers\r\n    sensor_state    = mp.Value(\"i\", 0)\r\n    pulse_state     = mp.Value(\"i\", 0)\r\n    target          = mp.Array(\"f\", [0.0, 0.0])\r\n    distance        = mp.Value(\"f\", 0.0)\r\n    pulse_interval  = mp.Value(\"f\", 0.0)\r\n    plot_filter_idx = mp.Value(\"i\", -1)\r\n    current_trial = mp.Value('i', -1)  # -1 = no active trial\r\n    pose_queue = mp.Queue(maxsize=10000)\r\n\r\n    # UI shared state\r\n    current_score   = mp.Value(\"i\", 0)   # optional (not used directly)\r\n    session_total   = mp.Value(\"i\", 0)   # what we display as the big number\r\n    game_time_left  = mp.Value(\"f\", float(settings[\"game_time\"]))\r\n    trial_time_left = mp.Value(\"f\", float(settings[\"trial_time\"]))\r\n    last_goal_points = mp.Value(\"i\", 0)  # 0/1/2 → UI coin animation trigger\r\n    enter_pressed    = mp.Value(\"i\", 0)  # UI sets to 1 when user presses Enter\r\n    ui_state         = mp.Value(\"i\", 0)  # 0 idle, 1 awaiting enter, 2 running, 3 over\r\n\r\n    # Highscore persistence via Subject\r\n    prev_high = int(getattr(subject, \"highscore\", 0))\r\n    highscore = mp.Value(\"i\", prev_high)\r\n\r\n    # Start UI\r\n    shared = game_ui.UIShared(\r\n        current_score=current_score,\r\n        game_time_left=game_time_left,\r\n        trial_time_left=trial_time_left,\r\n        last_goal_points=last_goal_points,\r\n        session_total=session_total,\r\n        enter_pressed=enter_pressed,\r\n        ui_state=ui_state,\r\n        highscore=highscore)\r\n    ui_proc = mp.Process(target=game_ui.run_ui, args=(shared, ROOT / \"data\" / \"ui\" / \"highscores.json\"))\r\n    ui_proc.start()\r\n\r\n    # Start workers\r\n    tracking_worker = mp.Process(target=head_tracker, args=(distance, target, sensor_state, pose_queue,\r\n                                                            current_trial, plot_filter_idx))\r\n    tracking_worker.start()\r\n    binsim_worker = mp.Process(target=binsim_stream, args=())\r\n    binsim_worker.start()\r\n    pulse_worker = mp.Process(target=pulse_maker, args=(pulse_interval, pulse_state))\r\n    pulse_worker.start()\r\n\r\n    if SHOW_TF:  # start plot_worker\r\n        plot_worker = mp.Process(target=plot_current_tf, args=(plot_filter_idx, 0.05, SHOW_TF), daemon=True)\r\n        plot_worker.start()\r\n\r\n    # Wait for tracker init\r\n    while sensor_state.value != 1:\r\n        time.sleep(0.05)\r\n\r\n    try:\r\n        while True:  # multiple sessions\r\n            # Reset per-session state\r\n            session_total.value = 0\r\n            last_goal_points.value = 0\r\n            game_time_left.value = float(settings[\"game_time\"])\r\n            enter_pressed.value = 0\r\n\r\n            # --- PRE-SESSION PROMPT ---\r\n            ui_state.value = 1  # waiting to start\r\n            while enter_pressed.value == 0:\r\n                time.sleep(0.05)\r\n            enter_pressed.value = 0\r\n\r\n            scores = []\r\n            game_timer = 0.0\r\n            game_time_left.value = float(settings[\"game_time\"])\r\n\r\n            while game_timer < settings[\"game_time\"]:\r\n                # init new session for recording\r\n                sess = begin_session(subject)\r\n                globals()[\"_current_session_id\"] = sess['session_id']\r\n                trial_idx = sess[\"base_index\"] + 1\r\n\r\n                # pick next target\r\n                try:\r\n                    set_target_probabilistic(target, settings, sequence, hrir)\r\n                except AttributeError:\r\n                    logging.debug(\"Could not load target probabilities\")\r\n\r\n                # show \"Press Enter\" overlay and wait for user\r\n                ui_state.value = 1\r\n                enter_pressed.value = 0\r\n                while enter_pressed.value == 0:\r\n                    # keep updating UI timer while we wait\r\n                    game_time_left.value = max(0.0, float(settings[\"game_time\"]) - game_timer)\r\n                    time.sleep(0.05)\r\n                # start trial\r\n                ui_state.value = 2\r\n                enter_pressed.value = 0\r\n\r\n                game_timer, score = play_trial(subject, trial_idx, current_trial, target, distance, pulse_interval,\r\n                                               pulse_state, sensor_state, game_time_left, game_timer, session_total,\r\n                                               last_goal_points, pose_queue)\r\n                scores.append(score)\r\n                # update high score live; persist to Subject\r\n                if session_total.value > highscore.value:\r\n                    play_sound(osc_client, soundfile='hi_score.wav', duration=None, sleep=True)\r\n                    highscore.value = int(session_total.value)\r\n                    setattr(subject, \"highscore\", int(highscore.value))\r\n                    subject.write()  # your Subject.write() persists object\r\n\r\n                # if time is up, break\r\n                if game_timer >= settings[\"game_time\"]:\r\n                    break\r\n\r\n            # end\r\n            ui_state.value = 3\r\n            pulse_state.value = 1  # idle\r\n            play_sound(osc_client, soundfile='buzzer.wav', duration=None, sleep=True)\r\n            logging.info(f\"Game Over! Total Score: {int(session_total.value)}\")\r\n\r\n            # Show play-again prompt (same big overlay, different text)\r\n            ui_state.value = 3  # session over → \"Press Enter to play again\"\r\n            enter_pressed.value = 0\r\n            # wait for Enter to start next session\r\n            while enter_pressed.value == 0:\r\n                time.sleep(0.05)\r\n            enter_pressed.value = 0\r\n            # loop continues -> new session\r\n\r\n    finally:\r\n        try:\r\n            # Clean up workers\r\n            pulse_state.value = 0\r\n            logging.info(\"Ending\")\r\n            binsim_worker.join()\r\n            pulse_worker.join()\r\n            tracking_worker.join()\r\n            ui_proc.terminate()\r\n            ui_proc.join()\r\n            binsim_worker.terminate()\r\n            pulse_worker.terminate()\r\n            tracking_worker.terminate()\r\n        except Exception:\r\n            pass\r\n        try:\r\n            ui_proc.terminate()\r\n            ui_proc.join()\r\n        except Exception:\r\n            pass\r\n\r\n\r\n\r\n\r\n# -------------------- Main --------------------\r\n\r\nif __name__ == \"__main__\":\r\n    try:\r\n        play_session()\r\n    except KeyboardInterrupt:\r\n        print(\"\\n[Training] Interrupted by user. Shutting down.\")\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/hrtf_relearning/experiment/Training.py b/hrtf_relearning/experiment/Training.py
--- a/hrtf_relearning/experiment/Training.py	(revision 35b6c9d32c06070f14b9010b7ce999b399df6fa3)
+++ b/hrtf_relearning/experiment/Training.py	(date 1769679650846)
@@ -19,7 +19,7 @@
 
 
 # -------------------- Config --------------------
-SUBJECT_ID = "JZ"
+SUBJECT_ID = "test"
 HRIR_NAME = "JZ"  # 'KU100', 'kemar', etc.
 EAR = 'left'              # or None for binaural
 HP = 'MYSPHERE'
@@ -28,15 +28,15 @@
 SOUND_FILE = None         # None -> pink noise pulses; or 'uso_225ms_9_.wav', etc.
 # Graphics
 show_ui = True  # todo
-SHOW_TF = False  # set to TF or IR to spawn live filter plot
+SHOW_TF = True  # set to TF or IR to spawn live filter plot
 
 # Game settings
 settings = dict(
-    target_size=3,
+    target_size=6,
     target_time=0.5,
     min_dist=30,
     game_time=90,
-    trial_time=10,
+    trial_time=20,
     score_time=6,
     gain=.15)
 
Index: hrtf_relearning/experiment/Localization.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import multiprocessing as mp\r\nimport hrtf_relearning as hr\r\nimport datetime\r\nimport time\r\nfrom pathlib import Path\r\nfrom hrtf_relearning.experiment.analysis.localization.localization_analysis import *\r\nfrom hrtf_relearning.experiment.misc.localization_helpers.make_sequence import *\r\nfrom hrtf_relearning.experiment.misc.localization_helpers.uso_generation import generate_uso\r\nfrom pythonosc import udp_client\r\nfrom hrtf_relearning.experiment.misc.training_helpers import meta_motion\r\nfrom hrtf_relearning.hrtf.binsim.hrtf2binsim import hrtf2binsim\r\nfrom pynput import keyboard\r\ndate = datetime.datetime.now()\r\ndate = f'{date.strftime(\"%d\")}.{date.strftime(\"%m\")}_{date.strftime(\"%H\")}:{date.strftime(\"%M\")}'\r\nlogging.getLogger().setLevel('INFO')\r\nROOT = hr.PATH\r\n\r\n# --- settings ----\r\nSUBJECT_ID = \"JZ\"\r\nHRIR_NAME = \"JZ\"  # 'KU100', 'kemar', etc.\r\nEAR = 'left'\r\nSTIM = 'noise'  # 'noise' or 'uso'\r\nHP = 'MYSPHERE'\r\n\r\n# --- load and process HRIR\r\nhrir = hrtf2binsim(HRIR_NAME, EAR,\r\n    reverb=True, drr=20,\r\n    hp_filter=True, hp=HP,\r\n    convolution=\"cuda\", storage=\"cuda\")\r\nslab.set_default_samplerate(hrir.samplerate)\r\nHRIR_DIR = (ROOT / \"data\" / \"hrtf\" / \"binsim\"\r\n            / hrir.name)\r\nsubject = hr.Subject(SUBJECT_ID)\r\n\r\nclass Localization:\r\n    \"\"\"\r\n    Localization test:\r\n        Test localization at uniformly random positions within sectors\r\n    \"\"\"\r\n    def __init__(self, subject, hrir):\r\n        # make trial sequence and write to subject\r\n\r\n        self.settings = {'kind': 'sectors',\r\n                         'azimuth_range': (-35, 35), 'elevation_range': (-35, 35),\r\n                         'sector_size': (14, 14),\r\n                         'targets_per_sector': 3, 'replace': False, 'min_distance': 30,\r\n                         'gain': .2}\r\n        # alternative setting: play 3 times from each source in the hrir (works well for dome recorded hrirs)\r\n        # self.settings = {'kind': 'standard', 'azimuth_range': (-60, 60), 'elevation_range': (-40, 40),\r\n        #                  'targets_per_speaker': 3, 'min_distance': 10, 'gain': .2}\r\n        self.subject = subject\r\n        self.filename = subject.id + date\r\n        # metadata\r\n        slab.set_default_samplerate(hrir.samplerate)\r\n        self.hrir_sources = hrir.sources.vertical_polar\r\n        self.sound_path = ROOT / 'data' / 'hrtf' / 'binsim' / hrir.name / 'sounds'\r\n        self.target = None\r\n\r\n        # make sequence\r\n        self.sequence = make_sequence(self.settings, self.hrir_sources)\r\n        self.sequence.name = self.filename\r\n        self.sequence.hrir = hrir.name\r\n        self.sequence.ear = EAR\r\n        self.sequence.stim = STIM\r\n\r\n    def write(self):\r\n        self.subject.localization[self.filename] = self.sequence\r\n        self.subject.write()\r\n\r\n    def run(self):\r\n        # init pybinsim\r\n        self.osc_client_1 = self._make_osc_client(port=10000)\r\n        self.osc_client_2 = self._make_osc_client(port=10003)\r\n        self.binsim_worker = mp.Process(target=self._binsim_stream, args=(hrir.name,))\r\n        self.binsim_worker.start()\r\n\r\n        # init motion sensor\r\n        self.motion_sensor = self.init_sensor()\r\n        time.sleep(.2)\r\n\r\n        self.play_sound('beep')\r\n        for self.target in self.sequence:\r\n            self.wait_for_button('Look at the Center and press Enter')\r\n            self.motion_sensor.calibrate()\r\n            self.play_trial()  # generate and play stim, get pose response and write to file\r\n        self.subject.last_sequence = self.sequence\r\n        self.sequence.response_errors = target_p(self.sequence, show=False)\r\n        self.write()\r\n        logging.info('Finished.')\r\n        return\r\n\r\n    def play_trial(self):\r\n        # generate stimulus\r\n        self.stim = self.make_stim()  # generate a new stim each trial\r\n        self.stim.write(self.sound_path / 'localization.wav')\r\n        # play stim\r\n        self.play_stimulus()\r\n        time.sleep(self.stim.duration)\r\n        # get response\r\n        self.wait_for_button()\r\n        response = self.motion_sensor.get_pose()\r\n        progress = self.sequence.this_n / len(self.sequence.conditions) * 100\r\n        logging.info(f'{progress:.1f}% | Target: {self.target} | Response: {response}')\r\n        time.sleep(.25)\r\n        self.sequence.add_response(numpy.array((response, self.target)))\r\n        self.write()  # write to file\r\n\r\n    def play_stimulus(self):\r\n        pose = self.motion_sensor.get_pose()\r\n        relative_coords = self.target - pose  # mimic freefield setup\r\n        # find the closest filter idx and send to pybinsim\r\n        relative_coords[0] = (-relative_coords[0] + 360) % 360  # mirror and convert to HRTF convention [0 < az < 360]\r\n        rel_target = numpy.array((relative_coords[0], relative_coords[1], self.hrir_sources[0, 2]))\r\n        filter_idx = numpy.argmin(numpy.linalg.norm(rel_target - self.hrir_sources, axis=1))\r\n        rel_hrtf_coords = self.hrir_sources[filter_idx]\r\n        self.osc_client_1.send_message('/pyBinSim_ds_Filter', [0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n                                                        float(rel_hrtf_coords[0]), float(rel_hrtf_coords[1]), 0,\r\n                                                        0, 0, 0])\r\n        logging.debug(f'Set filter for {self.hrir_sources[filter_idx]}')\r\n        # play\r\n        self.osc_client_2.send_message('/pyBinSimLoudness', self.settings['gain'])\r\n        self.osc_client_2.send_message('/pyBinSimFile', str(self.sound_path / 'localization.wav'))\r\n        time.sleep(.5)\r\n        self.osc_client_2.send_message('/pyBinSimLoudness', 0)\r\n\r\n    def play_sound(self, kind):\r\n        logging.info(f'Playing {kind} sound')\r\n        name = f'{kind}.wav'\r\n        duration = slab.Sound(self.sound_path / name).duration\r\n        self.osc_client_2.send_message('/pyBinSimLoudness', self.settings['gain'])\r\n        self.osc_client_2.send_message('/pyBinSimFile', str(self.sound_path / name))\r\n        time.sleep(duration)\r\n        self.osc_client_2.send_message('/pyBinSimLoudness', 0)\r\n\r\n    @staticmethod\r\n    def _make_osc_client(port, ip='127.0.0.1'):\r\n        return udp_client.SimpleUDPClient(ip, port)\r\n\r\n    @staticmethod\r\n    def _binsim_stream(hrir_name):\r\n        import pybinsim\r\n        pybinsim.logger.setLevel(logging.ERROR)\r\n        binsim = pybinsim.BinSim(ROOT / 'data'  / 'hrtf' / 'binsim' / hrir_name / f'{hrir_name}_test_settings.txt')\r\n        binsim.stream_start()  # run binsim loop\r\n\r\n    @staticmethod\r\n    def init_sensor():\r\n        # init motion sensor\r\n        device = meta_motion.get_device()  # Ensure this function initializes the hardware correctly\r\n        state = meta_motion.State(device)\r\n        return meta_motion.Sensor(state)\r\n\r\n    @staticmethod\r\n    def make_stim():\r\n        if STIM == 'noise':\r\n            stim = slab.Sound.pinknoise(duration=0.225, level=80).ramp(when='both', duration=0.01)\r\n            n_silent = (numpy.arange(25,221,25).reshape(4,2) * stim.samplerate / 1000).astype(int)\r\n            ramp_len = int(.005 * stim.samplerate)\r\n            half_len = int(ramp_len / 2)\r\n            for start, end in n_silent:\r\n                ramp_up = 0.5 * (1 - numpy.cos(numpy.linspace(0, numpy.pi, ramp_len)))\r\n                ramp_down = 0.5 * (1 - numpy.cos(numpy.linspace(numpy.pi, 0, ramp_len)))\r\n                ramp_up = ramp_up[:, numpy.newaxis]\r\n                ramp_down = ramp_down[:, numpy.newaxis]\r\n                # Apply ramps at the edges of the silent region\r\n                stim.data[start - half_len: start + half_len] *= (1 - ramp_up)\r\n                stim.data[end - half_len: end + half_len] *= (1 - ramp_down)\r\n                # Silence the center\r\n                stim.data[start + half_len: end - half_len] = 0\r\n            # stim = slab.Sound.pinknoise(duration=0.5, level=90).ramp(when='both', duration=0.01)\r\n            # noise = slab.Sound.pinknoise(duration=0.025, level=90)\r\n            # noise = noise.ramp(when='both', duration=0.01)\r\n            # silence = slab.Sound.silence(duration=0.025)\r\n            # stim = slab.Sound.sequence(noise, silence, noise, silence, noise,\r\n            #                            silence, noise, silence, noise)\r\n            # stim.ramp('both', 0.01)\r\n        elif STIM == 'uso':\r\n            stim = generate_uso(samplerate=hrir.samplerate)\r\n        else: raise ValueError('STIM must be \"noise\" or \"uso\".')\r\n        stim.level = 80\r\n        return stim\r\n\r\n    @staticmethod\r\n    def wait_for_button(msg=None):\r\n        if msg: print(msg)\r\n        def on_press(key):\r\n            if key == keyboard.Key.enter:\r\n                listener.stop()  # stop listening once Enter is pressed\r\n        with keyboard.Listener(on_press=on_press) as listener:\r\n            listener.join()  # block until listener.stop() is called\r\n\r\nif __name__ == \"__main__\":\r\n    loc_test = Localization(subject, hrir)\r\n    loc_test.run()\r\n    sequence = subject.localization[loc_test.filename]\r\n    plot_localization(sequence, report_stats=['azimuth', 'elevation'], filepath=ROOT / 'data'  / 'results' / 'plot' / subject.id)\r\n    plot_elevation_response(sequence, filepath=ROOT / 'data'  / 'results' / 'plot' / subject.id)
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/hrtf_relearning/experiment/Localization.py b/hrtf_relearning/experiment/Localization.py
--- a/hrtf_relearning/experiment/Localization.py	(revision 35b6c9d32c06070f14b9010b7ce999b399df6fa3)
+++ b/hrtf_relearning/experiment/Localization.py	(date 1769619820826)
@@ -41,7 +41,7 @@
         # make trial sequence and write to subject
 
         self.settings = {'kind': 'sectors',
-                         'azimuth_range': (-35, 35), 'elevation_range': (-35, 35),
+                         'azimuth_range': (-35, 0), 'elevation_range': (-35, 35),
                          'sector_size': (14, 14),
                          'targets_per_sector': 3, 'replace': False, 'min_distance': 30,
                          'gain': .2}
Index: .idea/shelf/Uncommitted_changes_before_Update_at_1_20_2026_9_12_AM__Changes_.xml
===================================================================
diff --git a/.idea/shelf/Uncommitted_changes_before_Update_at_1_20_2026_9_12_AM__Changes_.xml b/.idea/shelf/Uncommitted_changes_before_Update_at_1_20_2026_9_12_AM__Changes_.xml
deleted file mode 100644
--- a/.idea/shelf/Uncommitted_changes_before_Update_at_1_20_2026_9_12_AM__Changes_.xml	(revision 35b6c9d32c06070f14b9010b7ce999b399df6fa3)
+++ /dev/null	(revision 35b6c9d32c06070f14b9010b7ce999b399df6fa3)
@@ -1,20 +0,0 @@
-<changelist name="Uncommitted_changes_before_Update_at_1_20_2026_9_12_AM_[Changes]" date="1768896857260" recycled="true" deleted="true">
-  <option name="PATH" value="$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Update_at_1_20_2026_9_12_AM_[Changes]/shelved.patch" />
-  <option name="DESCRIPTION" value="Uncommitted changes before Update at 1/20/2026 9:12 AM [Changes]" />
-  <binary>
-    <option name="BEFORE_PATH" value="hrtf_relearning/data/results/paul.pkl" />
-    <option name="AFTER_PATH" value="hrtf_relearning/data/results/paul.pkl" />
-    <option name="SHELVED_PATH" value="$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Update_at_1_20_2026_9_12_AM_[Changes]/paul.pkl" />
-  </binary>
-  <binary>
-    <option name="BEFORE_PATH" value=".idea/shelf/Uncommitted_changes_before_Update_at_1_2_2026_5_52_PM_[Changes]/test.pkl" />
-  </binary>
-  <binary>
-    <option name="BEFORE_PATH" value=".idea/shelf/Uncommitted_changes_before_Update_at_1_2_2026_5_52_PM_[Changes]/AvS.pkl" />
-  </binary>
-  <binary>
-    <option name="BEFORE_PATH" value="hrtf_relearning/data/results/PF.pkl" />
-    <option name="AFTER_PATH" value="hrtf_relearning/data/results/PF.pkl" />
-    <option name="SHELVED_PATH" value="$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Update_at_1_20_2026_9_12_AM_[Changes]/PF.pkl" />
-  </binary>
-</changelist>
\ No newline at end of file
Index: .idea/shelf/Uncommitted_changes_before_Update_at_1_28_2026_12_03_PM__Changes_.xml
===================================================================
diff --git a/.idea/shelf/Uncommitted_changes_before_Update_at_1_28_2026_12_03_PM__Changes_.xml b/.idea/shelf/Uncommitted_changes_before_Update_at_1_28_2026_12_03_PM__Changes_.xml
deleted file mode 100644
--- a/.idea/shelf/Uncommitted_changes_before_Update_at_1_28_2026_12_03_PM__Changes_.xml	(revision 35b6c9d32c06070f14b9010b7ce999b399df6fa3)
+++ /dev/null	(revision 35b6c9d32c06070f14b9010b7ce999b399df6fa3)
@@ -1,4 +0,0 @@
-<changelist name="Uncommitted_changes_before_Update_at_1_28_2026_12_03_PM_[Changes]" date="1769598209732" recycled="false" toDelete="true">
-  <option name="PATH" value="$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Update_at_1_28_2026_12_03_PM_[Changes]/shelved.patch" />
-  <option name="DESCRIPTION" value="Uncommitted changes before Update at 1/28/2026 12:03 PM [Changes]" />
-</changelist>
\ No newline at end of file
Index: .idea/shelf/Uncommitted_changes_before_Update_at_1_20_2026_9_12_AM_[Changes]/shelved.patch
===================================================================
diff --git a/.idea/shelf/Uncommitted_changes_before_Update_at_1_20_2026_9_12_AM_[Changes]/shelved.patch b/.idea/shelf/Uncommitted_changes_before_Update_at_1_20_2026_9_12_AM_[Changes]/shelved.patch
deleted file mode 100644
--- a/.idea/shelf/Uncommitted_changes_before_Update_at_1_20_2026_9_12_AM_[Changes]/shelved.patch	(revision 35b6c9d32c06070f14b9010b7ce999b399df6fa3)
+++ /dev/null	(revision 35b6c9d32c06070f14b9010b7ce999b399df6fa3)
@@ -1,247 +0,0 @@
-Index: hrtf_relearning/experiment/Training.py
-IDEA additional info:
-Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
-<+>import matplotlib\r\nfrom matplotlib import pyplot as plt\r\nimport numpy\r\nimport time\r\nimport multiprocessing as mp\r\nfrom queue import Empty\r\nfrom pythonosc import udp_client\r\nimport datetime\r\ndate = datetime.datetime.now()\r\nimport hrtf_relearning\r\nROOT = hrtf_relearning.PATH\r\n\r\nfrom hrtf_relearning.experiment.misc.training_helpers import meta_motion, game_ui\r\nfrom hrtf_relearning.experiment.Subject import Subject\r\nfrom hrtf_relearning.experiment.misc.training_helpers.training_targets import set_target_probabilistic\r\nfrom hrtf_relearning.hrtf.binsim.hrtf2binsim import *\r\nmatplotlib.rcParams['figure.raise_window'] = False\r\nlogging.getLogger().setLevel('INFO')\r\n\r\n\r\n# -------------------- Config --------------------\r\nSUBJECT_ID = \"paul\"\r\nHRIR_NAME = \"universal\"  # 'KU100', 'kemar', etc.\r\nEAR = None              # or None for binaural\r\n\r\n# Sound\r\nSOUND_FILE = None         # None -> pink noise pulses; or 'uso_225ms_9_.wav', etc.\r\n# Graphics\r\nshow_ui = True  # todo\r\nSHOW_TF = False  # set to TF or IR to spawn live filter plot\r\n\r\n# Game settings\r\nsettings = dict(\r\n    target_size=3,\r\n    target_time=0.5,\r\n    min_dist=30,\r\n    game_time=90,\r\n    trial_time=15,\r\n    score_time=6,\r\n    gain=.15)\r\n\r\n# -------------------- Global HRIR/Sequence --------------------\r\nhrir = hrtf2binsim(HRIR_NAME, EAR,\r\n    reverb=True, drr=20,\r\n    hp_filter=True, hp_file=\"DT990_equalization.wav\",\r\n    convolution=\"cuda\", storage=\"cuda\")\r\nslab.set_default_samplerate(hrir.samplerate)\r\nHRIR_DIR = ROOT / \"data\" / \"hrtf\" / \"binsim\" / hrir.name\r\n\r\n\r\n\r\n# -------------------- Helpers --------------------\r\ndef make_osc_client(port, ip=\"127.0.0.1\"):\r\n    return udp_client.SimpleUDPClient(ip, port)\r\n\r\n\r\ndef _drain_pose_queue(q):\r\n    items = []\r\n    while True:\r\n        try:\r\n            items.append(q.get_nowait())\r\n        except Empty:\r\n            break\r\n    return items\r\n\r\ndef begin_session(subject):\r\n    \"\"\"\r\n    Call this once at the beginning of a session to get:\r\n      - session_id (timestamp-based)\r\n      - base_index = current length of subject.trials\r\n    \"\"\"\r\n    now = f'{date.strftime(\"%d\")}.{date.strftime(\"%m\")}_{date.strftime(\"%H\")}.{date.strftime(\"%M\")}'\r\n    session_id = datetime.datetime.now().strftime(now)\r\n    base_index = len(subject.trials)\r\n    return {\"session_id\": session_id, \"base_index\": base_index}\r\n\r\ndef play_sound(osc_client, soundfile=None, duration=None, sleep=False):\r\n    \"\"\"Wrapper: set /pyBinSimFile to play a file (or synthesize pink noise pulses).\"\"\"\r\n    if duration:\r\n        if soundfile:\r\n            sound = slab.Sound.read(HRIR_DIR / \"sounds\" / soundfile)\r\n            soundfile = \"cropped_\" + soundfile\r\n            (slab.Sound(sound.data[: int(hrir.samplerate * duration)])\r\n             .ramp(duration=0.03)\r\n             .write(HRIR_DIR / \"sounds\" / soundfile))\r\n        else:\r\n            soundfile = \"noise_pulse.wav\"\r\n            slab.Sound.pinknoise(duration, level=77).ramp(duration=0.03).write(HRIR_DIR / \"sounds\" / soundfile)\r\n    else:\r\n        duration = slab.Sound(HRIR_DIR / \"sounds\" / soundfile).duration\r\n    logging.debug(f\"Setting soundfile: {soundfile}\")\r\n    osc_client.send_message(\"/pyBinSimFile\", str(HRIR_DIR / \"sounds\" / soundfile))\r\n    if sleep:\r\n        time.sleep(duration)\r\n\r\ndef distance_to_interval(distance):\r\n    max_interval = 350\r\n    min_interval = 75\r\n    steepness = 5\r\n    max_distance = numpy.linalg.norm(numpy.subtract([0, 0], [settings[\"az_range\"][0], settings[\"ele_range\"][0]]))\r\n    if distance <= settings[\"target_size\"]:\r\n        return 0\r\n    norm_dist = (distance - settings[\"target_size\"]) / (max_distance - settings[\"target_size\"])\r\n    norm_dist = numpy.clip(norm_dist, 0, 1)\r\n    scale = numpy.log1p(steepness * norm_dist) / numpy.log1p(steepness)\r\n    interval = (min_interval + (max_interval - min_interval) * scale).astype(int)\r\n    return int(interval) / 1000\r\n\r\ndef plot_current_tf(filter_idx_shared, redraw_interval_s=0.05, kind=SHOW_TF):\r\n    \"\"\"\r\n    Lives in its own process. Opens a Qt figure and plots the TF of the\r\n    current HRTF (hrir[filter_idx]) whenever the filter index changes.\r\n    \"\"\"\r\n    # Reuse global `hrir` and its sources\r\n    global hrir\r\n    sources = hrir.sources.vertical_polar  # (N,3), az in [0..360), el linear\r\n    plt.ion()\r\n    fig, ax = plt.subplots(figsize=(7, 4))\r\n    if kind == 'TF':\r\n        ax.set_title(\"Current Transfer Function\")\r\n    if kind == 'IR':\r\n        ax.set_title(\"Current Impulse Response\")\r\n    fig.canvas.manager.set_window_title(f\"Live HR{kind}\")\r\n    last_idx = -1\r\n    while True:\r\n        idx = filter_idx_shared.value\r\n        if idx >= 0 and idx != last_idx:\r\n            last_idx = idx\r\n            try:\r\n                # Clear and replot using slab's built-in viz\r\n                ax.cla()\r\n                # slab.HRTF slice → .tf(show=True, axis=ax) will draw on provided axis\r\n                if kind == 'TF':\r\n                    hrir[idx].channel(0).tf(show=True, axis=ax)\r\n                    hrir[idx].channel(1).tf(show=True, axis=ax)\r\n                    ax.lines[0].set_label('left')\r\n                    ax.lines[1].set_label('right')\r\n                    ax.legend()\r\n                elif kind == 'IR':\r\n                    times = numpy.linspace(0, hrir[idx].n_samples / hrir.samplerate, hrir[idx].n_samples)\r\n                    ax.plot(times, hrir[idx].data[:, 0], label='left')\r\n                    ax.plot(times, hrir[idx].data[:, 1], label='right')\r\n                    ax.legend(loc='upper right')\r\n                # Add some context (az, el)\r\n                az0, el0 = sources[idx, 0], sources[idx, 1]\r\n                az180 = (az0 + 180) % 360 - 180  # to (-180,180]\r\n                ax.set_title(f\"{kind} idx {idx}  |  az={az180:.1f}°, el={el0:.1f}°\")\r\n                ax.grid(True, which='both', linestyle=':', linewidth=0.6)\r\n                fig.canvas.draw_idle()\r\n                plt.pause(0.001)\r\n            except Exception as e:\r\n                # Keep the loop alive even if one plot fails\r\n                ax.cla()\r\n                ax.text(0.5, 0.5, f\"Plot error for idx {idx}:\\n{e}\", ha='center', va='center')\r\n                fig.canvas.draw_idle()\r\n                plt.pause(0.001)\r\n\r\n        # Throttle the loop to avoid pegging a CPU core\r\n        plt.pause(redraw_interval_s)\r\n\r\n# -------------------- Subprocess workers --------------------\r\ndef binsim_stream():\r\n    import pybinsim\r\n    pybinsim.logger.setLevel(logging.WARNING)\r\n    logging.info(f\"Loading {hrir.name}\")\r\n    binsim = pybinsim.BinSim(HRIR_DIR / f\"{hrir.name}_training_settings.txt\")\r\n    binsim.stream_start()\r\n\r\ndef pulse_maker(pulse_interval, pulse_state):\r\n    \"\"\"state: 0 mute, 1 idle, 2 play pulses; interval in seconds (0 => continuous target sound)\"\"\"\r\n    osc = make_osc_client(port=10003)\r\n    target_sound = False\r\n    while True:\r\n        if pulse_state.value == 0:\r\n            osc.send_message(\"/pyBinSimLoudness\", 0)\r\n            target_sound = False\r\n        elif pulse_state.value == 1:\r\n            target_sound = False\r\n        elif pulse_state.value == 2:\r\n            osc.send_message(\"/pyBinSimLoudness\", settings[\"gain\"])\r\n            interval = pulse_interval.value\r\n            if interval == 0 and not target_sound:\r\n                play_sound(osc, soundfile=SOUND_FILE, duration=float(settings[\"target_time\"]), sleep=False)\r\n                target_sound = True\r\n            elif interval != 0:\r\n                play_sound(osc, soundfile=SOUND_FILE, duration=float(interval), sleep=True)\r\n                time.sleep(interval)\r\n                target_sound = False\r\n        time.sleep(0.02)\r\n\r\ndef head_tracker(distance, target, sensor_state, pose_queue, current_trial, plot_filter_idx):\r\n    import logging\r\n    logging.getLogger().setLevel('INFO')\r\n    osc = make_osc_client(port=10000)\r\n    hrtf_sources = hrir.sources.vertical_polar\r\n    #init motion sensor\r\n    device = meta_motion.get_device()\r\n    state = meta_motion.State(device)\r\n    motion_sensor = meta_motion.Sensor(state)\r\n    logging.debug('motion sensor running')\r\n    sensor_state.value = 1  # init flag\r\n    while True:\r\n        if sensor_state.value == 2:  # to be calibrated flag\r\n            logging.debug('Calibrating sensor..')\r\n            motion_sensor.calibrate()\r\n            while not motion_sensor.is_calibrated:\r\n                time.sleep(0.1)\r\n            sensor_state.value = 1\r\n            last_idx = -1\r\n        elif sensor_state.value == 3:\r\n            pose = motion_sensor.get_pose()\r\n            pose_raw = numpy.array((motion_sensor.state.pose.yaw, motion_sensor.state.pose.roll))\r\n            logging.debug(f'raw sensor headpose read out: {pose_raw}')\r\n            # set distance for play_session\r\n            try:\r\n                # store: (t_monotonic, current_trial_id, yaw, pitch, roll)\r\n                pose_queue.put((\r\n                    time.time(),\r\n                    int(current_trial.value),\r\n                    float(pose[0]), float(pose[1])\r\n                ))\r\n            except Exception:\r\n                pass\r\n            rel = target[:] - pose\r\n            distance.value = numpy.linalg.norm(rel)\r\n            # find closest HRTF index and send to BinSim\r\n            rel[0] = (-rel[0] + 360) % 360\r\n            rel_target = numpy.array((rel[0], rel[1], hrtf_sources[0, 2]))\r\n            filter_idx = numpy.argmin(numpy.linalg.norm(rel_target - hrtf_sources, axis=1))\r\n            rel_hrtf_coords = hrtf_sources[filter_idx]\r\n            if filter_idx != last_idx:\r\n                osc.send_message('/pyBinSim_ds_Filter', [0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n                                                         float(rel_hrtf_coords[0]), float(rel_hrtf_coords[1]), 0,\r\n                                                         0, 0, 0])\r\n                last_idx = filter_idx\r\n                if plot_filter_idx is not None:\r\n                    plot_filter_idx.value = int(filter_idx)\r\n        time.sleep(0.02)\r\n\r\ndef play_trial(subject, trial_idx, current_trial, target, distance, pulse_interval, pulse_state, sensor_state,\r\n               game_time_left, game_timer, session_total, last_goal_points, pose_queue):\r\n    \"\"\"\r\n    Returns: (game_timer, score)\r\n    \"\"\"\r\n    # Wait-for-Enter phase handled outside this function.\r\n    current_trial.value = int(trial_idx)\r\n\r\n    # optional: clear old samples so we only keep this trial's data\r\n    _ = _drain_pose_queue(pose_queue)\r\n\r\n    # Start tracking\r\n    score = 0\r\n    trial_timer = 0.0\r\n    time_on_target = 0.0\r\n    count_down = False\r\n\r\n    sensor_state.value = 2  # calibrate\r\n    time.sleep(0.1)\r\n    while not sensor_state.value == 3:\r\n        sensor_state.value = 3\r\n        time.sleep(0.05)\r\n\r\n    # Start pulser\r\n    pulse_interval.value = distance_to_interval(distance.value)\r\n    time.sleep(0.2)\r\n    pulse_state.value = 2\r\n\r\n    logging.debug(\"Starting trial\")\r\n    t0 = time.time()\r\n    while trial_timer < settings['trial_time']:\r\n        trial_timer = time.time() - t0\r\n        if game_timer + trial_timer > settings['game_time']:\r\n            break\r\n\r\n        # update UI timer\r\n        game_time_left.value = max(0.0, settings['game_time'] - (game_timer + trial_timer))\r\n\r\n        # pulse interval based on distance\r\n        pulse_interval.value = distance_to_interval(distance.value)\r\n\r\n        # target window / scoring\r\n        if distance.value < settings['target_size']:\r\n            if not count_down:\r\n                time_on_target, count_down = time.time(), True\r\n        else:\r\n            time_on_target, count_down = time.time(), False\r\n\r\n        if count_down and time.time() > time_on_target + settings['target_time']:  # goal condition\r\n            pulse_state.value = 1  # stop pulse loop (idle but don't mute)\r\n\r\n            # Decide score & file\r\n            if trial_timer <= settings['score_time']:\r\n                score = 2\r\n                sfile = 'coins.wav'\r\n                min_audible = 0.35   # let the double-coin poke through\r\n            else:\r\n                score = 1\r\n                sfile = 'coin.wav'\r\n                min_audible = 0.25   # brief head start for single coin\r\n\r\n            # 1) UI immediately (coin pop + score bump)\r\n            last_goal_points.value = score\r\n            session_total.value = int(session_total.value + score)\r\n\r\n            # 2) Make sure loudness is up for SFX and trigger sound non-blocking\r\n            osc_client.send_message('/pyBinSimLoudness', settings['gain'])\r\n\r\n            # Non-blocking SFX trigger\r\n            play_sound(osc_client, soundfile=sfile, duration=None, sleep=False)\r\n\r\n            # 3) Give the SFX a short head-start before we exit/mute\r\n            # read actual duration (safe if file is present)\r\n            actual_dur = slab.Sound(HRIR_DIR / 'sounds' / sfile).duration\r\n            time.sleep( actual_dur)\r\n\r\n            break\r\n\r\n        time.sleep(0.02)\r\n\r\n    t1 = time.time()\r\n    logging.info(f\"Score: {score}\")\r\n    game_timer += trial_timer\r\n    pulse_state.value = 0\r\n    sensor_state.value = 1\r\n\r\n    # Collect pose samples; keep those for our trial id & time window\r\n    raw = _drain_pose_queue(pose_queue)\r\n    # raw items are (t_monotonic, trial_id, yaw, pitch, roll)\r\n    trace = [(t, yaw, pitch,) for (t, tid, yaw, pitch) in raw\r\n             if (tid == trial_idx) and (t0 <= t <= t1)]\r\n\r\n    # Store on subject\r\n    trial_dict = {\r\n        \"trial_idx\": int(trial_idx),\r\n        \"target\": tuple(target.tolist() if hasattr(target, \"tolist\") else target),\r\n        \"pose_trace\": trace,  # [(t, yaw, pitch, roll), ...]\r\n        \"duration\": float(game_timer),\r\n        # add session id if you used begin_session():\r\n        \"session_id\": globals().get(\"_current_session_id\", None)\r\n    }\r\n    if trial_idx == len(subject.trials):\r\n        subject.trials.append(trial_dict)\r\n    elif 0 <= trial_idx < len(subject.trials):\r\n        subject.trials[trial_idx].update(trial_dict)\r\n    else:\r\n        while len(subject.trials) < (trial_idx + 1):\r\n            subject.trials.append({})\r\n        subject.trials[trial_idx] = trial_dict\r\n    subject.write()\r\n    return game_timer, score\r\n\r\n\r\ndef play_session():\r\n    \"\"\"\r\n    Main loop: start workers, then run until game_time.\r\n    \"\"\"\r\n    global osc_client\r\n    osc_client = make_osc_client(port=10003)\r\n    subject = Subject(SUBJECT_ID)\r\n    sequence = subject.last_sequence\r\n\r\n    if sequence:\r\n        az_range = tuple(sequence.settings[\"azimuth_range\"])\r\n        ele_range = tuple(sequence.settings[\"elevation_range\"])\r\n        logging.info(\"Using sequence-based target ranges: az=%s el=%s\", az_range, ele_range)\r\n    else:\r\n        az_range = (-35, 35)\r\n        ele_range = (-35, 35)\r\n        logging.info(\"Using default target ranges: az=%s el=%s\", az_range, ele_range)\r\n\r\n    global settings\r\n    settings = dict(settings, az_range=az_range, ele_range=ele_range)\r\n\r\n    # Shared state for workers\r\n    sensor_state    = mp.Value(\"i\", 0)\r\n    pulse_state     = mp.Value(\"i\", 0)\r\n    target          = mp.Array(\"f\", [0.0, 0.0])\r\n    distance        = mp.Value(\"f\", 0.0)\r\n    pulse_interval  = mp.Value(\"f\", 0.0)\r\n    plot_filter_idx = mp.Value(\"i\", -1)\r\n    current_trial = mp.Value('i', -1)  # -1 = no active trial\r\n    pose_queue = mp.Queue(maxsize=10000)\r\n\r\n    # UI shared state\r\n    current_score   = mp.Value(\"i\", 0)   # optional (not used directly)\r\n    session_total   = mp.Value(\"i\", 0)   # what we display as the big number\r\n    game_time_left  = mp.Value(\"f\", float(settings[\"game_time\"]))\r\n    trial_time_left = mp.Value(\"f\", float(settings[\"trial_time\"]))\r\n    last_goal_points = mp.Value(\"i\", 0)  # 0/1/2 → UI coin animation trigger\r\n    enter_pressed    = mp.Value(\"i\", 0)  # UI sets to 1 when user presses Enter\r\n    ui_state         = mp.Value(\"i\", 0)  # 0 idle, 1 awaiting enter, 2 running, 3 over\r\n\r\n    # Highscore persistence via Subject\r\n    prev_high = int(getattr(subject, \"highscore\", 0))\r\n    highscore = mp.Value(\"i\", prev_high)\r\n\r\n    # Start UI\r\n    shared = game_ui.UIShared(\r\n        current_score=current_score,\r\n        game_time_left=game_time_left,\r\n        trial_time_left=trial_time_left,\r\n        last_goal_points=last_goal_points,\r\n        session_total=session_total,\r\n        enter_pressed=enter_pressed,\r\n        ui_state=ui_state,\r\n        highscore=highscore)\r\n    ui_proc = mp.Process(target=game_ui.run_ui, args=(shared, ROOT / \"data\" / \"ui\" / \"highscores.json\"))\r\n    ui_proc.start()\r\n\r\n    # Start workers\r\n    tracking_worker = mp.Process(target=head_tracker, args=(distance, target, sensor_state, pose_queue,\r\n                                                            current_trial, plot_filter_idx))\r\n    tracking_worker.start()\r\n    binsim_worker = mp.Process(target=binsim_stream, args=())\r\n    binsim_worker.start()\r\n    pulse_worker = mp.Process(target=pulse_maker, args=(pulse_interval, pulse_state))\r\n    pulse_worker.start()\r\n\r\n    if SHOW_TF:  # start plot_worker\r\n        plot_worker = mp.Process(target=plot_current_tf, args=(plot_filter_idx, 0.05, SHOW_TF), daemon=True)\r\n        plot_worker.start()\r\n\r\n    # Wait for tracker init\r\n    while sensor_state.value != 1:\r\n        time.sleep(0.05)\r\n\r\n    try:\r\n        while True:  # multiple sessions\r\n            # Reset per-session state\r\n            session_total.value = 0\r\n            last_goal_points.value = 0\r\n            game_time_left.value = float(settings[\"game_time\"])\r\n            enter_pressed.value = 0\r\n\r\n            # --- PRE-SESSION PROMPT ---\r\n            ui_state.value = 1  # waiting to start\r\n            while enter_pressed.value == 0:\r\n                time.sleep(0.05)\r\n            enter_pressed.value = 0\r\n\r\n            scores = []\r\n            game_timer = 0.0\r\n            game_time_left.value = float(settings[\"game_time\"])\r\n\r\n            while game_timer < settings[\"game_time\"]:\r\n                # init new session for recording\r\n                sess = begin_session(subject)\r\n                globals()[\"_current_session_id\"] = sess['session_id']\r\n                trial_idx = sess[\"base_index\"] + 1\r\n\r\n                # pick next target\r\n                try:\r\n                    set_target_probabilistic(target, settings, sequence, hrir)\r\n                except AttributeError:\r\n                    logging.debug(\"Could not load target probabilities\")\r\n\r\n                # show \"Press Enter\" overlay and wait for user\r\n                ui_state.value = 1\r\n                enter_pressed.value = 0\r\n                while enter_pressed.value == 0:\r\n                    # keep updating UI timer while we wait\r\n                    game_time_left.value = max(0.0, float(settings[\"game_time\"]) - game_timer)\r\n                    time.sleep(0.05)\r\n                # start trial\r\n                ui_state.value = 2\r\n                enter_pressed.value = 0\r\n\r\n                game_timer, score = play_trial(subject, trial_idx, current_trial, target, distance, pulse_interval,\r\n                                               pulse_state, sensor_state, game_time_left, game_timer, session_total,\r\n                                               last_goal_points, pose_queue)\r\n                scores.append(score)\r\n                # update high score live; persist to Subject\r\n                if session_total.value > highscore.value:\r\n                    highscore.value = int(session_total.value)\r\n                    setattr(subject, \"highscore\", int(highscore.value))\r\n                    subject.write()  # your Subject.write() persists object\r\n\r\n                # if time is up, break\r\n                if game_timer >= settings[\"game_time\"]:\r\n                    break\r\n\r\n            # end\r\n            ui_state.value = 3\r\n            pulse_state.value = 1  # idle\r\n            play_sound(osc_client, soundfile='buzzer.wav', duration=None, sleep=True)\r\n            logging.info(f\"Game Over! Total Score: {int(session_total.value)}\")\r\n\r\n            # Show play-again prompt (same big overlay, different text)\r\n            ui_state.value = 3  # session over → \"Press Enter to play again\"\r\n            enter_pressed.value = 0\r\n            # wait for Enter to start next session\r\n            while enter_pressed.value == 0:\r\n                time.sleep(0.05)\r\n            enter_pressed.value = 0\r\n            # loop continues -> new session\r\n\r\n    finally:\r\n        try:\r\n            # Clean up workers\r\n            pulse_state.value = 0\r\n            logging.info(\"Ending\")\r\n            binsim_worker.join()\r\n            pulse_worker.join()\r\n            tracking_worker.join()\r\n            ui_proc.terminate()\r\n            ui_proc.join()\r\n            binsim_worker.terminate()\r\n            pulse_worker.terminate()\r\n            tracking_worker.terminate()\r\n        except Exception:\r\n            pass\r\n        try:\r\n            ui_proc.terminate()\r\n            ui_proc.join()\r\n        except Exception:\r\n            pass\r\n\r\n\r\n\r\n\r\n# -------------------- Main --------------------\r\n\r\nif __name__ == \"__main__\":\r\n    try:\r\n        play_session()\r\n    except KeyboardInterrupt:\r\n        print(\"\\n[Training] Interrupted by user. Shutting down.\")\r\n
-Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
-<+>UTF-8
-===================================================================
-diff --git a/hrtf_relearning/experiment/Training.py b/hrtf_relearning/experiment/Training.py
---- a/hrtf_relearning/experiment/Training.py	(revision 9ebe0d22a7833f12212419e6c03287d130ab7581)
-+++ b/hrtf_relearning/experiment/Training.py	(date 1768566988937)
-@@ -20,8 +20,9 @@
- 
- # -------------------- Config --------------------
- SUBJECT_ID = "paul"
--HRIR_NAME = "universal"  # 'KU100', 'kemar', etc.
-+HRIR_NAME = "PF"  # 'KU100', 'kemar', etc.
- EAR = None              # or None for binaural
-+HP = 'MYSPHERE'
- 
- # Sound
- SOUND_FILE = None         # None -> pink noise pulses; or 'uso_225ms_9_.wav', etc.
-@@ -40,10 +41,8 @@
-     gain=.15)
- 
- # -------------------- Global HRIR/Sequence --------------------
--hrir = hrtf2binsim(HRIR_NAME, EAR,
--    reverb=True, drr=20,
--    hp_filter=True, hp_file="DT990_equalization.wav",
--    convolution="cuda", storage="cuda")
-+hrir = hrtf2binsim(HRIR_NAME, EAR, reverb=False, hp=HP,
-+                   convolution='cuda', storage='cuda', overwrite=False)
- slab.set_default_samplerate(hrir.samplerate)
- HRIR_DIR = ROOT / "data" / "hrtf" / "binsim" / hrir.name
- 
-Index: hrtf_relearning/experiment/Localization.py
-IDEA additional info:
-Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
-<+>import multiprocessing as mp\r\nimport hrtf_relearning\r\nimport datetime\r\nimport time\r\nfrom pathlib import Path\r\nfrom pythonosc import udp_client\r\nfrom hrtf_relearning.experiment.misc.localization_helpers.uso_generation import generate_uso\r\nfrom hrtf_relearning.experiment.misc.training_helpers import meta_motion\r\nfrom hrtf_relearning.experiment.misc.localization_helpers.make_sequence import *\r\nfrom hrtf_relearning.hrtf.binsim.hrtf2binsim import hrtf2binsim\r\nfrom hrtf_relearning.experiment.Subject import Subject\r\nfrom pynput import keyboard\r\ndate = datetime.datetime.now()\r\ndate = f'{date.strftime(\"%d\")}.{date.strftime(\"%m\")}_{date.strftime(\"%H\")}:{date.strftime(\"%M\")}'\r\nlogging.getLogger().setLevel('INFO')\r\nROOT = Path(hrtf_relearning.__file__).resolve().parent\r\n\r\n# --- settings ----\r\nSUBJECT_ID = \"PF\"\r\nHRIR_NAME = \"PF\"  # 'KU100', 'kemar', etc.\r\nEAR = None\r\nSTIM = 'noise'  # 'noise' or 'uso'\r\nHP = 'MYSPHERE'\r\n\r\n# --- load and process HRIR\r\nhrir = hrtf2binsim(HRIR_NAME, EAR, reverb=True, hp=HP,\r\n                   convolution='cuda', storage='cuda', overwrite=False)\r\nslab.set_default_samplerate(hrir.samplerate)\r\nHRIR_DIR = (ROOT / \"data\" / \"hrtf\" / \"binsim\"\r\n            / hrir.name)\r\nsubject = Subject(SUBJECT_ID)\r\n\r\nclass Localization:\r\n    \"\"\"\r\n    Localization test:\r\n        Test localization at uniformly random positions within sectors\r\n    \"\"\"\r\n    def __init__(self, subject, hrir):\r\n        # make trial sequence and write to subject\r\n\r\n        # self.settings = {'kind': 'sectors',\r\n        #                  'azimuth_range': (-35, 35), 'elevation_range': (-35, 35),\r\n        #                  'sector_size': (14, 14),\r\n        #                  'targets_per_sector': 3, 'replace': False, 'min_distance': 30,\r\n        #                  'gain': .2}\r\n        # alternative setting: play 3 times from each source in the hrir (works well for dome recorded hrirs)\r\n        self.settings = {'kind': 'standard', 'azimuth_range': (-1, 1), 'elevation_range': (-35, 35),\r\n                         'targets_per_speaker': 3, 'min_distance': 10, 'gain': .2}\r\n        self.subject = subject\r\n        self.filename = subject.id + date\r\n        # metadata\r\n        slab.set_default_samplerate(hrir.samplerate)\r\n        self.hrir_sources = hrir.sources.vertical_polar\r\n        self.sound_path = ROOT / 'data' / 'hrtf' / 'binsim' / hrir.name / 'sounds'\r\n        self.target = None\r\n\r\n        # make sequence\r\n        self.sequence = make_sequence(self.settings, self.hrir_sources)\r\n        self.sequence.name = self.filename\r\n        self.sequence.hrir = hrir.name\r\n        self.sequence.ear = EAR\r\n        self.sequence.stim = STIM\r\n\r\n    def write(self):\r\n        self.subject.localization[self.filename] = self.sequence\r\n        self.subject.write()\r\n\r\n    def run(self):\r\n        # init pybinsim\r\n        self.osc_client_1 = self._make_osc_client(port=10000)\r\n        self.osc_client_2 = self._make_osc_client(port=10003)\r\n        self.binsim_worker = mp.Process(target=self._binsim_stream, args=(hrir.name,))\r\n        self.binsim_worker.start()\r\n\r\n        # init motion sensor\r\n        self.motion_sensor = self.init_sensor()\r\n        time.sleep(.2)\r\n\r\n        self.play_sound('beep')\r\n        for self.target in self.sequence:\r\n            self.wait_for_button('Look at the Center and press Enter')\r\n            self.motion_sensor.calibrate()\r\n            self.play_trial()  # generate and play stim, get pose response and write to file\r\n        self.subject.last_sequence = self.sequence\r\n        self.sequence.response_errors = target_p(self.sequence, show=False)\r\n        self.write()\r\n        logging.info('Finished.')\r\n        return\r\n\r\n    def play_trial(self):\r\n        # generate stimulus\r\n        self.stim = self.make_stim()  # generate a new stim each trial\r\n        self.stim.write(self.sound_path / 'localization.wav')\r\n        # play stim\r\n        self.play_stimulus()\r\n        time.sleep(self.stim.duration)\r\n        # get response\r\n        self.wait_for_button()\r\n        response = self.motion_sensor.get_pose()\r\n        progress = self.sequence.this_n / len(self.sequence.conditions) * 100\r\n        logging.info(f'{progress:.1f}% | Target: {self.target} | Response: {response}')\r\n        time.sleep(.25)\r\n        self.sequence.add_response(numpy.array((response, self.target)))\r\n        self.write()  # write to file\r\n\r\n    def play_stimulus(self):\r\n        pose = self.motion_sensor.get_pose()\r\n        relative_coords = self.target - pose  # mimic freefield setup\r\n        # find the closest filter idx and send to pybinsim\r\n        relative_coords[0] = (-relative_coords[0] + 360) % 360  # mirror and convert to HRTF convention [0 < az < 360]\r\n        rel_target = numpy.array((relative_coords[0], relative_coords[1], self.hrir_sources[0, 2]))\r\n        filter_idx = numpy.argmin(numpy.linalg.norm(rel_target - self.hrir_sources, axis=1))\r\n        rel_hrtf_coords = self.hrir_sources[filter_idx]\r\n        self.osc_client_1.send_message('/pyBinSim_ds_Filter', [0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n                                                        float(rel_hrtf_coords[0]), float(rel_hrtf_coords[1]), 0,\r\n                                                        0, 0, 0])\r\n        logging.debug(f'Set filter for {self.hrir_sources[filter_idx]}')\r\n        # play\r\n        self.osc_client_2.send_message('/pyBinSimLoudness', self.settings['gain'])\r\n        self.osc_client_2.send_message('/pyBinSimFile', str(self.sound_path / 'localization.wav'))\r\n        time.sleep(.5)\r\n        self.osc_client_2.send_message('/pyBinSimLoudness', 0)\r\n\r\n    def play_sound(self, kind):\r\n        logging.info(f'Playing {kind} sound')\r\n        name = f'{kind}.wav'\r\n        duration = slab.Sound(self.sound_path / name).duration\r\n        self.osc_client_2.send_message('/pyBinSimLoudness', self.settings['gain'])\r\n        self.osc_client_2.send_message('/pyBinSimFile', str(self.sound_path / name))\r\n        time.sleep(duration)\r\n        self.osc_client_2.send_message('/pyBinSimLoudness', 0)\r\n\r\n    @staticmethod\r\n    def _make_osc_client(port, ip='127.0.0.1'):\r\n        return udp_client.SimpleUDPClient(ip, port)\r\n\r\n    @staticmethod\r\n    def _binsim_stream(hrir_name):\r\n        import pybinsim\r\n        pybinsim.logger.setLevel(logging.ERROR)\r\n        binsim = pybinsim.BinSim(ROOT / 'data'  / 'hrtf' / 'binsim' / hrir_name / f'{hrir_name}_test_settings.txt')\r\n        binsim.stream_start()  # run binsim loop\r\n\r\n    @staticmethod\r\n    def init_sensor():\r\n        # init motion sensor\r\n        device = meta_motion.get_device()  # Ensure this function initializes the hardware correctly\r\n        state = meta_motion.State(device)\r\n        return meta_motion.Sensor(state)\r\n\r\n    @staticmethod\r\n    def make_stim():\r\n        if STIM == 'noise':\r\n            stim = slab.Sound.pinknoise(duration=0.225, level=80).ramp(when='both', duration=0.01)\r\n            n_silent = (numpy.arange(25,221,25).reshape(4,2) * stim.samplerate / 1000).astype(int)\r\n            ramp_len = int(.005 * stim.samplerate)\r\n            half_len = int(ramp_len / 2)\r\n            for start, end in n_silent:\r\n                ramp_up = 0.5 * (1 - numpy.cos(numpy.linspace(0, numpy.pi, ramp_len)))\r\n                ramp_down = 0.5 * (1 - numpy.cos(numpy.linspace(numpy.pi, 0, ramp_len)))\r\n                ramp_up = ramp_up[:, numpy.newaxis]\r\n                ramp_down = ramp_down[:, numpy.newaxis]\r\n                # Apply ramps at the edges of the silent region\r\n                stim.data[start - half_len: start + half_len] *= (1 - ramp_up)\r\n                stim.data[end - half_len: end + half_len] *= (1 - ramp_down)\r\n                # Silence the center\r\n                stim.data[start + half_len: end - half_len] = 0\r\n            # stim = slab.Sound.pinknoise(duration=0.5, level=90).ramp(when='both', duration=0.01)\r\n            # noise = slab.Sound.pinknoise(duration=0.025, level=90)\r\n            # noise = noise.ramp(when='both', duration=0.01)\r\n            # silence = slab.Sound.silence(duration=0.025)\r\n            # stim = slab.Sound.sequence(noise, silence, noise, silence, noise,\r\n            #                            silence, noise, silence, noise)\r\n            # stim.ramp('both', 0.01)\r\n        elif STIM == 'uso':\r\n            stim = generate_uso(samplerate=hrir.samplerate)\r\n        else: raise ValueError('STIM must be \"noise\" or \"uso\".')\r\n        stim.level = 80\r\n        return stim\r\n\r\n    @staticmethod\r\n    def wait_for_button(msg=None):\r\n        if msg: print(msg)\r\n        def on_press(key):\r\n            if key == keyboard.Key.enter:\r\n                listener.stop()  # stop listening once Enter is pressed\r\n        with keyboard.Listener(on_press=on_press) as listener:\r\n            listener.join()  # block until listener.stop() is called\r\n\r\nif __name__ == \"__main__\":\r\n    loc_test = Localization(subject, hrir)\r\n    loc_test.run()\r\n    sequence = subject.localization[loc_test.filename]\r\n    plot_localization(sequence, report_stats=['azimuth', 'elevation'], filepath=ROOT / 'data'  / 'results' / 'plot' / subject.id)\r\n    plot_elevation_response(sequence, filepath=ROOT / 'data'  / 'results' / 'plot' / subject.id)
-Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
-<+>UTF-8
-===================================================================
-diff --git a/hrtf_relearning/experiment/Localization.py b/hrtf_relearning/experiment/Localization.py
---- a/hrtf_relearning/experiment/Localization.py	(revision 9ebe0d22a7833f12212419e6c03287d130ab7581)
-+++ b/hrtf_relearning/experiment/Localization.py	(date 1768896719269)
-@@ -16,8 +16,8 @@
- ROOT = Path(hrtf_relearning.__file__).resolve().parent
- 
- # --- settings ----
--SUBJECT_ID = "PF"
--HRIR_NAME = "PF"  # 'KU100', 'kemar', etc.
-+SUBJECT_ID = "MB"
-+HRIR_NAME = "universal"  # 'KU100', 'kemar', etc.
- EAR = None
- STIM = 'noise'  # 'noise' or 'uso'
- HP = 'MYSPHERE'
-@@ -38,14 +38,14 @@
-     def __init__(self, subject, hrir):
-         # make trial sequence and write to subject
- 
--        # self.settings = {'kind': 'sectors',
--        #                  'azimuth_range': (-35, 35), 'elevation_range': (-35, 35),
--        #                  'sector_size': (14, 14),
--        #                  'targets_per_sector': 3, 'replace': False, 'min_distance': 30,
--        #                  'gain': .2}
-+        self.settings = {'kind': 'sectors',
-+                         'azimuth_range': (-35, 35), 'elevation_range': (-35, 35),
-+                         'sector_size': (14, 14),
-+                         'targets_per_sector': 3, 'replace': False, 'min_distance': 30,
-+                         'gain': .2}
-         # alternative setting: play 3 times from each source in the hrir (works well for dome recorded hrirs)
--        self.settings = {'kind': 'standard', 'azimuth_range': (-1, 1), 'elevation_range': (-35, 35),
--                         'targets_per_speaker': 3, 'min_distance': 10, 'gain': .2}
-+        # self.settings = {'kind': 'standard', 'azimuth_range': (-1, 1), 'elevation_range': (-35, 35),
-+        #                  'targets_per_speaker': 3, 'min_distance': 10, 'gain': .2}
-         self.subject = subject
-         self.filename = subject.id + date
-         # metadata
-@@ -191,5 +191,5 @@
-     loc_test = Localization(subject, hrir)
-     loc_test.run()
-     sequence = subject.localization[loc_test.filename]
--    plot_localization(sequence, report_stats=['azimuth', 'elevation'], filepath=ROOT / 'data'  / 'results' / 'plot' / subject.id)
-+    plot_localization(sequence, report_stats=['azimuth', 'elevation'], filepath=ROOT / 'data'  / 'results' / 'plot' / subject.id)  # todo
-     plot_elevation_response(sequence, filepath=ROOT / 'data'  / 'results' / 'plot' / subject.id)
-\ No newline at end of file
-Index: hrtf_relearning/__init__.py
-IDEA additional info:
-Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
-<+>from pathlib import Path\r\nfrom hrtf_relearning.experiment.Subject import Subject\r\nfrom hrtf_relearning.experiment.analysis.localization.localization_analysis import localization_accuracy\r\n# Absolute path to the installed package root\r\nPATH = Path(__file__).resolve().parent\r\n\r\n__all__ = [\"PATH\", \"Subject\", \"localization_accuracy\"]
-Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
-<+>UTF-8
-===================================================================
-diff --git a/hrtf_relearning/__init__.py b/hrtf_relearning/__init__.py
---- a/hrtf_relearning/__init__.py	(revision 9ebe0d22a7833f12212419e6c03287d130ab7581)
-+++ b/hrtf_relearning/__init__.py	(date 1768566360133)
-@@ -1,7 +1,7 @@
- from pathlib import Path
- from hrtf_relearning.experiment.Subject import Subject
--from hrtf_relearning.experiment.analysis.localization.localization_analysis import localization_accuracy
-+from hrtf_relearning.experiment.analysis.localization.localization_analysis import *
- # Absolute path to the installed package root
- PATH = Path(__file__).resolve().parent
- 
--__all__ = ["PATH", "Subject", "localization_accuracy"]
-\ No newline at end of file
-+__all__ = ["PATH", "Subject", "localization_accuracy", "target_p"]
-\ No newline at end of file
-Index: hrtf_relearning/hrtf/processing/make/unity2sofa.py
-IDEA additional info:
-Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
-<+>import matplotlib\r\nmatplotlib.use('tkagg')\r\nfrom matplotlib import pyplot as plt\r\nimport numpy as numpy\r\nimport slab\r\nimport pyfar\r\nimport hrtf_relearning\r\nimport re\r\n\r\nbase = hrtf_relearning.PATH / 'data' / 'hrtf'\r\npattern = re.compile(r\"hrir_az(?P<az>[+-]?\\d+\\.\\d)_el(?P<el>[+-]?\\d+\\.\\d)\\.wav\")\r\nwav_files = sorted((base / 'rec' / 'universal').glob(\"hrir_az*_el*.wav\"))\r\n\r\nfs = 48000\r\ndist = 1.0\r\n\r\n# I read wav files, write coordinates, align IR onsets and crop to 256 samples\r\ndata = []\r\nsources = []\r\nfor fname in wav_files:\r\n    ir = pyfar.io.read_audio(fname)\r\n    az = float(pattern.match(fname.name).group('az'))\r\n    el = float(pattern.match(fname.name).group('el'))\r\n    onsets = pyfar.dsp.find_impulse_response_start(ir)\r\n    aligned = pyfar.dsp.time_shift(\r\n        ir, -numpy.min(onsets) / ir.sampling_rate + .001,\r\n        unit='s')\r\n    windowed = pyfar.dsp.time_window(aligned, interval=(0, 255), window='boxcar', crop='window')\r\n    sources.append([az, el, dist])\r\n    data.append(windowed.time)\r\n\r\n# write sofa\r\nhrtf = slab.HRTF(data=numpy.array(data), datatype='FIR', samplerate=fs, sources=numpy.array(sources))\r\nhrtf.write_sofa(base / 'sofa' / 'universal.sofa')\r\n\r\n\r\n\r\n\"\"\"\r\nWrite sources txt for use in unity from numpy array\r\n\"\"\"\r\n\r\nimport slab\r\nimport hrtf_relearning\r\nhrtf_dir = hrtf_relearning.PATH / 'data' / 'hrtf' / 'sofa'\r\nfrom pathlib import Path\r\nfrom hrtf_relearning.hrtf.processing.make.spherical_sources import *\r\n\r\n\r\nsources = spherical_sources(resolution_deg=5)\r\n\r\nout = Path(\"C:/Users/paulf/UnityProjects/hrtf_relearning/Assets/StreamingAssets/sources.txt\")\r\nnumpy.savetxt(\r\n    out,\r\n    sources,\r\n    fmt=\"%.2f %.2f %.2f\",\r\n    header=\"az_deg el_deg radius_m\",\r\n    comments=\"\"\r\n)\r\nprint(f\"Wrote {sources.shape[0]} sources to {out}\")\r\n\r\n\r\n# test\r\nhrtf = slab.HRTF(hrtf_dir / 'universal.sofa')\r\naz_cone = hrtf.cone_sources(plane='horizontal')\r\nel_cone = hrtf.cone_sources(0)\r\n\r\nsound = slab.Binaural.pinknoise()\r\n# fig, ax = plt.subplots( figsize=(12, 8))\r\nfor src in el_cone:\r\n    # ax.clear()\r\n    # hrtf.plot_ir([src], ear='both', axis=[ax, ax])\r\n    # plt.show()\r\n    print(f'playing from {hrtf.sources.interaural_polar[src]}')\r\n    hrtf.apply(src, sound).play()\r\n\r\n# fig, ax = plt.subplots(figsize=(12, 8))\r\n# for src in source_idx:\r\n#     hrtf.plot_ir([src], axis=ax)\r\n#     ax.get_lines()[-1].set_label(f'{hrtf.sources.vertical_polar[src]}')\r\n#     plt.legend()\r\n
-Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
-<+>UTF-8
-===================================================================
-diff --git a/hrtf_relearning/hrtf/processing/make/unity2sofa.py b/hrtf_relearning/hrtf/processing/make/unity2sofa.py
---- a/hrtf_relearning/hrtf/processing/make/unity2sofa.py	(revision 9ebe0d22a7833f12212419e6c03287d130ab7581)
-+++ b/hrtf_relearning/hrtf/processing/make/unity2sofa.py	(date 1768568498920)
-@@ -47,6 +47,8 @@
- 
- 
- sources = spherical_sources(resolution_deg=5)
-+# todo add your sources
-+
- 
- out = Path("C:/Users/paulf/UnityProjects/hrtf_relearning/Assets/StreamingAssets/sources.txt")
- numpy.savetxt(
-Index: .idea/shelf/Uncommitted_changes_before_Update_at_1_2_2026_5_52_PM_[Changes]/shelved.patch
-===================================================================
-diff --git a/.idea/shelf/Uncommitted_changes_before_Update_at_1_2_2026_5_52_PM_[Changes]/shelved.patch b/.idea/shelf/Uncommitted_changes_before_Update_at_1_2_2026_5_52_PM_[Changes]/shelved.patch
-deleted file mode 100644
---- a/.idea/shelf/Uncommitted_changes_before_Update_at_1_2_2026_5_52_PM_[Changes]/shelved.patch	(revision 9ebe0d22a7833f12212419e6c03287d130ab7581)
-+++ /dev/null	(revision 9ebe0d22a7833f12212419e6c03287d130ab7581)
-@@ -1,92 +0,0 @@
--Index: hrtf_relearning/experiment/Localization.py
--IDEA additional info:
--Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
--<+>from hrtf_relearning.analysis.localization import *  # also set mpl backend\r\nimport multiprocessing as mp\r\nimport hrtf_relearning\r\nimport datetime\r\nimport time\r\nfrom pathlib import Path\r\nfrom pythonosc import udp_client\r\n\r\nfrom hrtf_relearning.experiment.misc.localization_helpers.uso_generation import generate_uso\r\nfrom hrtf_relearning.experiment.misc.training_helpers import meta_motion\r\nfrom hrtf_relearning.experiment.misc.localization_helpers.make_sequence import *\r\nfrom hrtf_relearning.hrtf.binsim.hrtf2binsim import hrtf2binsim\r\nfrom hrtf_relearning.experiment.Subject import Subject\r\nfrom pynput import keyboard\r\ndate = datetime.datetime.now()\r\ndate = f'{date.strftime(\"%d\")}.{date.strftime(\"%m\")}_{date.strftime(\"%H\")}:{date.strftime(\"%M\")}'\r\nlogging.getLogger().setLevel('INFO')\r\nROOT = Path(hrtf_relearning.__file__).resolve().parent\r\n\r\n# --- settings ----\r\nSUBJECT_ID = \"AvS\"\r\nHRIR_NAME = \"KU100\"  # 'KU100', 'kemar', etc.\r\nEAR = None\r\nSTIM = 'noise_burst'  # 'uso'\r\n\r\n# --- load and process HRIR\r\nhrir = hrtf2binsim(HRIR_NAME, EAR, reverb=True, hp_filter=True,\r\n                   convolution='cpu', storage='cpu', overwrite=False)\r\nslab.set_default_samplerate(hrir.samplerate)\r\nHRIR_DIR = ROOT / \"data\" / \"hrtf\" / \"binsim\" / hrir.name\r\nsubject = Subject(SUBJECT_ID)\r\n\r\nclass Localization:\r\n    \"\"\"\r\n    Localization test:\r\n        Test localization at uniformly random positions within sectors\r\n    \"\"\"\r\n    def __init__(self, subject, hrir):\r\n        # make trial sequence and write to subject\r\n\r\n        self.settings = {'kind': 'sectors',\r\n                         'azimuth_range': (-35, 35), 'elevation_range': (-35, 35),\r\n                         'sector_size': (14, 14),\r\n                         'targets_per_sector': 3, 'replace': False, 'min_distance': 15,\r\n                         'gain': .2}\r\n        # alternative setting: play 3 times from each source in the hrir (works well for dome recorded hrirs)\r\n        #self.settings = {'kind': 'standard', 'azimuth_range': (-45, 45), 'elevation_range': (-45, 45),\r\n         #                 'targets_per_speaker': 2, 'min_distance': 30, 'gain': .4}\r\n        self.subject = subject\r\n        self.filename = subject.id + f'_{hrir.name}' + '_loc_' + date\r\n        # metadata\r\n        slab.set_default_samplerate(hrir.samplerate)\r\n        self.hrir_sources = hrir.sources.vertical_polar\r\n        self.sound_path = ROOT / 'data' / 'hrtf' / 'binsim' / hrir.name / 'sounds'\r\n        self.target = None\r\n\r\n        # make sequence\r\n        self.sequence = make_sequence(self.settings, self.hrir_sources)\r\n        # self.sequence = make_sequence(self.settings)\r\n        self.sequence.name = self.filename\r\n\r\n    def write(self):\r\n        self.subject.localization[self.filename] = self.sequence\r\n        self.subject.write()\r\n\r\n    def run(self):\r\n        # init pybinsim\r\n        self.osc_client_1 = self._make_osc_client(port=10000)\r\n        self.osc_client_2 = self._make_osc_client(port=10003)\r\n        self.binsim_worker = mp.Process(target=self._binsim_stream, args=(hrir.name,))\r\n        self.binsim_worker.start()\r\n\r\n        # init motion sensor\r\n        self.motion_sensor = self.init_sensor()\r\n        time.sleep(.2)\r\n\r\n        self.play_sound('beep')\r\n        for self.target in self.sequence:\r\n            self.wait_for_button('Look at the Center and press Enter')\r\n            self.motion_sensor.calibrate()\r\n            self.play_trial()  # generate and play stim, get pose response and write to file\r\n        self.subject.last_sequence = self.sequence\r\n        self.sequence.response_errors = target_p(self.sequence, show=False)\r\n        self.write()\r\n        logging.info('Finished.')\r\n        return\r\n\r\n    def play_trial(self):\r\n        # generate stimulus\r\n        self.stim = self.make_stim()  # generate a new stim each trial\r\n        self.stim.write(self.sound_path / 'localization.wav')\r\n        # play stim\r\n        self.play_stimulus()\r\n        time.sleep(self.stim.duration)\r\n        # get response\r\n        self.wait_for_button()\r\n        response = self.motion_sensor.get_pose()\r\n        progress = self.sequence.this_n / len(self.sequence.conditions) * 100\r\n        logging.info(f'{progress:.1f}% | Target: {self.target} | Response: {response}')\r\n        time.sleep(.25)\r\n        self.sequence.add_response(numpy.array((response, self.target)))\r\n        self.write()  # write to file\r\n\r\n    def play_stimulus(self):\r\n        pose = self.motion_sensor.get_pose()\r\n        relative_coords = self.target - pose  # mimic freefield setup\r\n        # find the closest filter idx and send to pybinsim\r\n        relative_coords[0] = (-relative_coords[0] + 360) % 360  # mirror and convert to HRTF convention [0 < az < 360]\r\n        rel_target = numpy.array((relative_coords[0], relative_coords[1], self.hrir_sources[0, 2]))\r\n        filter_idx = numpy.argmin(numpy.linalg.norm(rel_target - self.hrir_sources, axis=1))\r\n        rel_hrtf_coords = self.hrir_sources[filter_idx]\r\n        self.osc_client_1.send_message('/pyBinSim_ds_Filter', [0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n                                                        float(rel_hrtf_coords[0]), float(rel_hrtf_coords[1]), 0,\r\n                                                        0, 0, 0])\r\n        logging.debug(f'Set filter for {self.hrir_sources[filter_idx]}')\r\n        # play\r\n        self.osc_client_2.send_message('/pyBinSimLoudness', self.settings['gain'])\r\n        self.osc_client_2.send_message('/pyBinSimFile', str(self.sound_path / 'localization.wav'))\r\n        time.sleep(.5)\r\n        self.osc_client_2.send_message('/pyBinSimLoudness', 0)\r\n\r\n    def play_sound(self, kind):\r\n        logging.info(f'Playing {kind} sound')\r\n        name = f'{kind}.wav'\r\n        duration = slab.Sound(self.sound_path / name).duration\r\n        self.osc_client_2.send_message('/pyBinSimLoudness', self.settings['gain'])\r\n        self.osc_client_2.send_message('/pyBinSimFile', str(self.sound_path / name))\r\n        time.sleep(duration)\r\n        self.osc_client_2.send_message('/pyBinSimLoudness', 0)\r\n\r\n    @staticmethod\r\n    def _make_osc_client(port, ip='127.0.0.1'):\r\n        return udp_client.SimpleUDPClient(ip, port)\r\n\r\n    @staticmethod\r\n    def _binsim_stream(hrir_name):\r\n        import pybinsim\r\n        pybinsim.logger.setLevel(logging.ERROR)\r\n        binsim = pybinsim.BinSim(ROOT / 'data'  / 'hrtf' / 'binsim' / hrir_name / f'{hrir_name}_test_settings.txt')\r\n        binsim.stream_start()  # run binsim loop\r\n\r\n    @staticmethod\r\n    def init_sensor():\r\n        # init motion sensor\r\n        device = meta_motion.get_device()  # Ensure this function initializes the hardware correctly\r\n        state = meta_motion.State(device)\r\n        return meta_motion.Sensor(state)\r\n\r\n    @staticmethod\r\n    def make_stim():\r\n        if STIM == 'noise':\r\n            stim = slab.Sound.pinknoise(duration=0.225, level=80).ramp(when='both', duration=0.01)\r\n            n_silent = (numpy.arange(25,221,25).reshape(4,2) * stim.samplerate / 1000).astype(int)\r\n            ramp_len = int(.005 * stim.samplerate)\r\n            half_len = int(ramp_len / 2)\r\n            for start, end in n_silent:\r\n                ramp_up = 0.5 * (1 - numpy.cos(numpy.linspace(0, numpy.pi, ramp_len)))\r\n                ramp_down = 0.5 * (1 - numpy.cos(numpy.linspace(numpy.pi, 0, ramp_len)))\r\n                ramp_up = ramp_up[:, numpy.newaxis]\r\n                ramp_down = ramp_down[:, numpy.newaxis]\r\n                # Apply ramps at the edges of the silent region\r\n                stim.data[start - half_len: start + half_len] *= (1 - ramp_up)\r\n                stim.data[end - half_len: end + half_len] *= (1 - ramp_down)\r\n                # Silence the center\r\n                stim.data[start + half_len: end - half_len] = 0\r\n            # stim = slab.Sound.pinknoise(duration=0.5, level=90).ramp(when='both', duration=0.01)\r\n            # noise = slab.Sound.pinknoise(duration=0.025, level=90)\r\n            # noise = noise.ramp(when='both', duration=0.01)\r\n            # silence = slab.Sound.silence(duration=0.025)\r\n            # stim = slab.Sound.sequence(noise, silence, noise, silence, noise,\r\n            #                            silence, noise, silence, noise)\r\n            # stim.ramp('both', 0.01)\r\n        elif STIM == 'uso':\r\n            stim = generate_uso(samplerate=hrir.samplerate)\r\n        else: raise ValueError('STIM must be \"noise\" or \"uso\".')\r\n        stim.level = 80\r\n        return stim\r\n\r\n    @staticmethod\r\n    def wait_for_button(msg=None):\r\n        if msg: print(msg)\r\n        def on_press(key):\r\n            if key == keyboard.Key.enter:\r\n                listener.stop()  # stop listening once Enter is pressed\r\n        with keyboard.Listener(on_press=on_press) as listener:\r\n            listener.join()  # block until listener.stop() is called\r\n\r\nif __name__ == \"__main__\":\r\n    loc_test = Localization(subject, hrir)\r\n    loc_test.run()\r\n    sequence = subject.localization[loc_test.filename]\r\n    plot_localization(sequence, report_stats=['azimuth', 'elevation'], filepath=ROOT / 'data'  / 'results' / 'plot' / subject.id)\r\n    plot_elevation_response(sequence, filepath=ROOT / 'data'  / 'results' / 'plot' / subject.id)
--Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
--<+>UTF-8
--===================================================================
--diff --git a/hrtf_relearning/experiment/Localization.py b/hrtf_relearning/experiment/Localization.py
----- a/hrtf_relearning/experiment/Localization.py	(revision 3c1328cced2ec02fa1c89da81a461651598a84dc)
--+++ b/hrtf_relearning/experiment/Localization.py	(date 1767372769987)
--@@ -18,16 +18,17 @@
-- ROOT = Path(hrtf_relearning.__file__).resolve().parent
-- 
-- # --- settings ----
---SUBJECT_ID = "AvS"
---HRIR_NAME = "KU100"  # 'KU100', 'kemar', etc.
--+SUBJECT_ID = "test"
--+HRIR_NAME = "universal"  # 'KU100', 'kemar', etc.
-- EAR = None
---STIM = 'noise_burst'  # 'uso'
--+STIM = 'noise'  # 'noise' or 'uso'
-- 
-- # --- load and process HRIR
-- hrir = hrtf2binsim(HRIR_NAME, EAR, reverb=True, hp_filter=True,
--                    convolution='cpu', storage='cpu', overwrite=False)
-- slab.set_default_samplerate(hrir.samplerate)
---HRIR_DIR = ROOT / "data" / "hrtf" / "binsim" / hrir.name
--+HRIR_DIR = (ROOT / "data" / "hrtf" / "binsim"
--+            / hrir.name)
-- subject = Subject(SUBJECT_ID)
-- 
-- class Localization:
--Index: hrtf_relearning/experiment/misc/localization_helpers/uso_generation.py
--IDEA additional info:
--Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
--<+>import math\r\nimport numpy\r\nimport slab\r\nfrom pathlib import Path\r\nimport random\r\nimport hrtf_relearning\r\nROOT = Path(hrtf_relearning.__file__).resolve().parent\r\ninput_folder = ROOT / 'data' / 'sounds' / 'mitsu_sounds'\r\n\r\ndef generate_uso(samplerate, duration=0.225, base=numpy.random.randint(0, 6), n_sounds=5):\r\n    bases = ['dryer', 'particl2', 'spray', 'shaver', 'tear', 'crumple', 'coffmill']\r\n    files = ['cherry1', 'cherry2', 'cherry3', 'wood2', 'wood3',\r\n               'bank', 'bowl', 'candybwl', 'colacan', 'metal15', 'metal10', 'metal05', 'trashbox',\r\n               'case1', 'case2', 'case3', 'dice2', 'dice3',\r\n               'bottle1', 'bottle2', 'china3', 'china4',\r\n               'saw2', 'sandpp1', 'sandpp2',\r\n               'sticks',\r\n               'clap1', 'clap2', 'cap1', 'cap2', 'snap', 'cracker',\r\n               'bell2', 'bells3', 'coin2', 'coin3',\r\n               'book1', 'book2',\r\n               'castanet', 'maracas', 'drum',\r\n               'stapler', 'punch']\r\n    sout = slab.Sound.read(input_folder / str(bases[base] + '.wav'))\r\n    base_sr = sout.samplerate\r\n    base_level = sout.level\r\n    length = int(base_sr * duration)\r\n    sout = sout.data[:, 0]\r\n    sout = sout[numpy.where((sout > 0.03) == True)[0][0]:numpy.where((sout > 0.03) == True)[0][-1]][1000:length+1000]\r\n    for i in range(n_sounds):\r\n        s = slab.Sound(input_folder / str(random.choice(files) + '.wav'))\r\n        while not any(numpy.abs(s.data) > 0.1):\r\n            s = slab.Sound(input_folder / str(random.choice(files) + '.wav'))\r\n        s_sr = s.samplerate\r\n        start, stop = numpy.where(numpy.abs(s.data) > 0.1)[0][0], numpy.where(numpy.abs(s.data) > 5e-3)[0][-1]\r\n        s = s.data[start:stop]\r\n        if base_sr != s_sr:\r\n            print(\"Error: Samplerates don't match\")\r\n        # offset = math.ceil(numpy.random.randint(low=0, high=50, size=1)/100 * length)\r\n        offset = int(length - length / n_sounds * (i + 1))\r\n        s = numpy.append(numpy.zeros(offset), s)\r\n        s = numpy.append(s, numpy.zeros(length))\r\n        s = s[:length]\r\n        # plt.plot(s)  # nice plot\r\n        sout = numpy.sum((sout, s), axis=0)\r\n    sout = slab.Sound(data=sout, samplerate=48000)\r\n    sout = sout.ramp(when='both', duration=0.01)\r\n    sout.data = (sout.data / sout.data.max()) - 0.01\r\n    sout = sout.resample(samplerate)\r\n    return sout
--Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
--<+>UTF-8
--===================================================================
--diff --git a/hrtf_relearning/experiment/misc/localization_helpers/uso_generation.py b/hrtf_relearning/experiment/misc/localization_helpers/uso_generation.py
----- a/hrtf_relearning/experiment/misc/localization_helpers/uso_generation.py	(revision 3c1328cced2ec02fa1c89da81a461651598a84dc)
--+++ b/hrtf_relearning/experiment/misc/localization_helpers/uso_generation.py	(date 1766159113326)
--@@ -22,7 +22,7 @@
--                'stapler', 'punch']
--     sout = slab.Sound.read(input_folder / str(bases[base] + '.wav'))
--     base_sr = sout.samplerate
---    base_level = sout.level
--+    sout.level += 6
--     length = int(base_sr * duration)
--     sout = sout.data[:, 0]
--     sout = sout[numpy.where((sout > 0.03) == True)[0][0]:numpy.where((sout > 0.03) == True)[0][-1]][1000:length+1000]
--Index: .idea/shelf/Uncommitted_changes_before_Update_at_12_17_2025_5_21_PM_[Changes]/shelved.patch
--===================================================================
--diff --git a/.idea/shelf/Uncommitted_changes_before_Update_at_12_17_2025_5_21_PM_[Changes]/shelved.patch b/.idea/shelf/Uncommitted_changes_before_Update_at_12_17_2025_5_21_PM_[Changes]/shelved.patch
--deleted file mode 100644
----- a/.idea/shelf/Uncommitted_changes_before_Update_at_12_17_2025_5_21_PM_[Changes]/shelved.patch	(revision 3c1328cced2ec02fa1c89da81a461651598a84dc)
--+++ /dev/null	(revision 3c1328cced2ec02fa1c89da81a461651598a84dc)
--@@ -1,22 +0,0 @@
---Index: hrtf_relearning/data/env config.txt
---===================================================================
---diff --git a/hrtf_relearning/data/env config.txt b/hrtf_relearning/data/env config.txt
---deleted file mode 100644
------ a/hrtf_relearning/data/env config.txt	(revision a5f0f2be9bbb483146dbd9fe5f5e7afe0aad62c2)
---+++ /dev/null	(revision a5f0f2be9bbb483146dbd9fe5f5e7afe0aad62c2)
---@@ -1,14 +0,0 @@
----pycharm 2025.2
----python 3.11.9 virtual environment (-add git/bin to PATH variables)
----
----
----pip install git+https://github.com/pfriedrich-hub/slab.git
---- git+https://github.com/pfriedrich-hub/pybinsim_tuil.git
---- h5py h5netcdf metawear pyqt5 pynput pyfar
----
----
---- optional:
----    -for cuda support (>=RTX 30xx):
----        pip install torch torchvision --index-url https://download.pytorch.org/whl/cu128
----        check with: torch.cuda.is_available()
---- pip install git+https://github.com/pfriedrich-hub/freefield.git
---\ No newline at end of file
--Index: .idea/shelf/Uncommitted_changes_before_Update_at_12_17_2025_5_21_PM__Changes_.xml
--===================================================================
--diff --git a/.idea/shelf/Uncommitted_changes_before_Update_at_12_17_2025_5_21_PM__Changes_.xml b/.idea/shelf/Uncommitted_changes_before_Update_at_12_17_2025_5_21_PM__Changes_.xml
--deleted file mode 100644
----- a/.idea/shelf/Uncommitted_changes_before_Update_at_12_17_2025_5_21_PM__Changes_.xml	(revision 3c1328cced2ec02fa1c89da81a461651598a84dc)
--+++ /dev/null	(revision 3c1328cced2ec02fa1c89da81a461651598a84dc)
--@@ -1,4 +0,0 @@
---<changelist name="Uncommitted_changes_before_Update_at_12_17_2025_5_21_PM_[Changes]" date="1765988508893" recycled="true" deleted="true">
---  <option name="PATH" value="$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Update_at_12_17_2025_5_21_PM_[Changes]/shelved.patch" />
---  <option name="DESCRIPTION" value="Uncommitted changes before Update at 12/17/2025 5:21 PM [Changes]" />
---</changelist>
--\ No newline at end of file
-Index: .idea/shelf/Uncommitted_changes_before_Update_at_1_2_2026_5_52_PM__Changes_.xml
-===================================================================
-diff --git a/.idea/shelf/Uncommitted_changes_before_Update_at_1_2_2026_5_52_PM__Changes_.xml b/.idea/shelf/Uncommitted_changes_before_Update_at_1_2_2026_5_52_PM__Changes_.xml
-deleted file mode 100644
---- a/.idea/shelf/Uncommitted_changes_before_Update_at_1_2_2026_5_52_PM__Changes_.xml	(revision 9ebe0d22a7833f12212419e6c03287d130ab7581)
-+++ /dev/null	(revision 9ebe0d22a7833f12212419e6c03287d130ab7581)
-@@ -1,14 +0,0 @@
--<changelist name="Uncommitted_changes_before_Update_at_1_2_2026_5_52_PM_[Changes]" date="1767372774896" recycled="true" deleted="true">
--  <option name="PATH" value="$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Update_at_1_2_2026_5_52_PM_[Changes]/shelved.patch" />
--  <option name="DESCRIPTION" value="Uncommitted changes before Update at 1/2/2026 5:52 PM [Changes]" />
--  <binary>
--    <option name="BEFORE_PATH" value="hrtf_relearning/data/results/AvS.pkl" />
--    <option name="AFTER_PATH" value="hrtf_relearning/data/results/AvS.pkl" />
--    <option name="SHELVED_PATH" value="$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Update_at_1_2_2026_5_52_PM_[Changes]/AvS.pkl" />
--  </binary>
--  <binary>
--    <option name="BEFORE_PATH" value="hrtf_relearning/data/results/test.pkl" />
--    <option name="AFTER_PATH" value="hrtf_relearning/data/results/test.pkl" />
--    <option name="SHELVED_PATH" value="$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Update_at_1_2_2026_5_52_PM_[Changes]/test.pkl" />
--  </binary>
--</changelist>
-\ No newline at end of file
